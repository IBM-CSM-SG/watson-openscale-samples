{"cells":[{"metadata":{},"cell_type":"markdown","source":["<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"]},{"metadata":{},"cell_type":"markdown","source":["# Tutorial on generating an explanation for an image-based binary classifier model on Watson OpenScale"]},{"metadata":{},"cell_type":"markdown","source":["## Contents:\n","- [1. Setup](#setup)\n","- [2. Creating and deploying an image-based model](#deployment)\n","- [3. Subscriptions](#subscription)\n","- [4. Explainability](#explainability)"]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"setup\"></a>\n","## 1. Setup\n","\n","### 1.1 Install OS and WML packages"]},{"metadata":{},"cell_type":"code","source":["!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["!pip install --upgrade ibm-watson-machine-learning --no-cache | tail -n 1"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Note: Restart the kernel to assure the new libraries are being used."]},{"metadata":{},"cell_type":"markdown","source":["### 1.2 Configure credentials"]},{"metadata":{},"cell_type":"markdown","source":["Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.\n","\n","**NOTE:** You can also get OpenScale `API_KEY` using IBM CLOUD CLI.\n","\n","How to install IBM Cloud (bluemix) console: [instruction](https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use)\n","\n","How to get api key using console:\n","```\n","bx login --sso\n","bx iam api-key-create 'my_key'\n","```"]},{"metadata":{},"cell_type":"code","source":["CLOUD_API_KEY = \"***\"\n","IAM_URL=\"https://iam.ng.bluemix.net/oidc/token\""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["WML_CREDENTIALS = {\n","                   \"url\": \"https://us-south.ml.cloud.ibm.com\",\n","                   \"apikey\": CLOUD_API_KEY\n","}"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"deployment\"></a>\n","## 2. Creating and deploying an image-based model"]},{"metadata":{},"cell_type":"markdown","source":["We are going to create a binary classifier which classifies an image as a Dog or a Cat (Probability: 1 = dog, 0 = cat). The dataset can be downloaded from here: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data. The dataset can also be found here: https://ibm.box.com/shared/static/itl0el289mz06py2e6aemehx6lge1rou.zip\n","\n","Now, create a folder named `data` and inside it create subdirectories: `train` and `validation`. Further, create folders named `dogs` and `cats` (as shown below) with 1024 dog and cat images in the `train` directory and 416 dog and cat images in the `validation` directory respectively. Post unzipping the downloaded zip file, use the images from the `train` folder found after unzipping `train.zip`.\n","\n","```python\n","data/\n","    train/\n","        dogs/ # 1024 pictures\n","            dog.1.jpg\n","            dog.2.jpg\n","            ...\n","        cats/ # 1024 pictures\n","            cat.1.jpg\n","            cat.2.jpg\n","            ...\n","    validation/\n","        dogs/ # 416 pictures\n","            dog.1025.jpg\n","            dog.1026.jpg\n","            ...\n","        cats/ # 416 pictures\n","            cat.1025.jpg\n","            cat.1026.jpg\n","            ...\n","```\n","\n","Note: Keras and TensorFlow versions supported by WML are: Keras 2.2.5 with TensorFlow 1.15 backend. This combination is used in this notebook."]},{"metadata":{},"cell_type":"code","source":["!pip install keras==2.2.5\n","!pip install tensorflow==1.15.0\n","!pip install keras_sequential_ascii\n","!pip install numpy\n","!pip install pillow\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras_sequential_ascii import sequential_model_to_ascii_printout\n","from keras import backend as keras_backend\n","from keras import optimizers\n","from keras import applications\n","from keras.models import Model\n","import numpy as np\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Insert project token in notebook and use to upload train and validation zip in data assets and load in notebook"]},{"metadata":{},"cell_type":"code","source":["import zipfile\n","def get_zip(file_name):\n","    '''\n","    file_name = Name of zip file you want to download from object storage\n","    '''\n","    try:\n","        fobj = open(file_name, \"wb\")\n","        fobj.write(project.get_file(file_name).read()) \n","        fobj.close()\n","        z = zipfile.ZipFile(file_name)\n","        z.extractall()\n","    except Exception as e:\n","        print(Exception,e)\n","    else:\n","        print('Files downloaded successfully') "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["get_zip('train.zip')\n","get_zip('validation.zip')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.1 Creating a model"]},{"metadata":{},"cell_type":"code","source":["!ls"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Dimension of the images\n","img_width, img_height = 90, 90\n","\n","train_data_dir = 'train/'\n","validation_data_dir = 'validation/'"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Note: Please modify the paths above accordingly."]},{"metadata":{},"cell_type":"code","source":["# Preprocessing\n","\n","#used to rescale the pixel values from [0, 255] to [0, 1] interval\n","datagen = ImageDataGenerator(rescale=1./255)\n","batch_size = 32\n","\n","# automagically retrieve images and their classes for train and validation sets\n","train_generator = datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(img_width, img_height),\n","        batch_size=batch_size,\n","        class_mode='binary')\n","\n","validation_generator = datagen.flow_from_directory(\n","        validation_data_dir,\n","        target_size=(img_width, img_height),\n","        batch_size=batch_size,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Define Model\n","\n","def base_model():\n","    model = Sequential()\n","    model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Convolution2D(32, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Convolution2D(64, (3, 3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Dropout(0.5))\n","    model.add(Flatten())\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["epochs = 10 # One can increase the no. of epochs to get better accuracy\n","train_samples = 2048\n","validation_samples = 832"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["cnn_n = base_model()\n","cnn_n.summary()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Vizualizing model structure\n","sequential_model_to_ascii_printout(cnn_n)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Train the model\n","cnn_n.fit_generator(\n","    train_generator,\n","    steps_per_epoch=train_samples // batch_size,\n","    epochs=epochs,\n","    validation_steps=validation_samples // batch_size,\n","    validation_data=validation_generator\n",")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["!ls"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["cnn_n.save('dog_cat_cnn.h5')\n","!rm dog_cat_cnn.tar*\n","!tar -czvf dog_cat_cnn.tar.gz dog_cat_cnn.h5\n","!rm dog_cat_cnn.h5"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["scores = cnn_n.evaluate_generator(validation_generator, validation_samples)\n","print(scores)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.2 Storing the model"]},{"metadata":{},"cell_type":"code","source":["import json\n","from ibm_watson_machine_learning import APIClient\n","\n","wml_client = APIClient(WML_CREDENTIALS)\n","wml_client.version"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["wml_client.spaces.list(limit=10)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["WML_SPACE_ID='***' # use space id here\n","wml_client.set.default_space(WML_SPACE_ID)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["MODEL_NAME = \"Dog-Cat binary\""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["wml_client.software_specifications.list()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["software_spec_uid = wml_client.software_specifications.get_id_by_name(\"tensorflow_1.15-py3.6\")\n","print(\"Software Specification ID: {}\".format(software_spec_uid))\n","model_props = {\n","        wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(MODEL_NAME),\n","        wml_client._models.ConfigurationMetaNames.SPACE_UID: WML_SPACE_ID,\n","        wml_client._models.ConfigurationMetaNames.TYPE: \"keras_2.2.5\",\n","        wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n","    }"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(\"Storing model ...\")\n","published_model_details = wml_client.repository.store_model(\n","    model='dog_cat_cnn.tar.gz', \n","    meta_props=model_props, \n",")\n","\n","model_uid = wml_client.repository.get_model_uid(published_model_details)\n","print(\"Done\")\n","print(\"Model ID: {}\".format(model_uid))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.3 Deploying the model"]},{"metadata":{},"cell_type":"code","source":["deployment_details = wml_client.deployments.create(\n","    model_uid, \n","    meta_props={\n","        wml_client.deployments.ConfigurationMetaNames.NAME: \"{}\".format(MODEL_NAME + \" deployment\"),\n","        wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n","    }\n",")\n","scoring_url = wml_client.deployments.get_scoring_href(deployment_details)\n","deployment_uid=wml_client.deployments.get_uid(deployment_details)\n","\n","print(\"Scoring URL:\" + scoring_url)\n","print(\"Model id: {}\".format(model_uid))\n","print(\"Deployment id: {}\".format(deployment_uid))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3. Subscriptions <a id=\"subscription\"></a>"]},{"metadata":{},"cell_type":"markdown","source":["### 3.1 Configuring OpenScale"]},{"metadata":{},"cell_type":"code","source":["!pip install matplotlib\n","!pip install opencv-python\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","import matplotlib.image as mpimg\n","from skimage.transform import resize\n","\n","img = mpimg.imread(\"train/dogs/dog.8022.jpg\")\n","img = resize(img, (90, 90))\n","print(img.shape)\n","plt.imshow(img, cmap='gray')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["from ibm_cloud_sdk_core.authenticators import IAMAuthenticator,BearerTokenAuthenticator\n","\n","from ibm_watson_openscale import *\n","from ibm_watson_openscale.supporting_classes.enums import *\n","from ibm_watson_openscale.supporting_classes import *\n","\n","\n","authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY)\n","#authenticator = BearerTokenAuthenticator(bearer_token=IAM_TOKEN) ## uncomment this line if using IAM token to authenticate\n","wos_client = APIClient(authenticator=authenticator)\n","wos_client.version"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["#DB_CREDENTIALS= {\"hostname\":\"\",\"username\":\"\",\"password\":\"\",\"database\":\"\",\"port\":\"\",\"ssl\":True,\"sslmode\":\"\",\"certificate_base64\":\"\"}\n","DB_CREDENTIALS = None\n","KEEP_MY_INTERNAL_POSTGRES = True"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["data_marts = wos_client.data_marts.list().result.data_marts\n","if len(data_marts) == 0:\n","    if DB_CREDENTIALS is not None:\n","        if SCHEMA_NAME is None: \n","            print(\"Please specify the SCHEMA_NAME and rerun the cell\")\n","\n","        print('Setting up external datamart')\n","        added_data_mart_result = wos_client.data_marts.add(\n","                background_mode=False,\n","                name=\"WOS Data Mart\",\n","                description=\"Data Mart created by WOS tutorial notebook\",\n","                database_configuration=DatabaseConfigurationRequest(\n","                  database_type=DatabaseType.POSTGRESQL,\n","                    credentials=PrimaryStorageCredentialsLong(\n","                        hostname=DB_CREDENTIALS['hostname'],\n","                        username=DB_CREDENTIALS['username'],\n","                        password=DB_CREDENTIALS['password'],\n","                        db=DB_CREDENTIALS['database'],\n","                        port=DB_CREDENTIALS['port'],\n","                        ssl=True,\n","                        sslmode=DB_CREDENTIALS['sslmode'],\n","                        certificate_base64=DB_CREDENTIALS['certificate_base64']\n","                    ),\n","                    location=LocationSchemaName(\n","                        schema_name= SCHEMA_NAME\n","                    )\n","                )\n","             ).result\n","    else:\n","        print('Setting up internal datamart')\n","        added_data_mart_result = wos_client.data_marts.add(\n","                background_mode=False,\n","                name=\"WOS Data Mart\",\n","                description=\"Data Mart created by WOS tutorial notebook\", \n","                internal_database = True).result\n","        \n","    data_mart_id = added_data_mart_result.metadata.id\n","    \n","else:\n","    data_mart_id=data_marts[0].metadata.id\n","    print('Using existing datamart {}'.format(data_mart_id))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["SERVICE_PROVIDER_NAME = \"Watson Machine Learning V2_test\"\n","SERVICE_PROVIDER_DESCRIPTION = \"Added by tutorial WOS notebook.\""],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["service_providers = wos_client.service_providers.list().result.service_providers\n","for service_provider in service_providers:\n","    service_instance_name = service_provider.entity.name\n","    if service_instance_name == SERVICE_PROVIDER_NAME:\n","        service_provider_id = service_provider.metadata.id\n","        wos_client.service_providers.delete(service_provider_id)\n","        print(\"Deleted existing service_provider for WML instance: {}\".format(service_provider_id))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["added_service_provider_result = wos_client.service_providers.add(\n","        name=SERVICE_PROVIDER_NAME,\n","        description=SERVICE_PROVIDER_DESCRIPTION,\n","        service_type=ServiceTypes.WATSON_MACHINE_LEARNING,\n","        deployment_space_id = WML_SPACE_ID,\n","        operational_space_id = \"production\",\n","        credentials=WMLCredentialsCloud(\n","            apikey=CLOUD_API_KEY,      ## use `apikey=IAM_TOKEN` if using IAM_TOKEN to initiate client\n","            url=WML_CREDENTIALS[\"url\"],\n","            instance_id=None\n","        ),\n","        background_mode=False\n","    ).result\n","service_provider_id = added_service_provider_result.metadata.id"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["asset_deployment_details_list = wos_client.service_providers.list_assets(data_mart_id=data_mart_id, service_provider_id=service_provider_id, deployment_space_id = WML_SPACE_ID).result['resources']\n","DEPLOYMENT_NAME=MODEL_NAME + \" deployment\" # use the model name here \n","asset_deployment_details = [asset for asset in asset_deployment_details_list if asset['entity'][\"name\"]==DEPLOYMENT_NAME]\n","\n","if len(asset_deployment_details)>0:\n","    [asset_deployment_details] = asset_deployment_details\n","else:\n","    raise ValueError('deployment with name \"{}\" not found.'.format(DEPLOYMENT_NAME))\n","asset_deployment_details"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["model_asset_details_from_deployment=wos_client.service_providers.get_deployment_asset(data_mart_id=data_mart_id,service_provider_id=service_provider_id,deployment_id=deployment_uid,deployment_space_id=WML_SPACE_ID)\n","model_asset_details_from_deployment"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.2 Subscribe the asset"]},{"metadata":{},"cell_type":"code","source":["subscriptions = wos_client.subscriptions.list().result.subscriptions\n","for subscription in subscriptions:\n","    sub_model_id = subscription.entity.asset.asset_id\n","    if sub_model_id == model_uid:\n","        wos_client.subscriptions.delete(subscription.metadata.id)\n","        print('Deleted existing subscription for model', sub_model_id)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["subscription_details = wos_client.subscriptions.add(\n","        data_mart_id=data_mart_id,\n","        service_provider_id=service_provider_id,\n","        asset=Asset(\n","            asset_id=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"asset_id\"],\n","            name=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"name\"],\n","            url=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"url\"],\n","            asset_type=AssetTypes.MODEL,\n","            input_data_type=InputDataType.UNSTRUCTURED_IMAGE,\n","            problem_type=ProblemType.BINARY_CLASSIFICATION\n","        ),\n","        deployment=AssetDeploymentRequest(\n","            deployment_id=asset_deployment_details['metadata']['guid'],\n","            name=asset_deployment_details['entity']['name'],\n","            deployment_type= DeploymentTypes.ONLINE,\n","            url=asset_deployment_details['metadata']['url']\n","        ),\n","        asset_properties=AssetPropertiesRequest(\n","            probability_fields=['probability']\n","            )\n","    ).result\n","subscription_id = subscription_details.metadata.id\n","subscription_id"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["import time\n","\n","time.sleep(5)\n","payload_data_set_id = None\n","payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n","                                                target_target_id=subscription_id, \n","                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n","if payload_data_set_id is None:\n","    print(\"Payload data set not found. Please check subscription status.\")\n","else:\n","    print(\"Payload data set id: \", payload_data_set_id)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.3 Score the model and get transaction-id"]},{"metadata":{},"cell_type":"code","source":["scoring_data={\"input_data\": [{\"values\": [img.tolist()]}]}\n","predictions = wml_client.deployments.score(deployment_uid, scoring_data)\n","print(predictions)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["wos_client.data_sets.get_records_count(payload_data_set_id)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"explainability\"></a>\n","## 4. Explainability"]},{"metadata":{},"cell_type":"markdown","source":["### 4.1 Configure Explainability"]},{"metadata":{},"cell_type":"code","source":["target = Target(\n","    target_type=TargetTypes.SUBSCRIPTION,\n","    target_id=subscription_id\n",")\n","parameters = {\n","    \"enabled\": True\n","}\n","explainability_details = wos_client.monitor_instances.create(\n","    data_mart_id=data_mart_id,\n","    background_mode=False,\n","    monitor_definition_id=wos_client.monitor_definitions.MONITORS.EXPLAINABILITY.ID,\n","    target=target,\n","    parameters=parameters\n",").result\n","\n","explainability_monitor_id = explainability_details.metadata.id"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 4.2 Get explanation for the transaction"]},{"metadata":{},"cell_type":"code","source":["pl_records_resp = wos_client.data_sets.get_list_of_records(data_set_id=payload_data_set_id, limit=1, offset=0).result\n","scoring_ids = [pl_records_resp[\"records\"][0][\"entity\"][\"values\"][\"scoring_id\"]]\n","print(\"Running explanations on scoring IDs: {}\".format(scoring_ids))\n","explanation_types = [\"lime\", \"contrastive\"]\n","result = wos_client.monitor_instances.explanation_tasks(scoring_ids=scoring_ids, explanation_types=explanation_types).result\n","print(result)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["explanation_task_id=result.to_dict()['metadata']['explanation_task_ids'][0]\n","explanation=wos_client.monitor_instances.get_explanation_tasks(explanation_task_id=explanation_task_id).result.to_dict()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### The explanation images can be obtained using the cells below"]},{"metadata":{},"cell_type":"code","source":["!pip install Pillow\n","from PIL import Image\n","import base64\n","import io\n","\n","pred = explanation[\"entity\"]['explanations'][0]['predictions'][0]\n","print(\"Explanation for {} region:\".format(pred[\"value\"]))\n","\n","img = pred[\"explanation\"][0][\"full_image\"]\n","img_data = base64.b64decode(img)\n","Image.open(io.BytesIO(img_data))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["pred = pred = explanation[\"entity\"]['explanations'][0]['predictions'][1]\n","print(\"Explanation for {} region:\".format(pred[\"value\"]))\n","\n","img = pred[\"explanation\"][0][\"full_image\"]\n","img_data = base64.b64decode(img)\n","Image.open(io.BytesIO(img_data))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}