{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run using with Python 3.7.x with Spark runtime environment. If you are viewing this in Watson Studio and do not see Python 3.7.x with Spark in the upper right corner of your screen, please update the runtime now. It requires service credentials for the following services:\n",
    "\n",
    "<li>Watson OpenScale\n",
    "<li>Watson Machine Learning\n",
    "<li>Cloud Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be33565b-cdbf-4de0-b191-03c666c0fd9a"
   },
   "outputs": [],
   "source": [
    "!pip install pyspark==2.4.0 --no-cache | tail -n 1\n",
    "\n",
    "!pip install --upgrade pandas==0.25.3 --no-cache | tail -n 1\n",
    "!pip install --upgrade requests==2.23 --no-cache | tail -n 1\n",
    "!pip install numpy==1.16.4 --no-cache | tail -n 1\n",
    "!pip install SciPy --no-cache | tail -n 1\n",
    "!pip install lime --no-cache | tail -n 1\n",
    "!pip install pyJWT==2.0.0 --no-cache | tail -n 1\n",
    "\n",
    "!pip install --upgrade ibm-watson-machine-learning --user | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below.\n",
    "\n",
    "**NOTE:** You can also get OpenScale `API_KEY` using IBM CLOUD CLI.\n",
    "\n",
    "How to install IBM Cloud (bluemix) console: [instruction](https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use)\n",
    "\n",
    "How to get api key using console:\n",
    "```\n",
    "bx login --sso\n",
    "bx iam api-key-create 'my_key'\n",
    "```\n",
    "\n",
    "**Cloud object storage details**\n",
    "\n",
    "In next cells, you will need to paste some credentials to Cloud Object Storage. If you haven't worked with COS yet please visit [getting started with COS tutorial](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started). \n",
    "You can find `COS_API_KEY_ID` and `COS_RESOURCE_CRN` variables in **_Service Credentials_** in menu of your COS instance. Used COS Service Credentials must be created with _Role_ parameter set as Writer. Later training data file will be loaded to the bucket of your instance and used as training refecence in subsription.  \n",
    "`COS_ENDPOINT` variable can be found in **_Endpoint_** field of the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "46f58b47aa6a4db48c81e5c3f23a3f28"
   },
   "outputs": [],
   "source": [
    "CLOUD_API_KEY = \"***\"\n",
    "SERVICE_URL= \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "IAM_URL= \"https://iam.bluemix.net/oidc/token\"\n",
    "DB_CREDENTIALS = None\n",
    "KEEP_MY_INTERNAL_POSTGRES = True\n",
    "WML_CREDENTIALS = {\n",
    "    \"apikey\": CLOUD_API_KEY,\n",
    "    \"service_name\":\"Machine Learning-v2_standard\",\n",
    "    \"crn\":\"***\",\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "#Keys for training data\n",
    "COS_API_KEY_ID = \"***\"\n",
    "COS_ENDPOINT = \"https://cos-service.bluemix.net/endpoints\"\n",
    "COS_RESOURCE_INSTANCE_ID = \"***\"\n",
    "BUCKET_NAME = \"***\"\n",
    "FILE_NAME = \"german_credit_data_biased_training.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52f28bc861c3490eb2dfe10926e27909"
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "from IPython.utils import io\n",
    "\n",
    "with io.capture_output() as captured:\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/credit_risk/german_credit_data_biased_training.csv -O german_credit_data_biased_training.csv\n",
    "!ls -lh german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f11c87700cb14fc1a860982fdb28fdd3"
   },
   "outputs": [],
   "source": [
    "#Load and explore data\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "pd_data = pd.read_csv(\"german_credit_data_biased_training.csv\", sep=\",\", header=0)\n",
    "df_data = spark.read.csv(path=\"german_credit_data_biased_training.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "training_data_file_name = \"german_credit_data_biased_training.csv\"\n",
    "df_data.head()\n",
    "\n",
    "df_data.printSchema()\n",
    "print(\"Number of records: \" + str(df_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ade1d0ba9c2477f896df66667c4d9b5"
   },
   "outputs": [],
   "source": [
    "#Create Model\n",
    "spark_df = df_data\n",
    "(train_data, test_data) = spark_df.randomSplit([0.8, 0.2], 24)\n",
    "\n",
    "MODEL_NAME = \"Spark German Risk Model - Training stats\"\n",
    "DEPLOYMENT_NAME = \"Spark German Risk Deployment - - Training stats\"\n",
    "\n",
    "print(\"Number of records for training: \" + str(train_data.count()))\n",
    "print(\"Number of records for evaluation: \" + str(test_data.count()))\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "features = [x for x in spark_df.columns if x != 'Risk']\n",
    "categorical_features = ['CheckingStatus', 'CreditHistory', 'LoanPurpose', 'ExistingSavings', 'EmploymentDuration', 'Sex', 'OthersOnLoan', 'OwnsProperty', 'InstallmentPlans', 'Housing', 'Job', 'Telephone', 'ForeignWorker']\n",
    "categorical_num_features = [x + '_IX' for x in categorical_features]\n",
    "si_list = [StringIndexer(inputCol=x, outputCol=y) for x, y in zip(categorical_features, categorical_num_features)]\n",
    "va_features = VectorAssembler(inputCols=categorical_num_features + [x for x in features if x not in categorical_features], outputCol=\"features\")\n",
    "\n",
    "si_label = StringIndexer(inputCol=\"Risk\", outputCol=\"label\").fit(spark_df)\n",
    "label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_label.labels)\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier(featuresCol=\"features\")\n",
    "feature_filter = SQLTransformer(statement=\"SELECT * FROM __THIS__\")\n",
    "pipeline = Pipeline(stages= si_list + [si_label, va_features, classifier, label_converter, feature_filter])\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "evaluatorDT = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "area_under_curve = evaluatorDT.evaluate(predictions)\n",
    "\n",
    "print(\"areaUnderROC = %g\" % area_under_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e22bc7fdb73c4d91bcbc69ce402af032"
   },
   "outputs": [],
   "source": [
    "# Publish the model\n",
    "\n",
    "import json\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_client = APIClient(WML_CREDENTIALS)\n",
    "wml_client.version\n",
    "\n",
    "WML_SPACE_ID='***' # use space id here\n",
    "wml_client.set.default_space(WML_SPACE_ID)\n",
    "\n",
    "# First remove existing model and deployment\n",
    "deployments_list = wml_client.deployments.get_details()\n",
    "for deployment in deployments_list[\"resources\"]:\n",
    "    model_id = deployment[\"entity\"][\"asset\"][\"id\"]\n",
    "    deployment_id = deployment[\"metadata\"][\"id\"]\n",
    "    if deployment[\"metadata\"][\"name\"] == DEPLOYMENT_NAME:\n",
    "        print(\"Deleting deployment id\", deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "        print(\"Deleting model id\", model_id)\n",
    "        wml_client.repository.delete(model_id)\n",
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81ef45b35cfc43619a58aa15b2ad5a58"
   },
   "outputs": [],
   "source": [
    "training_data_references = [\n",
    "                {\n",
    "                    \"id\": \"product line\",\n",
    "                    \"type\": \"s3\",\n",
    "                    \"connection\": {\n",
    "                        \"access_key_id\": COS_API_KEY_ID,\n",
    "                        \"endpoint_url\": COS_ENDPOINT,\n",
    "                        \"resource_instance_id\":COS_RESOURCE_INSTANCE_ID\n",
    "                    },\n",
    "                    \"location\": {\n",
    "                        \"bucket\": BUCKET_NAME,\n",
    "                        \"path\": FILE_NAME,\n",
    "                    }\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0171e9f746e342598b35fa5c182a44cf"
   },
   "outputs": [],
   "source": [
    "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"spark-mllib_2.4\")\n",
    "print(\"Software Specification ID: {}\".format(software_spec_uid))\n",
    "model_props = {\n",
    "        wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(MODEL_NAME),\n",
    "        #wml_client._models.ConfigurationMetaNames.SPACE_UID: WML_SPACE_ID,\n",
    "        wml_client._models.ConfigurationMetaNames.TYPE: \"mllib_2.4\",\n",
    "        wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n",
    "        wml_client._models.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: training_data_references,\n",
    "        wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"Risk\",\n",
    "    }\n",
    "\n",
    "print(\"Storing model ...\")\n",
    "published_model_details = wml_client.repository.store_model(\n",
    "    model=model, \n",
    "    meta_props=model_props, \n",
    "    training_data=train_data, \n",
    "    pipeline=pipeline)\n",
    "\n",
    "model_uid = wml_client.repository.get_model_uid(published_model_details)\n",
    "print(\"Done\")\n",
    "print(\"Model ID: {}\".format(model_uid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eb971f10aa2433faf4509e7c589e2d0"
   },
   "outputs": [],
   "source": [
    "# Deploy Model\n",
    "deployment_details = wml_client.deployments.create(\n",
    "    model_uid, \n",
    "    meta_props={\n",
    "        wml_client.deployments.ConfigurationMetaNames.NAME: \"{}\".format(DEPLOYMENT_NAME),\n",
    "        wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    ")\n",
    "scoring_url = wml_client.deployments.get_scoring_href(deployment_details)\n",
    "deployment_uid=wml_client.deployments.get_uid(deployment_details)\n",
    "\n",
    "print(\"Scoring URL:\" + scoring_url)\n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a8becb7135c46d2b40991ef3c65c917"
   },
   "outputs": [],
   "source": [
    "#Score Model\n",
    "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n",
    "                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n",
    "                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "                  \"Telephone\", \"ForeignWorker\"]\n",
    "values = [\n",
    "            [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n",
    "             \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"],\n",
    "            [\"no_checking\", 24, \"prior_payments_delayed\", \"furniture\", 4567, \"500_to_1000\", \"1_to_4\", 4, \"male\", \"none\",\n",
    "             4, \"savings_insurance\", 36, \"none\", \"free\", 2, \"management_self-employed\", 1, \"none\", \"yes\"],\n",
    "        ]\n",
    "\n",
    "scoring_payload = {\"input_data\": [{\"fields\": fields, \"values\": values}]}\n",
    "\n",
    "scoring_response = wml_client.deployments.score(deployment_uid, scoring_payload)\n",
    "scoring_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "500418a646474e8180250e940b4ffc75"
   },
   "outputs": [],
   "source": [
    "# Configure deployment in OpenScale\n",
    "\n",
    "#Create wos client\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator,BearerTokenAuthenticator\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY)\n",
    "wos_client = APIClient(authenticator=authenticator)\n",
    "wos_client.version\n",
    "\n",
    "data_mart_id = \"***\"\n",
    "\n",
    "#Create service provider\n",
    "SERVICE_PROVIDER_NAME = \"WML - Training Notebook\"\n",
    "SERVICE_PROVIDER_DESCRIPTION = \"Added by - Training Notebook\"\n",
    "service_providers = wos_client.service_providers.list().result.service_providers\n",
    "for service_provider in service_providers:\n",
    "    service_instance_name = service_provider.entity.name\n",
    "    if service_instance_name == SERVICE_PROVIDER_NAME:\n",
    "        service_provider_id = service_provider.metadata.id\n",
    "        wos_client.service_providers.delete(service_provider_id)\n",
    "        print(\"Deleted existing service_provider for WML instance: {}\".format(service_provider_id))\n",
    "\n",
    "added_service_provider_result = wos_client.service_providers.add(\n",
    "        name=SERVICE_PROVIDER_NAME,\n",
    "        description=SERVICE_PROVIDER_DESCRIPTION,\n",
    "        service_type=ServiceTypes.WATSON_MACHINE_LEARNING,\n",
    "        deployment_space_id = WML_SPACE_ID,\n",
    "        operational_space_id = \"production\",\n",
    "        credentials=WMLCredentialsCloud(\n",
    "            apikey=CLOUD_API_KEY,      ## use `apikey=IAM_TOKEN` if using IAM_TOKEN to initiate client\n",
    "            url=WML_CREDENTIALS[\"url\"],\n",
    "            instance_id=None\n",
    "        ),\n",
    "        background_mode=False\n",
    "    ).result\n",
    "service_provider_id = added_service_provider_result.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d89c35c05fda435f8eb771f56357cb0b"
   },
   "outputs": [],
   "source": [
    "# Generate training stats\n",
    "# Setup info for generating training stats for GCR Model\n",
    "from ibm_watson_openscale.utils.training_stats import TrainingStats\n",
    "service_configuration_support = {\n",
    "    \"enable_fairness\": True,\n",
    "    \"enable_explainability\": True,\n",
    "    \"enable_drift\": True\n",
    "}\n",
    "\n",
    "training_data_info = {\n",
    "    \"class_label\": \"Risk\",\n",
    "    \"feature_columns\": [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\", \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\", \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\", \"Telephone\", \"ForeignWorker\"],\n",
    "    \"categorical_columns\": [\"Sex\", \"OwnsProperty\", \"Telephone\", \"ForeignWorker\"]\n",
    "}\n",
    "\n",
    "fairness_attributes = [{\n",
    "   \"feature\": \"Sex\", \n",
    "   \"majority\": [\n",
    "       \"male\"\n",
    "   ],\n",
    "   \"minority\": [\n",
    "       \"female\"\n",
    "   ],\n",
    "   \"threshold\": 0.8\n",
    "}]\n",
    "\n",
    "model_type = \"binary\"\n",
    "parameters = {\n",
    "    \"favourable_class\" :  [ \"No Risk\" ],\n",
    "    \"unfavourable_class\": [ \"Risk\" ]\n",
    "}\n",
    "min_records = 100\n",
    "\n",
    "# Generate Training stats\n",
    "enable_explainability = service_configuration_support.get('enable_explainability')\n",
    "enable_fairness = service_configuration_support.get('enable_fairness')\n",
    "data_df = pd.read_csv('german_credit_data_biased_training.csv')\n",
    "training_data_stats = None\n",
    "if enable_explainability or enable_fairness:\n",
    "    fairness_inputs = None\n",
    "    if enable_fairness:\n",
    "        fairness_inputs = {\n",
    "                \"fairness_attributes\": fairness_attributes,\n",
    "                \"min_records\" : min_records,\n",
    "                \"favourable_class\" :  parameters[\"favourable_class\"],\n",
    "                \"unfavourable_class\": parameters[\"unfavourable_class\"]\n",
    "            }\n",
    "\n",
    "    input_parameters = {\n",
    "        \"label_column\": training_data_info[\"class_label\"],\n",
    "        \"feature_columns\": training_data_info[\"feature_columns\"],\n",
    "        \"categorical_columns\": training_data_info[\"categorical_columns\"],\n",
    "        \"fairness_inputs\": fairness_inputs,  \n",
    "        \"problem_type\" : model_type  \n",
    "    }\n",
    "\n",
    "    training_stats = TrainingStats(data_df,input_parameters, explain=enable_explainability, fairness=enable_fairness, drop_na=True)\n",
    "    training_data_stats = training_stats.get_training_statistics()\n",
    "    training_data_stats[\"notebook_version\"] = 5.0 \n",
    "\n",
    "print(training_data_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "300e0d45c9714623aa6598fbbae9963c"
   },
   "outputs": [],
   "source": [
    "#Create subscription from training stats\n",
    "prediction_column = \"predictedLabel\"\n",
    "probability_columns = ['probability']\n",
    "#predicted_target_column = \"predicted_label\"\n",
    "predicted_target_column = \"***\"\n",
    "subscription_details = wos_client.subscriptions.add(data_mart_id,\n",
    "    service_provider_id,\n",
    "    asset = None,\n",
    "    deployment = None,\n",
    "    training_data_stats=training_data_stats,\n",
    "    deployment_id = deployment_uid,\n",
    "    deployment_space_id = WML_SPACE_ID,\n",
    "    prediction_field = prediction_column,\n",
    "    predicted_target_field = predicted_target_column,\n",
    "    probability_fields = probability_columns,background_mode = False).result\n",
    "\n",
    "subscription_id = subscription_details.metadata.id\n",
    "print(subscription_details)\n",
    "print(\"Subscription id {}\".format(subscription_id))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45b7319653bd484ca6fa7e7dc6241be5"
   },
   "outputs": [],
   "source": [
    "#Score payload\n",
    "with io.capture_output() as captured:\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/credit_risk/german_credit_feed.json -O german_credit_feed.json\n",
    "!ls -lh german_credit_feed.json\n",
    "\n",
    "import random, time\n",
    "import uuid\n",
    "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n",
    "\n",
    "payload_data_set_id = None\n",
    "payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
    "if payload_data_set_id is None:\n",
    "    print(\"Payload data set not found. Please check subscription status.\")\n",
    "else:\n",
    "    print(\"Payload data set id: \", payload_data_set_id)\n",
    "    \n",
    "\n",
    "with open('german_credit_feed.json', 'r') as scoring_file:\n",
    "    scoring_data = json.load(scoring_file)\n",
    "\n",
    "fields = scoring_data['fields']\n",
    "values = []\n",
    "for _ in range(100):\n",
    "    values.append(random.choice(scoring_data['values']))\n",
    "payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values}]}\n",
    "\n",
    "scoring_response = wml_client.deployments.score(deployment_uid, payload_scoring)\n",
    "time.sleep(5)\n",
    "\n",
    "wos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=[PayloadRecord(\n",
    "                   scoring_id=str(uuid.uuid4()),\n",
    "                   request=payload_scoring,\n",
    "                   response=scoring_response,\n",
    "                   response_time=460\n",
    "               )])\n",
    "time.sleep(5)\n",
    "pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b0f245a54cb4e20abbf370936c40d1b"
   },
   "outputs": [],
   "source": [
    "#Create monitors\n",
    "print(\"Creating monitor instances...\")\n",
    "response = wos_client.monitor_instances.create(monitor_definition_id = None, \n",
    "                        target = None, data_mart_id = data_mart_id, training_data_stats=training_data_stats, \n",
    "                        subscription_id=subscription_id,background_mode=False)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
