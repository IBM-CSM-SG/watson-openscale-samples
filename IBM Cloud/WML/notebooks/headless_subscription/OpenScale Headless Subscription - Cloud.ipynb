{"cells": [{"metadata": {"collapsed": true, "id": "75feab07-55ef-4436-ab6c-48d5c2d133e4"}, "cell_type": "markdown", "source": "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"}, {"metadata": {"id": "b18c0eec7d1c46f6b8fe4c779c478b7b"}, "cell_type": "markdown", "source": "# Working with Watson OpenScale - Headless Subscription"}, {"metadata": {"id": "fc3ebd630e524b3e812e2d17d603e5c9"}, "cell_type": "markdown", "source": "This notebook should be run using with **Python 3.9** runtime environment. \n\nIt requires service credentials for the following services:\n  * Watson OpenScale\n  \n# OpenScale Headless Subscription\n\n## Motivation\nFor security restrictions, or air gap deployment reasons, or firewall restrictions, some Customers are unwilling to expose their Machine Learning model scoring endpoint for external applications like OpenScale for monitoring purposes. The other use is in case of Batch Scoring models, where the scoring happens asynchronously, OpenScale does not have access to the scoring end point. But customers are looking for measuring the performance of their models by logging the payload data and feedback data to OpenScale data mart and thereby configure and evaluate the OpenScale monitors against this data.\n\n## Solution\nThe solution is, with OpenScale, the customers can create a custom ML provider with an empty deployment URL, and there by configure an headless subscription by describing the payload data, followed by logging the payload data and configuring the monitors.\n\n## Workflow\nThe notebook will configure OpenScale with a Headless subscription, where it showcases the following aspects related to Batch Scoring Models:\n\n* Get hold of the training data and create a Pandas dataframe against it.\n* Using the Training Statistics Generation API from OpenScale SDK to generate the training statistics.\n* Create an OpenScale Headless susbcription by including the generated training statistics.\n* Get hold of the output of the batch scoring model, and transform it in the format that OpenScale payload logging API understands.\n     * This is the important step for customers who are using batch scoring models and wants to use OpenScale for monitoring the scored data.\n     * The motivation here is, the batch scoring can happen in any scoring environment. All the OpenScale needs is, fetch the scored data, transform it such that OpenScale understands and log it.\n* Log the payload data by calling the OpenScale DataSets API.\n* Configure Explain Monitor, and generate an explanation on a transaction that is randomly selected from the logged payload data.\n* Configure Fairness Monitor, and perform bias checking on the logged payload data.\n* Log scored label data for performing quality monitor analysis.\n* Configure Quality Monitor and run the quality monitor evaluation.\n* Generate the Drift Archive using the training data, following by configuring the Drift monitor\n* Run Drift evaluation."}, {"metadata": {"id": "262ffb75c64b4523bfda24ea95d4b8f5"}, "cell_type": "markdown", "source": "# Setup <a name=\"setup\"></a>"}, {"metadata": {"id": "3b7c0a42ac1e43139057e5d78abfe075"}, "cell_type": "markdown", "source": "## Package installation"}, {"metadata": {"id": "dc441429a8ad4aada3fa29d81e98e5cf"}, "cell_type": "code", "source": "!pip install --upgrade ibm-watson-machine-learning --user | tail -n 1\n!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1", "execution_count": null, "outputs": []}, {"metadata": {"id": "44f0e2adc53c4f04ba9647b031d88cb9"}, "cell_type": "markdown", "source": "### Action: restart the kernel!"}, {"metadata": {"id": "827d92b4b8e1491e81d23153816f555c"}, "cell_type": "code", "source": "import warnings\nwarnings.filterwarnings('ignore')", "execution_count": null, "outputs": []}, {"metadata": {"id": "f8cdd3fa70d94b9c8e3bea9fc4c65e9f"}, "cell_type": "markdown", "source": "## Configure credentials"}, {"metadata": {}, "cell_type": "code", "source": "CLOUD_API_KEY = \"<Incldue your user API Key here>\"\nIAM_URL=\"https://iam.ng.bluemix.net/oidc/token\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "c470852b2bf14f7caeef5d025c8d64c7"}, "cell_type": "code", "source": "#masked\nWML_CREDENTIALS = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": CLOUD_API_KEY\n}", "execution_count": null, "outputs": []}, {"metadata": {"id": "2963bb1dc0064426839aa24a0ea45150"}, "cell_type": "markdown", "source": "# Get training data statistics"}, {"metadata": {"id": "5abbe05c50fe46f28d692cb36fcfb81d"}, "cell_type": "code", "source": "feature_columns=[\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\ncat_features=[\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\nclass_label = \"Risk\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "636c77c1db4a48da85ed3dd8c6846a45"}, "cell_type": "markdown", "source": "### Get the training data"}, {"metadata": {"id": "d6bbdd544c8d471b91eb5ef7a49cd645"}, "cell_type": "code", "source": "!rm german_credit_data_biased_training.csv\n!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv", "execution_count": null, "outputs": []}, {"metadata": {"id": "3681d34f301c4b559ca8730bf04bf47b"}, "cell_type": "code", "source": "import pandas as pd\ndata_df=pd.read_csv (\"german_credit_data_biased_training.csv\")\ndata_df.head()", "execution_count": null, "outputs": []}, {"metadata": {"id": "b5afc1d931da4c6495a10f497b5c4d52"}, "cell_type": "markdown", "source": "### Generate the training data stats"}, {"metadata": {"id": "49a11fd0e1734d6789c54ebb58977f43"}, "cell_type": "code", "source": "from ibm_watson_openscale.utils.training_stats import TrainingStats", "execution_count": null, "outputs": []}, {"metadata": {"id": "0fbc59045de043258af88cb0d65beef2"}, "cell_type": "code", "source": "input_parameters = {\n    \"label_column\": class_label,\n    \"feature_columns\": feature_columns,\n    \"categorical_columns\": cat_features,\n    \"fairness_inputs\": None,  \n    \"problem_type\" : \"binary\"\n}", "execution_count": null, "outputs": []}, {"metadata": {"id": "b0ddac7d43784eff8f51faac32315fb7"}, "cell_type": "code", "source": "training_stats = TrainingStats(data_df,input_parameters, explain=True, fairness=False, drop_na=True)", "execution_count": null, "outputs": []}, {"metadata": {"id": "69f30aa6275a45c1aabee80b8bc91ba2"}, "cell_type": "code", "source": "config_json = training_stats.get_training_statistics()", "execution_count": null, "outputs": []}, {"metadata": {"id": "ba14fdd0d5fc42148ffa0c70318e0bc0"}, "cell_type": "code", "source": "config_json[\"notebook_version\"] = 5.0", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### This JSON contains the training statistics"}, {"metadata": {"id": "b76d8c0b08f8411884a8d04ceccb4677"}, "cell_type": "code", "source": "config_json", "execution_count": null, "outputs": []}, {"metadata": {"id": "9b0707ac1440466492c933e7069aa015"}, "cell_type": "markdown", "source": "# Configure OpenScale \n\nThe notebook will now import the necessary libraries and set up a Python OpenScale client."}, {"metadata": {"id": "6b03734389aa45fb84321fadc60743e8"}, "cell_type": "code", "source": "from ibm_watson_openscale import APIClient\nfrom ibm_watson_openscale.utils import *\nfrom ibm_watson_openscale.supporting_classes import *\nfrom ibm_watson_openscale.supporting_classes.enums import *\nfrom ibm_watson_openscale.base_classes.watson_open_scale_v2 import *\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator,BearerTokenAuthenticator\n\nimport json\nimport requests\nimport base64\nfrom requests.auth import HTTPBasicAuth\nimport time", "execution_count": null, "outputs": []}, {"metadata": {"id": "3043544c667e49d38cd70855d8ccb5ad"}, "cell_type": "markdown", "source": "## Get a instance of the OpenScale SDK client"}, {"metadata": {"id": "d3d5b4df0a9f4d598a6cbd595700ae53"}, "cell_type": "code", "source": "authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY)\nwos_client = APIClient(authenticator=authenticator)\nwos_client.version", "execution_count": null, "outputs": []}, {"metadata": {"id": "5dbc59b8112144b8a06e6c41a8301f0a"}, "cell_type": "markdown", "source": "## OpenScale DataMart\n\nWatson OpenScale uses a database to store payload and feedback logs and calculated metrics. Here we are using already configured data mart in IBM Cloud."}, {"metadata": {"id": "ca368ed3793443da944e24b8b5e0d281"}, "cell_type": "code", "source": "wos_client.data_marts.show()", "execution_count": null, "outputs": []}, {"metadata": {"id": "2966db92a2994a958136635144f05572"}, "cell_type": "code", "source": "data_marts = wos_client.data_marts.list().result.data_marts\ndata_mart_id=data_marts[0].metadata.id\nprint('Using existing datamart {}'.format(data_mart_id))", "execution_count": null, "outputs": []}, {"metadata": {"id": "5862cdb82a534375b7e290cee338774e"}, "cell_type": "code", "source": "data_mart_details = wos_client.data_marts.list().result.data_marts[0]\ndata_mart_details.to_dict()", "execution_count": null, "outputs": []}, {"metadata": {"id": "b61551bb00fa430b8595748c93a2dfb9"}, "cell_type": "code", "source": "wos_client.service_providers.show()", "execution_count": null, "outputs": []}, {"metadata": {"id": "b1ecf806072240cd89af4324cb844744"}, "cell_type": "markdown", "source": "## Remove existing service provider\n\nMultiple service providers for the same engine instance are avaiable in Watson OpenScale. To avoid multiple service providers of used WML instance in the tutorial notebook the following code deletes existing service provder(s) and then adds new one."}, {"metadata": {"id": "34534f784ac845438b54c6947d227ccb"}, "cell_type": "code", "source": "SERVICE_PROVIDER_NAME = \"OpenScale Headless Service Provider\"\nSERVICE_PROVIDER_DESCRIPTION = \"Added by tutorial WOS notebook to showcase Headless Subscription functionality.\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "ebd41ed59d0a44b3837152bdd67e10fc"}, "cell_type": "code", "source": "service_providers = wos_client.service_providers.list().result.service_providers\nfor service_provider in service_providers:\n    service_instance_name = service_provider.entity.name\n    if service_instance_name == SERVICE_PROVIDER_NAME:\n        service_provider_id = service_provider.metadata.id\n        wos_client.service_providers.delete(service_provider_id)\n        print(\"Deleted existing service_provider for WML instance: {}\".format(service_provider_id))", "execution_count": null, "outputs": []}, {"metadata": {"id": "48cf5770290744c28274669a5af0103b"}, "cell_type": "markdown", "source": "## Add service provider\n\nWatson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model.\n\nNote: Here the service provider is created with empty credentials, meaning no endpoint. Just to demonstrate the use case were we don't need an actual end point serving requests."}, {"metadata": {"id": "2d260d321cad475682aea0857c9b1054"}, "cell_type": "code", "source": "MLCredentials = {}\nadded_service_provider_result = wos_client.service_providers.add(\n        name=SERVICE_PROVIDER_NAME,\n        description=SERVICE_PROVIDER_DESCRIPTION,\n        service_type=ServiceTypes.CUSTOM_MACHINE_LEARNING,\n        operational_space_id = \"production\",\n        credentials=MLCredentials,\n        background_mode=False\n    ).result\nservice_provider_id = added_service_provider_result.metadata.id", "execution_count": null, "outputs": []}, {"metadata": {"id": "eae202864f724fb9880ed31fadf75ac0"}, "cell_type": "code", "source": "print(wos_client.service_providers.get(service_provider_id).result)", "execution_count": null, "outputs": []}, {"metadata": {"id": "09f4993d2caa48269b9832c7e9b145d6"}, "cell_type": "markdown", "source": "## Subscriptions"}, {"metadata": {"id": "2e59906593c44bda97f79a9c35e728f6"}, "cell_type": "markdown", "source": "Remove existing credit risk subscriptions\n\nThis code removes previous subscriptions to the model to refresh the monitors with the new model and new data."}, {"metadata": {"id": "6b97d781684b401095188860bd0a3c96"}, "cell_type": "code", "source": "wos_client.subscriptions.show()", "execution_count": null, "outputs": []}, {"metadata": {"id": "b0d085c8a875458b834992abd3577219"}, "cell_type": "markdown", "source": "## Remove the existing subscription"}, {"metadata": {"id": "3084501d8ecc482282eaa59a7c4327f9"}, "cell_type": "code", "source": "SUBSCRIPTION_NAME = \"GCR Headless Subscription\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "f5ef621a07cb4e468fca6cc62d22595e"}, "cell_type": "code", "source": "subscriptions = wos_client.subscriptions.list().result.subscriptions\nfor subscription in subscriptions:\n    if subscription.entity.asset.name == '[asset] ' + SUBSCRIPTION_NAME:\n        sub_model_id = subscription.metadata.id\n        wos_client.subscriptions.delete(subscription.metadata.id)\n        print('Deleted existing subscription for model', sub_model_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "d117477d751b4d6380d2feceac14450e"}, "cell_type": "markdown", "source": "This code creates the model subscription in OpenScale using the Python client API. Note that we need to provide the model unique identifier, and some information about the model itself."}, {"metadata": {"id": "e2df727978ef4fbe8062c30a63944b6d"}, "cell_type": "code", "source": "print(\"Data Mart ID: \" + data_mart_id)\nprint(\"Service Provide ID: \" + service_provider_id)\nimport uuid\nasset_id = str(uuid.uuid4())\nasset_name = '[asset] ' + SUBSCRIPTION_NAME\nurl = None\n\nasset_deployment_id = str(uuid.uuid4())\nasset_deployment_name = asset_name", "execution_count": null, "outputs": []}, {"metadata": {"id": "1de20abba6d84c6c8ba84cd3ed3bc96e"}, "cell_type": "code", "source": "prediction_column = \"prediction\"\nprobability_columns = ['probability']\npredicted_target_column = \"prediction\"\nsubscription_details = wos_client.subscriptions.add(data_mart_id,\n    service_provider_id,\n    asset=Asset(\n        asset_id=asset_id,\n        name=asset_name,\n        url=url,\n        asset_type=AssetTypes.MODEL,\n        input_data_type=InputDataType.STRUCTURED,\n        problem_type=ProblemType.BINARY_CLASSIFICATION\n    ),\n    deployment=None,    \n    training_data_stats=config_json,\n    prediction_field = prediction_column,\n    predicted_target_field = predicted_target_column,\n    probability_fields = probability_columns,background_mode = False\n    ,deployment_name = asset_name\n    ).result\n\nsubscription_id = subscription_details.metadata.id\nprint(\"Subscription id {}\".format(subscription_id))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "wos_client.subscriptions.get(subscription_id).result.to_dict()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### The following code fetches the data set id, against which we would be performing the payload logging"}, {"metadata": {"id": "9dee41fc8ae2407483f7d08f7ecd9663"}, "cell_type": "code", "source": "import time\n\ntime.sleep(5)\npayload_data_set_id = None\npayload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n                                                target_target_id=subscription_id, \n                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\nif payload_data_set_id is None:\n    print(\"Payload data set not found. Please check subscription status.\")\nelse:\n    print(\"Payload data set id:\", payload_data_set_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "2d75c57ab8914d70acdc3ed523675b1b"}, "cell_type": "markdown", "source": "## Push a payload record to setup the required schemas in the subscription\n\nThis is the location where one needs to fetch the output of the batch scoring model and construct the payload as per the OpenScale Payload Logging format.\n\nNote : No scoring is done against the model. The PayloadRecord is constructed with the request and response from the model/deployment."}, {"metadata": {"id": "7ea1d04fe73a452685847cfc4f780256"}, "cell_type": "markdown", "source": "## Scoring Request Payload"}, {"metadata": {"id": "cb53d8ad950146bda2fd9ad017112835"}, "cell_type": "code", "source": "scoring_request =   {\n        \"fields\": [\n            \"CheckingStatus\",\n            \"LoanDuration\",\n            \"CreditHistory\",\n            \"LoanPurpose\",\n            \"LoanAmount\",\n            \"ExistingSavings\",\n            \"EmploymentDuration\",\n            \"InstallmentPercent\",\n            \"Sex\",\n            \"OthersOnLoan\",\n            \"CurrentResidenceDuration\",\n            \"OwnsProperty\",\n            \"Age\",\n            \"InstallmentPlans\",\n            \"Housing\",\n            \"ExistingCreditsCount\",\n            \"Job\",\n            \"Dependents\",\n            \"Telephone\",\n            \"ForeignWorker\",\n            \"Risk\"\n        ],\n        \"values\": [\n            [\n                \"no_checking\",\n                28,\n                \"outstanding_credit\",\n                \"appliances\",\n                5990,\n                \"500_to_1000\",\n                \"greater_7\",\n                5,\n                \"male\",\n                \"co-applicant\",\n                3,\n                \"car_other\",\n                55,\n                \"none\",\n                \"free\",\n                2,\n                \"skilled\",\n                2,\n                \"yes\",\n                \"yes\",\n                \"Risk\"\n            ],\n            [\n                \"greater_200\",\n                22,\n                \"all_credits_paid_back\",\n                \"car_used\",\n                3376,\n                \"less_100\",\n                \"less_1\",\n                3,\n                \"female\",\n                \"none\",\n                2,\n                \"car_other\",\n                32,\n                \"none\",\n                \"own\",\n                1,\n                \"skilled\",\n                1,\n                \"none\",\n                \"yes\",\n                \"No Risk\"\n            ],\n            [\n                \"no_checking\",\n                39,\n                \"credits_paid_to_date\",\n                \"vacation\",\n                6434,\n                \"unknown\",\n                \"greater_7\",\n                5,\n                \"male\",\n                \"none\",\n                4,\n                \"car_other\",\n                39,\n                \"none\",\n                \"own\",\n                2,\n                \"skilled\",\n                2,\n                \"yes\",\n                \"yes\",\n                \"Risk\"\n            ],\n            [\n                \"0_to_200\",\n                20,\n                \"credits_paid_to_date\",\n                \"furniture\",\n                2442,\n                \"less_100\",\n                \"unemployed\",\n                3,\n                \"female\",\n                \"none\",\n                1,\n                \"real_estate\",\n                42,\n                \"none\",\n                \"own\",\n                1,\n                \"skilled\",\n                1,\n                \"none\",\n                \"yes\",\n                \"No Risk\"\n            ],\n            [\n                \"greater_200\",\n                4,\n                \"all_credits_paid_back\",\n                \"education\",\n                4206,\n                \"less_100\",\n                \"unemployed\",\n                1,\n                \"female\",\n                \"none\",\n                3,\n                \"savings_insurance\",\n                27,\n                \"none\",\n                \"own\",\n                1,\n                \"management_self-employed\",\n                1,\n                \"none\",\n                \"yes\",\n                \"No Risk\"\n            ],\n            [\n                \"greater_200\",\n                23,\n                \"credits_paid_to_date\",\n                \"car_used\",\n                2963,\n                \"greater_1000\",\n                \"greater_7\",\n                4,\n                \"male\",\n                \"none\",\n                4,\n                \"car_other\",\n                46,\n                \"none\",\n                \"own\",\n                2,\n                \"skilled\",\n                1,\n                \"none\",\n                \"yes\",\n                \"Risk\"\n            ],\n            [\n                \"no_checking\",\n                31,\n                \"prior_payments_delayed\",\n                \"vacation\",\n                2673,\n                \"500_to_1000\",\n                \"1_to_4\",\n                3,\n                \"male\",\n                \"none\",\n                2,\n                \"real_estate\",\n                35,\n                \"stores\",\n                \"rent\",\n                1,\n                \"skilled\",\n                2,\n                \"none\",\n                \"yes\",\n                \"Risk\"\n            ],\n            [\n                \"no_checking\",\n                37,\n                \"prior_payments_delayed\",\n                \"other\",\n                6971,\n                \"500_to_1000\",\n                \"1_to_4\",\n                3,\n                \"male\",\n                \"none\",\n                3,\n                \"savings_insurance\",\n                54,\n                \"none\",\n                \"own\",\n                2,\n                \"skilled\",\n                1,\n                \"yes\",\n                \"yes\",\n                \"Risk\"\n            ],\n            [\n                \"no_checking\",\n                14,\n                \"all_credits_paid_back\",\n                \"car_new\",\n                1525,\n                \"500_to_1000\",\n                \"4_to_7\",\n                3,\n                \"male\",\n                \"none\",\n                4,\n                \"real_estate\",\n                33,\n                \"none\",\n                \"own\",\n                1,\n                \"skilled\",\n                1,\n                \"none\",\n                \"yes\",\n                \"No Risk\"\n            ],\n            [\n                \"less_0\",\n                10,\n                \"prior_payments_delayed\",\n                \"furniture\",\n                4037,\n                \"less_100\",\n                \"4_to_7\",\n                3,\n                \"male\",\n                \"none\",\n                3,\n                \"savings_insurance\",\n                31,\n                \"none\",\n                \"rent\",\n                1,\n                \"skilled\",\n                1,\n                \"none\",\n                \"yes\",\n                \"Risk\"\n            ]\n        ]\n    }", "execution_count": null, "outputs": []}, {"metadata": {"id": "3e469b9bf6cc4baa855d4954b28b5ff7"}, "cell_type": "markdown", "source": "## Scoring Response Payload"}, {"metadata": {"id": "12303ea22a7146b2ab77b898a3fdffe2"}, "cell_type": "code", "source": "scoring_response = {\n    \"predictions\": [\n        {\n            \"fields\": [\n                \"prediction\",\n                \"probability\"\n            ],\n            \"values\": [\n                [\n                    \"Risk\",\n                    [\n                        0.104642951112211,\n                        0.895357048887789\n                    ]\n                ],\n                [\n                    \"No Risk\",\n                    [\n                        0.892112895920181,\n                        0.10788710407981907\n                    ]\n                ],\n                [\n                    \"Risk\",\n                    [\n                        0.4863177905287259,\n                        0.5136822094712741\n                    ]\n                ],\n                [\n                    \"No Risk\",\n                    [\n                        0.980811537315731,\n                        0.01918846268426898\n                    ]\n                ],\n                [\n                    \"No Risk\",\n                    [\n                        0.9053052561083984,\n                        0.09469474389160164\n                    ]\n                ],\n                [\n                    \"No Risk\",\n                    [\n                        0.5315146773053994,\n                        0.4684853226946007\n                    ]\n                ],\n                [\n                    \"No Risk\",\n                    [\n                        0.7689466209701616,\n                        0.23105337902983833\n                    ]\n                ],\n                [\n                    \"Risk\",\n                    [\n                        0.41317664143643873,\n                        0.5868233585635613\n                    ]\n                ],\n                [\n                    \"No Risk\",\n                    [\n                        0.9190247585206522,\n                        0.08097524147934775\n                    ]\n                ],\n                [\n                    \"No Risk\",\n                    [\n                        0.781841942776921,\n                        0.21815805722307902\n                    ]\n                ]\n            ]\n        }\n    ]\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Construct the payload using the scoring_request and scoring_response and then log the records"}, {"metadata": {"id": "edb0cf12b0164869879f0ea101f520e0"}, "cell_type": "code", "source": "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n\nrecords_list=[]\nfor x in range(10):\n    pl_record = PayloadRecord(request=scoring_request, response=scoring_response)\n    records_list.append(pl_record)\n\nwos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=records_list)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Make sure the records reached the payload logging table inside the OpenScale DataMart."}, {"metadata": {"id": "933b5220cd9d4c5681f54308ce266ade"}, "cell_type": "code", "source": "time.sleep(5)\npl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\nprint(\"Number of records in the payload logging table: {}\".format(pl_records_count))\nif pl_records_count == 0:\n    raise Exception(\"Payload logging did not happen!\")", "execution_count": null, "outputs": []}, {"metadata": {"id": "9383640e6ca5477b9d0f2f3c9ea46885"}, "cell_type": "markdown", "source": "## Fetch the subscription details to confirm output data schemas are setup"}, {"metadata": {"id": "f8fa3697195d4f02895b042e6add28b4"}, "cell_type": "code", "source": "wos_client.subscriptions.get(subscription_id).result.to_dict()", "execution_count": null, "outputs": []}, {"metadata": {"id": "c9154f4c69ad4c4db3c14d8f0bc6236c"}, "cell_type": "markdown", "source": "# Explainability Monitor Configuration\nFrom the notebook, connect to the training data base, get stats, generate perturbations, perform offline scoring against the customer model, create an explain archive and save this archive to data mart.\n\n* Only Local explanations are supported.\n* For contrastive explanations, as scoring is needed and because it is headless subscription without any deployment URL, contrastive explanations are not supported."}, {"metadata": {"id": "abd67154b29049c584b8cef8b12d01db"}, "cell_type": "markdown", "source": "## Generate perturbations over the training stats"}, {"metadata": {"id": "da8d35ac24b64873ac4b4d8790cc07b9"}, "cell_type": "code", "source": "from ibm_wos_utils.explainability.utils.perturbations import Perturbations   \nperturbations=Perturbations(training_stats=config_json.get(\"explainability_configuration\"), problem_type=\"binary\", perturbations_count=5000)\nperturbs_df = perturbations.generate_perturbations()", "execution_count": null, "outputs": []}, {"metadata": {"id": "32b628f9591f4f4e823b912e45c739f3"}, "cell_type": "markdown", "source": "## Construct the scoring payload on the generated perturbations"}, {"metadata": {"id": "bea840c627dd47e09e0a82c0fe67a759"}, "cell_type": "code", "source": "cols_to_remove = [class_label]\ncols_to_remove", "execution_count": null, "outputs": []}, {"metadata": {"id": "cf10c60d1f2a4a2ebfffd667932d93f2"}, "cell_type": "code", "source": "def get_scoring_payload(no_of_records_to_score = 1):\n    for col in cols_to_remove:\n        if col in perturbs_df.columns:\n            del perturbs_df[col] \n\n    fields = perturbs_df.columns.tolist()\n    values = perturbs_df[fields].values.tolist()\n\n    payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values[:no_of_records_to_score]}]}  \n    return payload_scoring", "execution_count": null, "outputs": []}, {"metadata": {"id": "d994cbe80ec54972bdfcfc5366699b97"}, "cell_type": "code", "source": "def sample_scoring(no_of_records_to_score = 1):\n    records_list=[]\n    payload_scoring = get_scoring_payload(no_of_records_to_score)\n    scoring_response = wml_client.deployments.score(deployment_uid, payload_scoring)\n    print('Single record scoring result:', '\\n fields:', scoring_response['predictions'][0]['fields'], '\\n values: ', scoring_response['predictions'][0]['values'][0])\n    #print(json.dumps(scoring_response, indent=None))\n    return payload_scoring, scoring_response", "execution_count": null, "outputs": []}, {"metadata": {"id": "aac1dc85b142421290d5096d9646982b"}, "cell_type": "markdown", "source": "## Score the perturbations\n\nHere, this notebook uses a credit risk model deployment in WML. This can be replaced with the scoring engine of your choice, but making sure the scoring response is in the format that OpenScale understands for monitor processing."}, {"metadata": {"id": "a8cfbd042be041cd8f807ada9a55c477"}, "cell_type": "code", "source": "import json\nfrom ibm_watson_machine_learning import APIClient\n\nwml_client = APIClient(WML_CREDENTIALS)\nwml_client.version", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Listing all the available spaces"}, {"metadata": {}, "cell_type": "code", "source": "wml_client.spaces.list(limit=10)", "execution_count": null, "outputs": []}, {"metadata": {"id": "56e8566e7dd64d778bce3623b35ad834"}, "cell_type": "code", "source": "space_uid = '<Include the space id>'", "execution_count": null, "outputs": []}, {"metadata": {"id": "d0c28b3f1dea46e0b1e1b52ea6b90a73"}, "cell_type": "code", "source": "wml_client.set.default_space(space_uid)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "deployments_list = wml_client.deployments.get_details()\nfor deployment in deployments_list[\"resources\"]:\n    deployment_id = deployment[\"metadata\"][\"id\"]\n    deployment_name = deployment[\"entity\"][\"name\"]\n    print(deployment_name + ' : ' + deployment_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "deployment_uid = '<Include the deployment id>'", "execution_count": null, "outputs": []}, {"metadata": {"id": "2d6db6823c0b43738f277442c780a060"}, "cell_type": "code", "source": "payload_scoring, scoring_response = sample_scoring(no_of_records_to_score = 5000)", "execution_count": null, "outputs": []}, {"metadata": {"id": "b10c5bdd411a4292b93712ba6a6e2c48"}, "cell_type": "markdown", "source": "## Construct the explain archive"}, {"metadata": {"id": "320778faa84046258ebacfb495fb3ac8"}, "cell_type": "code", "source": "fields = scoring_response['predictions'][0]['fields']\nvalues = scoring_response['predictions'][0]['values']\nscored_data = pd.DataFrame(values, columns = fields)", "execution_count": null, "outputs": []}, {"metadata": {"id": "3883894e48f04fca8f1244ca09c2f987"}, "cell_type": "code", "source": "probabilities = [pro for pro in scored_data['probability']]\npredictions = [pre for pre in scored_data['prediction']]\n\nexplain_perturb_payload = {'probabilities' : probabilities,\n                            'predictions' : predictions}", "execution_count": null, "outputs": []}, {"metadata": {"id": "62c1c37efc514cef805ab893c38a38d4"}, "cell_type": "code", "source": "with open('explain_scoring_response.json', 'w') as outfile:\n    json.dump(explain_perturb_payload, outfile)", "execution_count": null, "outputs": []}, {"metadata": {"id": "5fed94a6e294421880af25ad6170eb1a"}, "cell_type": "code", "source": "import tarfile\nfrom io import BytesIO\nfile_name = 'explain_scoring_response.tar.gz'\n\nwith tarfile.open(file_name, 'w:gz') as archive:\n    archive.add('explain_scoring_response.json')\n\nwith open(file_name, 'rb') as fh:\n    buf = BytesIO(fh.read())\nbuf = open(file_name, mode=\"rb\").read()    ", "execution_count": null, "outputs": []}, {"metadata": {"id": "f53e45aa9848403e83089a093e2bdd40"}, "cell_type": "markdown", "source": "## Upload the explain archive to OpenScale data mart"}, {"metadata": {"id": "d506960881a6436a93b090dc9ce9a2e6"}, "cell_type": "code", "source": "with open(\"explain_scoring_response.tar.gz\", mode=\"rb\") as perturbations_tar:\n    wos_client.monitor_instances.upload_explainability_archive(subscription_id=subscription_id, archive=perturbations_tar)\n\nprint(\"Uploaded perturbations scoring response archive successfully.\")", "execution_count": null, "outputs": []}, {"metadata": {"id": "d6b2e9d4c4fe498c86eb6bc170be72e7"}, "cell_type": "markdown", "source": "## Enable the Explainability monitor"}, {"metadata": {"id": "7cc25b98422c44bf8d02b253d3246f07"}, "cell_type": "code", "source": "print(\"Creating monitor instances...\")\nresponse = wos_client.monitor_instances.create(monitor_definition_id = None, \n                        target = None, data_mart_id = data_mart_id, training_data_stats=config_json, \n                        subscription_id=subscription_id, background_mode=False)\nprint(response)", "execution_count": null, "outputs": []}, {"metadata": {"id": "2d1c3230c47946e780d450d12132d083"}, "cell_type": "markdown", "source": "### Trigger a local explanation."}, {"metadata": {"id": "7ec4862bc34442429bb196699a6496cb"}, "cell_type": "code", "source": "payload_data = wos_client.data_sets.get_list_of_records(data_set_id=payload_data_set_id,output_type='pandas').result\nexplanation_types = [\"lime\"]\n\nscoring_ids = payload_data.head(1)['scoring_id'].tolist()\nresult = wos_client.monitor_instances.explanation_tasks(scoring_ids=scoring_ids, explanation_types=explanation_types, subscription_id=subscription_id).result\n\nexplanation_task_ids=result.metadata.explanation_task_ids\nexplanation_task_ids", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Wait for the local explanation to complete."}, {"metadata": {"id": "08118985179d4f698b1c7dd7f3d140a7"}, "cell_type": "code", "source": "def finish_explanation_tasks(sample_size = 1):\n    finished_explanations = []\n    finished_explanation_task_ids = []\n    \n    # Check for the explanation task status for finished status. \n    # If it is in-progress state, then sleep for some time and check again. \n    # Perform the same for couple of times, so that all tasks get into finished state.\n    for i in range(0, 5):\n        # for each explanation\n        print('iteration ' + str(i))\n        \n        #check status for all explanation tasks\n        for explanation_task_id in explanation_task_ids:\n            if explanation_task_id not in finished_explanation_task_ids:\n                result = wos_client.monitor_instances.get_explanation_tasks(explanation_task_id=explanation_task_id, subscription_id=subscription_id ).result\n                print(explanation_task_id + ' : ' + result.entity.status.state)\n                if (result.entity.status.state == 'finished' or result.entity.status.state == 'error') and explanation_task_id not in finished_explanation_task_ids:\n                    finished_explanation_task_ids.append(explanation_task_id)\n                    finished_explanations.append(result)\n\n\n        # if there is altest one explanation task that is not yet completed, then sleep for sometime, \n        # and check for all those tasks, for which explanation is not yet completeed.\n        \n        if len(finished_explanation_task_ids) != sample_size:\n            print('sleeping for some time..')\n            time.sleep(10)\n        else:\n            break\n                    \n    return finished_explanations", "execution_count": null, "outputs": []}, {"metadata": {"id": "c913ceab53ad4aa1a9da66a2f6ad3820"}, "cell_type": "markdown", "source": "### Find the explain task status"}, {"metadata": {"id": "3917c1c26e93442182a9830d956dfed1"}, "cell_type": "code", "source": "finished_explanations = finish_explanation_tasks(1)", "execution_count": null, "outputs": []}, {"metadata": {"id": "d2aae51b02a248228474c84950ac1c95"}, "cell_type": "markdown", "source": "## Print explain task output"}, {"metadata": {"id": "eef3927e9f634bdd923c318ebab2e6c1"}, "cell_type": "code", "source": "for result in finished_explanations:\n    print(result)", "execution_count": null, "outputs": []}, {"metadata": {"id": "09c318b2e5c54b839eb6f3ac8b247ca4"}, "cell_type": "markdown", "source": "# Fairness configuration"}, {"metadata": {"id": "3d73b84061cc494a8ea5a19e897b981f"}, "cell_type": "markdown", "source": "The code below configures fairness monitoring for our model. It turns on monitoring for two features, sex and age. In each case, we must specify:\n    \nWhich model feature to monitor One or more majority groups, which are values of that feature that we expect to receive a higher percentage of favorable outcomes One or more minority groups, which are values of that feature that we expect to receive a higher percentage of unfavorable outcomes The threshold at which we would like OpenScale to display an alert if the fairness measurement falls below (in this case, 80%) Additionally, we must specify which outcomes from the model are favourable outcomes, and which are unfavourable. We must also provide the number of records OpenScale will use to calculate the fairness score. In this case, OpenScale's fairness monitor will run hourly, but will not calculate a new fairness rating until at least 100 records have been added. Finally, to calculate fairness, OpenScale must perform some calculations on the training data, so we provide the dataframe containing the data."}, {"metadata": {"id": "f59d4d82ca7d4aa7978e7a777416c281"}, "cell_type": "markdown", "source": "### Create Fairness Monitor Instance"}, {"metadata": {"id": "1864c05c176f4a718e36059628d7f0ed"}, "cell_type": "code", "source": "target = Target(\n    target_type=TargetTypes.SUBSCRIPTION,\n    target_id=subscription_id\n\n)\nparameters = {\n    \"features\": [\n        {\"feature\": \"Sex\",\n         \"majority\": ['female'],\n         \"minority\": ['male'],\n         \"correlated_attributes\": []\n         }\n    ],\n    \"favourable_class\": [\"No Risk\"],\n    \"unfavourable_class\": [\"Risk\"],\n    \"min_records\": 95\n}\nthresholds = [{\n    \"metric_id\": \"fairness_value\",\n    \"specific_values\": [\n        {\n            \"applies_to\": [{\n                \"key\": \"feature\",\n                \"type\": \"tag\",\n                \"value\": \"Sex\"\n            }],\n            \"value\": 98\n        }\n    ],\n    \"type\": \"lower_limit\",\n    \"value\": 80.0\n}]\n\nfairness_monitor_details = wos_client.monitor_instances.create(\n    data_mart_id=data_mart_id,\n    background_mode=False,\n    monitor_definition_id=wos_client.monitor_definitions.MONITORS.FAIRNESS.ID,\n    target=target,\n    parameters=parameters,\n    thresholds=thresholds).result", "execution_count": null, "outputs": []}, {"metadata": {"id": "50d51a9c080d4a55aed61a79b768b0df"}, "cell_type": "code", "source": "fairness_monitor_instance_id = fairness_monitor_details.metadata.id", "execution_count": null, "outputs": []}, {"metadata": {"id": "ae999234ea39453e82c74169ac7d74a8"}, "cell_type": "markdown", "source": "### Get Fairness Monitor Instance"}, {"metadata": {"id": "812cdeea78af4ca8ba38ea5f07efd990"}, "cell_type": "code", "source": "wos_client.monitor_instances.show()", "execution_count": null, "outputs": []}, {"metadata": {"id": "03e3bf32570d4bb5816b860d58db555d"}, "cell_type": "markdown", "source": "### Get run details\nIn case of production subscription, initial monitoring run is triggered internally. Checking its status"}, {"metadata": {"id": "6af6098a23384c93b88f113f6b5024b7"}, "cell_type": "code", "source": "runs = wos_client.monitor_instances.list_runs(fairness_monitor_instance_id, limit=1).result.to_dict()\nfairness_monitoring_run_id = runs[\"runs\"][0][\"metadata\"][\"id\"]\nrun_status = None\nwhile(run_status not in [\"finished\", \"error\"]):\n    run_details = wos_client.monitor_instances.get_run_details(fairness_monitor_instance_id, fairness_monitoring_run_id).result.to_dict()\n    run_status = run_details[\"entity\"][\"status\"][\"state\"]\n    print('run_status: ', run_status)\n    if run_status in [\"finished\", \"error\"]:\n        break\n    time.sleep(10)", "execution_count": null, "outputs": []}, {"metadata": {"id": "13e80670e3474f5581ef4de516e19d70"}, "cell_type": "markdown", "source": "### Fairness run output"}, {"metadata": {"id": "8b9b909ce8104fc4ad51ed3b7f388c5e"}, "cell_type": "code", "source": "wos_client.monitor_instances.get_run_details(fairness_monitor_instance_id, fairness_monitoring_run_id).result.to_dict()", "execution_count": null, "outputs": []}, {"metadata": {"id": "cd87098c263343c88302caf6c6a7fe67"}, "cell_type": "code", "source": "wos_client.monitor_instances.show_metrics(monitor_instance_id=fairness_monitor_instance_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "864da785a62b4bb782651e7a89b04837"}, "cell_type": "markdown", "source": "# Quality monitoring and feedback logging"}, {"metadata": {"id": "2cfa62a024bd4951827899957267c0ae"}, "cell_type": "markdown", "source": "## Enable quality monitoring\n\nThe code below waits ten seconds to allow the payload logging table to be set up before it begins enabling monitors. First, it turns on the quality (accuracy) monitor and sets an alert threshold of 70%. OpenScale will show an alert on the dashboard if the model accuracy measurement (area under the curve, in the case of a binary classifier) falls below this threshold.\n\nThe second paramater supplied, min_records, specifies the minimum number of feedback records OpenScale needs before it calculates a new measurement. The quality monitor runs hourly, but the accuracy reading in the dashboard will not change until an additional 50 feedback records have been added, via the user interface, the Python client, or the supplied feedback endpoint."}, {"metadata": {"id": "315eff5637f3499789af5bff0e952c27"}, "cell_type": "code", "source": "import time\n\n#time.sleep(10)\ntarget = Target(\n        target_type=TargetTypes.SUBSCRIPTION,\n        target_id=subscription_id\n)\nparameters = {\n    \"min_feedback_data_size\": 100\n}\nthresholds = [\n                {\n                    \"metric_id\": \"area_under_roc\",\n                    \"type\": \"lower_limit\",\n                    \"value\": .80\n                }\n            ]\nquality_monitor_details = wos_client.monitor_instances.create(\n    data_mart_id=data_mart_id,\n    background_mode=False,\n    monitor_definition_id=wos_client.monitor_definitions.MONITORS.QUALITY.ID,\n    target=target,\n    parameters=parameters,\n    thresholds=thresholds\n).result", "execution_count": null, "outputs": []}, {"metadata": {"id": "4854f81d452a4e41804bf69fffd23793"}, "cell_type": "code", "source": "quality_monitor_instance_id = quality_monitor_details.metadata.id\nquality_monitor_instance_id", "execution_count": null, "outputs": []}, {"metadata": {"id": "37088b2299714a2d8a7ff123dca6f67b"}, "cell_type": "markdown", "source": "## Get feedback logging dataset ID"}, {"metadata": {"id": "eb0240054545408e886dc81e11073107"}, "cell_type": "code", "source": "feedback_dataset_id = None\nfeedback_dataset = wos_client.data_sets.list(type=DataSetTypes.FEEDBACK, \n                                                target_target_id=subscription_id, \n                                                target_target_type=TargetTypes.SUBSCRIPTION).result\nfeedback_dataset_id = feedback_dataset.data_sets[0].metadata.id\nif feedback_dataset_id is None:\n    print(\"Feedback data set not found. Please check quality monitor status.\")", "execution_count": null, "outputs": []}, {"metadata": {"id": "d3440261ffba406589148380ed0296a9"}, "cell_type": "code", "source": "feedback_dataset_id", "execution_count": null, "outputs": []}, {"metadata": {"id": "37812e16eee44208819af7dec9d14986"}, "cell_type": "code", "source": "feedback_payload = {\n    \"fields\": [\n        \"CheckingStatus\",\n        \"LoanDuration\",\n        \"CreditHistory\",\n        \"LoanPurpose\",\n        \"LoanAmount\",\n        \"ExistingSavings\",\n        \"EmploymentDuration\",\n        \"InstallmentPercent\",\n        \"Sex\",\n        \"OthersOnLoan\",\n        \"CurrentResidenceDuration\",\n        \"OwnsProperty\",\n        \"Age\",\n        \"InstallmentPlans\",\n        \"Housing\",\n        \"ExistingCreditsCount\",\n        \"Job\",\n        \"Dependents\",\n        \"Telephone\",\n        \"ForeignWorker\",\n        \"Risk\",\n        \"_original_probability\",\n        \"_original_prediction\",\n        \"_debiased_probability\",\n        \"_debiased_prediction\"        \n    ],\n    \"values\": [\n        [\n            \"less_0\",\n            18,\n            \"credits_paid_to_date\",\n            \"car_new\",\n            462,\n            \"less_100\",\n            \"1_to_4\",\n            2,\n            \"female\",\n            \"none\",\n            2,\n            \"savings_insurance\",\n            37,\n            \"stores\",\n            \"own\",\n            2,\n            \"skilled\",\n            1,\n            \"none\",\n            \"yes\",\n            \"No Risk\",\n            [\n                0.767955712021837,\n                0.23204428797816307\n            ],\n            \"Risk\",\n            [\n                0.767955712021837,\n                0.23204428797816307\n            ],\n            \"Risk\"\n        ],\n        [\n            \"less_0\",\n            15,\n            \"prior_payments_delayed\",\n            \"furniture\",\n            250,\n            \"less_100\",\n            \"1_to_4\",\n            2,\n            \"male\",\n            \"none\",\n            3,\n            \"real_estate\",\n            28,\n            \"none\",\n            \"own\",\n            2,\n            \"skilled\",\n            1,\n            \"yes\",\n            \"no\",\n            \"No Risk\",\n            [\n                0.7419002139563244,\n                0.25809978604367556\n            ],\n            \"Risk\",\n            [\n                0.767955712021837,\n                0.23204428797816307\n            ],\n            \"Risk\"\n        ],\n        [\n            \"0_to_200\",\n            28,\n            \"credits_paid_to_date\",\n            \"retraining\",\n            3693,\n            \"less_100\",\n            \"greater_7\",\n            3,\n            \"male\",\n            \"none\",\n            2,\n            \"savings_insurance\",\n            32,\n            \"none\",\n            \"own\",\n            1,\n            \"skilled\",\n            1,\n            \"none\",\n            \"yes\",\n            \"No Risk\",\n            [\n                0.6935080115729353,\n                0.3064919884270647\n            ],\n            \"Risk\",\n            [\n                0.8,\n                0.2\n            ],\n            \"Risk\"\n        ],\n        [\n            \"no_checking\",\n            28,\n            \"prior_payments_delayed\",\n            \"education\",\n            6235,\n            \"500_to_1000\",\n            \"greater_7\",\n            3,\n            \"male\",\n            \"none\",\n            3,\n            \"unknown\",\n            57,\n            \"none\",\n            \"own\",\n            2,\n            \"skilled\",\n            1,\n            \"none\",\n            \"yes\",\n            \"Risk\",\n            [\n                0.331110352092386,\n                0.668889647907614\n            ],\n            \"Risk\",\n            [\n                0.9,\n                0.1\n            ],\n            \"Risk\"\n        ],\n        [\n            \"no_checking\",\n            32,\n            \"outstanding_credit\",\n            \"vacation\",\n            9604,\n            \"500_to_1000\",\n            \"greater_7\",\n            6,\n            \"male\",\n            \"co-applicant\",\n            5,\n            \"unknown\",\n            57,\n            \"none\",\n            \"free\",\n            2,\n            \"skilled\",\n            2,\n            \"yes\",\n            \"yes\",\n            \"Risk\",\n            [\n                0.11270206970758759,\n                0.8872979302924124\n            ],\n            \"Risk\",\n            [\n                0.1,\n                0.9\n            ],\n            \"Risk\"\n        ],\n        [\n            \"no_checking\",\n            9,\n            \"prior_payments_delayed\",\n            \"car_new\",\n            1032,\n            \"100_to_500\",\n            \"4_to_7\",\n            3,\n            \"male\",\n            \"none\",\n            4,\n            \"savings_insurance\",\n            41,\n            \"none\",\n            \"own\",\n            1,\n            \"management_self-employed\",\n            1,\n            \"none\",\n            \"yes\",\n            \"No Risk\",\n            [\n                0.6704819620865308,\n                0.32951803791346923\n            ],\n            \"Risk\",\n            [\n                0.767955712021837,\n                0.23204428797816307\n            ],\n            \"Risk\"\n        ],\n        [\n            \"less_0\",\n            16,\n            \"credits_paid_to_date\",\n            \"vacation\",\n            3109,\n            \"less_100\",\n            \"4_to_7\",\n            3,\n            \"female\",\n            \"none\",\n            1,\n            \"car_other\",\n            36,\n            \"none\",\n            \"own\",\n            2,\n            \"skilled\",\n            1,\n            \"none\",\n            \"yes\",\n            \"No Risk\",\n            [\n                0.6735810290914039,\n                0.3264189709085961\n            ],\n            \"Risk\",\n            [\n                0.6,\n                0.4\n            ],\n            \"Risk\"\n        ],\n        [\n            \"0_to_200\",\n            11,\n            \"credits_paid_to_date\",\n            \"car_new\",\n            4553,\n            \"less_100\",\n            \"less_1\",\n            3,\n            \"female\",\n            \"none\",\n            3,\n            \"savings_insurance\",\n            22,\n            \"none\",\n            \"own\",\n            1,\n            \"management_self-employed\",\n            1,\n            \"none\",\n            \"yes\",\n            \"No Risk\",\n            [\n                0.637964656269084,\n                0.362035343730916\n            ],\n            \"Risk\",\n            [\n                0.767955712021837,\n                0.23204428797816307\n            ],\n            \"Risk\"\n        ],\n        [\n            \"no_checking\",\n            35,\n            \"outstanding_credit\",\n            \"appliances\",\n            7138,\n            \"500_to_1000\",\n            \"greater_7\",\n            5,\n            \"male\",\n            \"co-applicant\",\n            4,\n            \"unknown\",\n            49,\n            \"none\",\n            \"free\",\n            2,\n            \"skilled\",\n            2,\n            \"yes\",\n            \"yes\",\n            \"Risk\",\n            [\n                0.11270206970758759,\n                0.8872979302924124\n            ],\n            \"Risk\",\n            [\n                0.767955712021837,\n                0.23204428797816307\n            ],\n            \"Risk\"\n        ],\n        [\n            \"less_0\",\n            5,\n            \"all_credits_paid_back\",\n            \"car_new\",\n            1523,\n            \"less_100\",\n            \"unemployed\",\n            2,\n            \"female\",\n            \"none\",\n            2,\n            \"real_estate\",\n            19,\n            \"none\",\n            \"rent\",\n            1,\n            \"management_self-employed\",\n            1,\n            \"none\",\n            \"yes\",\n            \"No Risk\",\n            [\n                0.7304597628653227,\n                0.26954023713467745\n            ],\n            \"Risk\",\n            [\n                0.767955712021837,\n                0.23204428797816307\n            ],\n            \"Risk\"\n        ]\n    ]\n}", "execution_count": null, "outputs": []}, {"metadata": {"id": "f0240e34c1fe4b4c931406954b410eb1"}, "cell_type": "code", "source": "import urllib3, requests, json\ndef generate_access_token():\n    headers={}\n    headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n    headers[\"Accept\"] = \"application/json\"\n    auth = HTTPBasicAuth(\"bx\", \"bx\")\n    data = {\n        \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n        \"apikey\": CLOUD_API_KEY\n    }\n    response = requests.post(IAM_URL, data=data, headers=headers, auth=auth)\n    json_data = response.json()\n    iam_access_token = json_data['access_token']\n    return iam_access_token", "execution_count": null, "outputs": []}, {"metadata": {"id": "c9917cd69a9d4b22a8a27f0ebb1423da"}, "cell_type": "code", "source": "headers = {}\nheaders[\"Content-Type\"] = \"application/json\"\nheaders[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\nWOS_GUID=data_mart_id", "execution_count": null, "outputs": []}, {"metadata": {"id": "8e2cf6e368ee414d8ffe8f178bbf4294"}, "cell_type": "markdown", "source": "### Store the feedback payload using the data sets API\n\nThere are two ways OpenScale APIs can be used - a) using OpenScale Python SDK b) using OpenScale REST APIs.\n\nFor any reason if in the customer environment one cannot use the SDK, then the alternative is to use the REST APIs. The below cell demostrates to invoke one such OpenScale REST API, to log the feedback records to the OpenScale DataMart."}, {"metadata": {"id": "f2a376a7df1642c189f1920445012f6a"}, "cell_type": "code", "source": "DATASETS_STORE_RECORDS_URL =   \"https://api.aiopenscale.cloud.ibm.com/openscale/{0}/v2/data_sets/{1}/records\".format(data_mart_id, feedback_dataset_id)\nfor x in range(10):\n    response = requests.post(DATASETS_STORE_RECORDS_URL, json=feedback_payload, headers=headers, verify=False)\n    json_data = response.json()\n    print(json_data)", "execution_count": null, "outputs": []}, {"metadata": {"id": "373ef04bff5b4772833b6b1120fd2314"}, "cell_type": "markdown", "source": "### Wait for sometime, and make sure the records have reached to data sets related table."}, {"metadata": {"id": "88c162434aa24e018a131ca10c188d5c"}, "cell_type": "code", "source": "time.sleep(10)\nDATASETS_STORE_RECORDS_URL =   \"https://api.aiopenscale.cloud.ibm.com/openscale/{0}/v2/data_sets/{1}/records?limit={2}&include_total_count={3}\".format(data_mart_id, feedback_dataset_id, 1, \"true\")\nresponse = requests.get(DATASETS_STORE_RECORDS_URL, headers=headers, verify=False)\njson_data = response.json()\nprint(json_data['total_count'])", "execution_count": null, "outputs": []}, {"metadata": {"id": "96bdfc3a376d44a585432889b033f060"}, "cell_type": "markdown", "source": "## Run Quality Monitor"}, {"metadata": {"id": "adfd17e52f3e4c4f88c4fe8016c4d6b0"}, "cell_type": "code", "source": "run_details = wos_client.monitor_instances.run(monitor_instance_id=quality_monitor_instance_id, background_mode=False).result", "execution_count": null, "outputs": []}, {"metadata": {"id": "9067577f098247d6bceb49f733097b75"}, "cell_type": "code", "source": "wos_client.monitor_instances.show_metrics(monitor_instance_id=quality_monitor_instance_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "37c0967b10a1460c817d7eebe273d549"}, "cell_type": "markdown", "source": "# Drift Configuration"}, {"metadata": {"id": "033d1ee83da3498ab2b1981ea9d3f144"}, "cell_type": "markdown", "source": "## Create the drift detection model archive"}, {"metadata": {"id": "5d37de5934d5473e81d1b1b946b2676a"}, "cell_type": "code", "source": "def score(training_data_frame):\n      \n    #The data type of the label column and prediction column should be same .\n    #User needs to make sure that label column and prediction column array should have the same unique class labels\n    prediction_column_name = \"predictedLabel\"\n    probability_column_name = \"probability\"\n        \n    feature_columns = list(training_data_frame.columns)\n    training_data_rows = training_data_frame[feature_columns].values.tolist()\n    \n    payload_scoring = {\n      wml_client.deployments.ScoringMetaNames.INPUT_DATA: [{\n           \"fields\": feature_columns,\n           \"values\": [x for x in training_data_rows]\n      }]\n    }\n\n    score = wml_client.deployments.score(deployment_uid, payload_scoring)\n    score_predictions = score.get('predictions')[0]\n\n    prob_col_index = list(score_predictions.get('fields')).index(probability_column_name)\n    predict_col_index = list(score_predictions.get('fields')).index(prediction_column_name)\n\n    if prob_col_index < 0 or predict_col_index < 0:\n        raise Exception(\"Missing prediction/probability column in the scoring response\")\n\n    import numpy as np\n    probability_array = np.array([value[prob_col_index] for value in score_predictions.get('values')])\n    prediction_vector = np.array([value[predict_col_index] for value in score_predictions.get('values')])\n\n    return probability_array, prediction_vector", "execution_count": null, "outputs": []}, {"metadata": {"id": "018d764554af48c887e28f33f3c6ece9"}, "cell_type": "code", "source": "import pandas as pd\ntraining_data_frame=pd.read_csv(\"german_credit_data_biased_training.csv\")\ntraining_data_frame.head()", "execution_count": null, "outputs": []}, {"metadata": {"id": "226adfb1fd1c4e628582a894746bf9be"}, "cell_type": "code", "source": "probability_array, prediction_vector = score(training_data_frame)\nprediction_vector", "execution_count": null, "outputs": []}, {"metadata": {"id": "f2d3db7dd4cc489d8ab484f396ac5085"}, "cell_type": "code", "source": "from ibm_wos_utils.drift.drift_trainer import DriftTrainer\n\ndrift_detection_input = {\n    \"feature_columns\": feature_columns,\n    \"categorical_columns\":cat_features,\n    \"label_column\": class_label,\n    \"problem_type\": \"binary\"\n}\n\ndrift_trainer = DriftTrainer(training_data_frame, drift_detection_input)\ndrift_trainer.generate_drift_detection_model(score, batch_size=training_data_frame.shape[0], check_for_ddm_quality=False)\ndrift_trainer.learn_constraints(\n    two_column_learner_limit=200, categorical_unique_threshold=0.8, user_overrides=[])\ndrift_trainer.create_archive()", "execution_count": null, "outputs": []}, {"metadata": {"id": "aec8b83613724a8f8d3360fe46df5c0a"}, "cell_type": "markdown", "source": "### Enable the drift monitor"}, {"metadata": {"id": "3b9117de377943948135cc3717ccd500"}, "cell_type": "markdown", "source": "In the following code cell, type a path to the drift configuration tar ball."}, {"metadata": {"id": "a34f983fbb2a472083a3dfadc5eb9c65"}, "cell_type": "code", "source": "wos_client.monitor_instances.upload_drift_model(\n    model_path=\"drift_detection_model.tar.gz\",\n    data_mart_id=data_mart_id,\n    subscription_id=subscription_id\n).result", "execution_count": null, "outputs": []}, {"metadata": {"id": "8fe2184b01ff4b1888fe77bf9a5abbb6"}, "cell_type": "markdown", "source": "In the following code cell, default values are set for the drift monitor. You can change the default values by updating the values in the parameters section. The min_samples parameter controls the number of records that triggers the drift monitor to run. The drift_threshold parameter sets the threshold in decimal format for the drift percentage to trigger an alert. The train_drift_model parameter controls whether to re-train the model based on the drift analysis."}, {"metadata": {"id": "f7f34159743e492b84e447fa1a3e4dac"}, "cell_type": "code", "source": "import time\n\ntarget = Target(\n    target_type=TargetTypes.SUBSCRIPTION,\n    target_id=subscription_id\n)\n\nparameters = {\n    \"min_samples\": 100,\n    \"drift_threshold\": 0.05,\n    \"train_drift_model\": False\n}\n\ndrift_monitor_details = wos_client.monitor_instances.create(\n    data_mart_id=data_mart_id,\n    monitor_definition_id=wos_client.monitor_definitions.MONITORS.DRIFT.ID,\n    target=target,\n    parameters=parameters\n).result\n\ndrift_monitor_instance_id = drift_monitor_details.metadata.id\nprint(drift_monitor_details)", "execution_count": null, "outputs": []}, {"metadata": {"id": "cd5009b2aae34f8d858881c4d579a55f"}, "cell_type": "markdown", "source": "## Check monitor instance status"}, {"metadata": {"id": "c6bb901ae33e4712a379e5c905c11dfc"}, "cell_type": "code", "source": "drift_status = None\n\nwhile drift_status not in (\"active\", \"error\"):\n    monitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=drift_monitor_instance_id).result\n    drift_status = monitor_instance_details.entity.status.state\n    if drift_status not in (\"active\", \"error\"):\n        print(datetime.utcnow().strftime('%H:%M:%S'), drift_status)\n        time.sleep(30)\n\nprint(datetime.utcnow().strftime('%H:%M:%S'), drift_status)", "execution_count": null, "outputs": []}, {"metadata": {"id": "946296294929480180f1ab60b0336dfa"}, "cell_type": "markdown", "source": "## Run an on-demand evaluation"}, {"metadata": {"id": "41c8a3d5548e4d97b8a87c69e31e9520"}, "cell_type": "code", "source": "# Check Drift monitor instance details\n\nmonitor_instance_details = wos_client.monitor_instances.get(monitor_instance_id=drift_monitor_instance_id).result\nprint(monitor_instance_details)", "execution_count": null, "outputs": []}, {"metadata": {"id": "a0cd274bbe47418583ca873246683e73"}, "cell_type": "code", "source": "# Trigger on-demand run\n\nmonitoring_run_details = wos_client.monitor_instances.run(monitor_instance_id=drift_monitor_instance_id).result\nmonitoring_run_id=monitoring_run_details.metadata.id\n\nprint(monitoring_run_details)", "execution_count": null, "outputs": []}, {"metadata": {"id": "806c9a4638934d13b347f686670996ca"}, "cell_type": "code", "source": "# Check run status\n\ndrift_run_status = None\nwhile drift_run_status not in (\"finished\", \"error\"):\n    monitoring_run_details = wos_client.monitor_instances.get_run_details(monitor_instance_id=drift_monitor_instance_id, monitoring_run_id=monitoring_run_id).result\n    drift_run_status = monitoring_run_details.entity.status.state\n    if drift_run_status not in (\"finished\", \"error\"):\n        print(datetime.utcnow().strftime(\"%H:%M:%S\"), drift_run_status)\n        time.sleep(30)\n        \nprint(datetime.utcnow().strftime(\"%H:%M:%S\"), drift_run_status)", "execution_count": null, "outputs": []}, {"metadata": {"id": "e5e0387d165e423fb62edda0d6021ed9"}, "cell_type": "markdown", "source": "## Display drift metrics"}, {"metadata": {"id": "1b089c7ecbea4a8382f63d162c53773f"}, "cell_type": "code", "source": "wos_client.monitor_instances.show_metrics(monitor_instance_id=drift_monitor_instance_id)", "execution_count": null, "outputs": []}, {"metadata": {"id": "03db2a8db59c417b89348fa82c665260"}, "cell_type": "markdown", "source": "<!-- ### Run on-demand Fairness\nIf you would like to peform an on-demand fairness check, then we need to score a fresh set of data with meta-fields, so that they would be used for indirect bias checking. So the below two cells will score and make sure these records are reached to payload logging table. -->"}, {"metadata": {"id": "48c3a513d1a44de782f747574f431d66"}, "cell_type": "markdown", "source": "Author: Ravi Chamarthy (ravi.chamarthy@in.ibm.com)"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}