{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "130546d4-d72c-46f1-a506-246ace42ad56"
   },
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6d32920-c6f8-4df6-91a7-925640a9920a"
   },
   "source": [
    "# Working with a custom metrics provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab7073b7-baf8-48ba-b9fb-e39e497596aa"
   },
   "source": [
    "This notebook demonstrates how to configure the custom monitor and custom metrics deployment by using IBM Watson OpenScale. This notebook should be run in a Watson Studio project, using **IBM Runtime 22.1 on Python 3.9 XS** runtime environment. **If you are viewing this in Watson Studio and do not see the required runtime env in the upper right corner of your screen, please update the runtime now.**. It requires service credentials for the following services:\n",
    "  * Watson OpenScale\n",
    "  * Watson Machine Learning\n",
    "\n",
    "  \n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "  1. [Set up your environment.](#setup)\n",
    "  1. [Create the custom metrics provider - python function.](#provider)\n",
    "  1. [Register the custom metrics provider and create a deployment.](#deployment)\n",
    "  1. [Configure Watson OpenScale](#config)\n",
    "  1. [Create the integrated system for the custom metrics provider.](#custom)\n",
    "  1. [Set up the custom monitor definition and instance.](#instance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c3c7fcc-8701-45f3-ab34-af1b093b590c"
   },
   "source": [
    "## 1. Set up your environment. <a name=\"setup\"></a>\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "8b4212ee-4116-4a47-a586-f0997df1ec53"
   },
   "source": [
    "### Install the  `ibm-watson-machine-learning` and `ibm-watson-openscale` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eb75b61-93b5-4139-96d5-fae98c8c9173",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-watson-machine-learning | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cd55a125-14e4-440c-a2ee-c58813d75f9e"
   },
   "source": [
    "### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2abe81f0-cd47-4fe0-9b5c-505712c17752",
    "scrolled": true
   },
   "source": [
    "### Credentials for IBM Cloud Pak for Data\n",
    "To authenticate, in the following code boxes, replace the sample data with your own credentials. Get the information from your system administrator or through the Cloud Pak for Data dashboard.\n",
    "\n",
    "\n",
    "### Obtaining your Watson OpenScale credentials\n",
    "\n",
    "You can retrieve the URL by running the following command: `oc get route -n namespace1 --no-headers | awk '{print $2}'` Replace the `namespace1` variable with your namespace.\n",
    "\n",
    "You should have been assigned a username and password when you were added to the Cloud Pak for Data system. You might need to ask either your database administrator or your system administrator for some of the information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9698f02e94014d8fa21fb55686dda7c8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f499be0-0ed7-46c9-9bf4-753c2529525f"
   },
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# Paste your Watson OpenScale credentials into the following section and then run this cell.\n",
    "############################################################################################\n",
    "CLOUD_API_KEY = \"<Your Cloud IAM API Key>\"\n",
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"https://api.aiopenscale.cloud.ibm.com\",\n",
    "    \"apikey\": CLOUD_API_KEY\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAM_URL=\"https://iam.ng.bluemix.net/oidc/token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update your WML instance url\n",
    "WML_CREDENTIALS = {\n",
    "        \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "        \"apikey\": CLOUD_API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a13f3095f2e34d428a5538fcdac3d8d2"
   },
   "source": [
    "\n",
    "### Enter your Watson OpenScale GUID.\n",
    "\n",
    "For most systems, the default GUID is already entered for you. You would only need to update this particular entry if the GUID was changed from the default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36cc22be8776482cad5d42710a8f7794"
   },
   "outputs": [],
   "source": [
    "#Update your Watson OpenScale datamart id.\n",
    "WOS_GUID=\"<IBM Watson OpenScale DataMart Id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "498971eeef99499f8fcd21ff2daac45c"
   },
   "source": [
    "### Define the Watson OpenScale subscription to which the custom metrics have to be sent.\n",
    "\n",
    "Create a subscription from the Watson Openscale UI or SDK to configure custom metrics. You can configure custom metrics for the subscriptions that have predefined monitors, such as fairness, quality, or drift or without predefined monitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c97612076c64480a94169fa8f73ce26b"
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Paste your Subscription in the following field and then run this cell.\n",
    "####################################################################\n",
    "\n",
    "subscription_id = \"<Subscription Id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b88f68ac232493385c8baa50ef22e4f"
   },
   "source": [
    "### Python function details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fc70a115fc042eb85ba551eebcb0152"
   },
   "outputs": [],
   "source": [
    "PYTHON_FUNCTION_NAME = 'Custom Metrics Provider Batch Function'\n",
    "DEPLOYMENT_NAME = 'Custom Metrics Provider Batch Deployment'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5411c368b0a46cb8c81483ca729686c"
   },
   "source": [
    "### OpenScale Custom Metrics Provider name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68b70fc65238456d8717656175cb3197"
   },
   "outputs": [],
   "source": [
    "CUSTOM_METRICS_PROVIDER_NAME = \"Custom Metrics Provider\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c986710412246c78db2b041a5b21544"
   },
   "source": [
    "### OpenSale Custom Monitor name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3a4214d9b1564cdfb948e62351276673"
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# UPDATE your custom monitor name in the following field and then run this cell.\n",
    "####################################################################\n",
    "CUSTOM_MONITOR_NAME = 'Sample Model Performance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51dab6f2e41045f38ead783922814c0a"
   },
   "source": [
    "## 2. Create the custom metrics provider - Python function. <a name=\"provider\"></a>\n",
    "\n",
    "The Python function receives the required variables, such as the `datamart_id`, `monitor_instance_id`, `monitor_id`, `monitor_instance_parameters` and `subscription_id` from the Watson OpenScale service when it is invoked by the custom monitor. \n",
    "\n",
    "In the Python function, add your own logic to compute the custom metrics in the `get_metrics` method, publish the metrics to the Watson Openscale service and update the status of the run to the `finished` state in the custom monitor instance.\n",
    "\n",
    "Update the `WOS_CREDENTIALS` in the Python function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7ec6979ce114f528246ba99e8619090"
   },
   "outputs": [],
   "source": [
    "#wml_python_function\n",
    "parms = {\n",
    "        \"iam_url\": IAM_URL,\n",
    "        \"url\": WOS_CREDENTIALS[\"url\"],\n",
    "        \"apikey\": WOS_CREDENTIALS[\"apikey\"]\n",
    "    }\n",
    "def custom_metrics_provider(parms = parms):\n",
    "    \n",
    "    import json\n",
    "    import requests\n",
    "    import base64\n",
    "    from requests.auth import HTTPBasicAuth\n",
    "    import time\n",
    "    import uuid    \n",
    "    \n",
    "    headers = {}\n",
    "    headers[\"Content-Type\"] = \"application/json\"\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "    \n",
    "    \n",
    "    # Get the access token\n",
    "    def get_access_token():\n",
    "        url = parms['iam_url']\n",
    "        headers={}\n",
    "        headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n",
    "        headers[\"Accept\"] = \"application/json\"\n",
    "        data = {\n",
    "             \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n",
    "             \"apikey\": parms['apikey']\n",
    "        }\n",
    "        response = requests.post(url, data=data, headers=headers)\n",
    "        json_data = response.json()\n",
    "        access_token = json_data['access_token']\n",
    "        return access_token\n",
    "    \n",
    "    def get_feedback_dataset_id(access_token, data_mart_id, subscription_id):\n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        DATASETS_URL =  parms[\"url\"] + \"/openscale/{0}/v2/data_sets?target.target_id={1}&target.target_type=subscription&type=feedback\".format(data_mart_id, subscription_id)\n",
    "        response = requests.get(DATASETS_URL, headers=headers, verify=False)\n",
    "        json_data = response.json()\n",
    "        feedback_dataset_id = None\n",
    "        if \"data_sets\" in json_data and len(json_data[\"data_sets\"]) > 0:\n",
    "            feedback_dataset_id = json_data[\"data_sets\"][0][\"metadata\"][\"id\"]\n",
    "        \n",
    "        return feedback_dataset_id\n",
    "    \n",
    "    def get_feedback_data(access_token, data_mart_id, feedback_dataset_id):\n",
    "        json_data = None\n",
    "        if feedback_dataset_id is not None:\n",
    "            headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "            DATASETS_STORE_RECORDS_URL = parms[\"url\"] + \"/openscale/{0}/v2/data_sets/{1}/records?limit={2}&format=list\".format(data_mart_id, feedback_dataset_id, 100)\n",
    "            response = requests.get(DATASETS_STORE_RECORDS_URL, headers=headers, verify=False)\n",
    "            json_data = response.json()\n",
    "            return json_data\n",
    "    \n",
    "    #Update the run status to Finished in the custom monitor instance\n",
    "    def update_monitor_instance(base_url, access_token, custom_monitor_instance_id, payload):\n",
    "        monitor_instance_url = base_url + '/v2/monitor_instances/' + custom_monitor_instance_id + '?update_metadata_only=true'\n",
    "        \n",
    "        patch_payload  = [\n",
    "            {\n",
    "                \"op\": \"replace\",\n",
    "                \"path\": \"/parameters\",\n",
    "                \"value\": payload\n",
    "            }\n",
    "        ]\n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        response = requests.patch(monitor_instance_url, headers=headers, json = patch_payload, verify=False)\n",
    "        monitor_response = response.json()\n",
    "        return response.status_code, monitor_response\n",
    "    \n",
    "    #Add your code to compute the custom metrics. \n",
    "    def get_metrics(access_token, data_mart_id, subscription_id):\n",
    "        #Add the logic here to compute the metrics. Use the below metric names while creating the custom monitor definition\n",
    "        feedback_dataset_id = get_feedback_dataset_id(access_token, data_mart_id, subscription_id)\n",
    "        json_data = get_feedback_data(access_token, data_mart_id, feedback_dataset_id)\n",
    "        gender_less40_fav_prediction_ratio = 0\n",
    "        if json_data is not None:\n",
    "            fields = json_data['records'][0]['fields']\n",
    "            values = json_data['records'][0]['values']\n",
    "            import pandas as pd\n",
    "            feedback_data = pd.DataFrame(values, columns = fields)\n",
    "            female_less40_fav_prediction = len(feedback_data.query('Sex == \\'female\\' & Age <= 40 & Risk == \\'No Risk\\''))\n",
    "            male_less40_fav_prediction = len(feedback_data.query('Sex == \\'male\\' & Age <= 40 & Risk == \\'No Risk\\''))\n",
    "            gender_less40_fav_prediction_ratio = female_less40_fav_prediction / male_less40_fav_prediction\n",
    "\n",
    "        metrics = {\"specificity\": 1.2, \"sensitivity\": 0.85, \"gender_less40_fav_prediction_ratio\": gender_less40_fav_prediction_ratio, \"region\": \"us-south\"}\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "        \n",
    "    # Publishes the Custom Metrics to OpenScale\n",
    "    def publish_metrics(base_url, access_token, data_mart_id, subscription_id, custom_monitor_id, custom_monitor_instance_id, custom_monitoring_run_id, timestamp):\n",
    "        # Generate an monitoring run id, where the publishing happens against this run id\n",
    "        custom_metrics = get_metrics(access_token, data_mart_id, subscription_id)\n",
    "        measurements_payload = [\n",
    "                  {\n",
    "                    \"timestamp\": timestamp,\n",
    "                    \"run_id\": custom_monitoring_run_id,\n",
    "                    \"metrics\": [custom_metrics]\n",
    "                  }\n",
    "                ]\n",
    "        headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "        measurements_url = base_url + '/v2/monitor_instances/' + custom_monitor_instance_id + '/measurements'\n",
    "        response = requests.post(measurements_url, headers=headers, json = measurements_payload, verify=False)\n",
    "        published_measurement = response.json()\n",
    "     \n",
    "        return response.status_code, published_measurement\n",
    "        \n",
    "    \n",
    "    def publish( input_data ):\n",
    "        import datetime\n",
    "        timestamp = datetime.datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "        \n",
    "        payload_array = input_data.get(\"input_data\")[0].get(\"values\")\n",
    "        payload = payload_array[0]\n",
    "        data_mart_id = payload['data_mart_id']\n",
    "        subscription_id = payload['subscription_id']\n",
    "        custom_monitor_id = payload['custom_monitor_id']\n",
    "        custom_monitor_instance_id = payload['custom_monitor_instance_id']\n",
    "        custom_monitor_instance_params  = payload['custom_monitor_instance_params']\n",
    "\n",
    "        base_url = parms['url'] + '/openscale' + '/' + data_mart_id\n",
    "        access_token = get_access_token()\n",
    "        \n",
    "        published_measurements = []\n",
    "        error_msgs = []\n",
    "        \n",
    "        custom_monitoring_run_id = custom_monitor_instance_params[\"run_details\"][\"run_id\"]\n",
    "        try:\n",
    "            status_code, published_measurement = publish_metrics(base_url, access_token, data_mart_id, subscription_id, custom_monitor_id, custom_monitor_instance_id, custom_monitoring_run_id, timestamp)\n",
    "            if int(status_code) in [200, 201, 202]:\n",
    "                custom_monitor_instance_params[\"run_details\"][\"run_status\"] = \"finished\"\n",
    "                published_measurements.append(published_measurement)\n",
    "            else:\n",
    "                custom_monitor_instance_params[\"run_details\"][\"run_status\"] = \"error\"\n",
    "                custom_monitor_instance_params[\"run_details\"][\"run_error_msg\"] = published_measurement\n",
    "                error_msgs.append(published_measurement)\n",
    "                    \n",
    "            custom_monitor_instance_params[\"last_run_time\"] = timestamp\n",
    "            status_code, response = update_monitor_instance(base_url, access_token, custom_monitor_instance_id, custom_monitor_instance_params)\n",
    "            if not int(status_code) in [200, 201, 202]:\n",
    "                error_msgs.append(response)\n",
    "                \n",
    "        except Exception as ex:\n",
    "            error_msgs.append(str(ex))\n",
    "        if len(error_msgs) == 0:\n",
    "            response_payload = {\n",
    "                \"predictions\" : [{ \n",
    "                    \"values\" : published_measurements\n",
    "                }]\n",
    "\n",
    "            }\n",
    "        else:\n",
    "            response_payload = {\n",
    "                \"predictions\":[],\n",
    "                \"errors\": error_msgs\n",
    "            }\n",
    "        \n",
    "        return response_payload\n",
    "        \n",
    "    return publish\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47683fe263944fafb25f856214b1ec70"
   },
   "source": [
    "## 3. Register the custom metrics provider and create a deployment. <a name=\"deployment\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8948f9b03e849d9aba1f74d7e7830c3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_client = APIClient(WML_CREDENTIALS)\n",
    "wml_client.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15601ba7120748b9902f57ca107067b6"
   },
   "outputs": [],
   "source": [
    "wml_client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f9a983b13d84b40bf2b5544ac11d078"
   },
   "outputs": [],
   "source": [
    "space_id = \"<Update your space id>\"\n",
    "wml_client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31a721ab-5858-40a8-b773-0819455343ef"
   },
   "source": [
    "### Remove existing function and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fec89e6e-01ef-4d8f-9da2-143c40525696"
   },
   "outputs": [],
   "source": [
    "deployments_list = wml_client.deployments.get_details()\n",
    "for deployment in deployments_list[\"resources\"]:\n",
    "    model_id = deployment[\"entity\"][\"asset\"][\"id\"]\n",
    "    deployment_id = deployment[\"metadata\"][\"id\"]\n",
    "    if deployment[\"metadata\"][\"name\"] == DEPLOYMENT_NAME or deployment[\"metadata\"][\"name\"] == DEPLOYMENT_NAME + '_WRAPPER':\n",
    "        print(\"Deleting deployment id\", deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "        print(\"Deleting model id\", model_id)\n",
    "        wml_client.repository.delete(model_id)\n",
    "\n",
    "wml_client.repository.list_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dc634c8321444c7aeab616fac9d0158"
   },
   "source": [
    "### Get the software spec id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3360f3287764b5a8f357d36eef914b4"
   },
   "outputs": [],
   "source": [
    "software_spec_id =  wml_client.software_specifications.get_id_by_name('runtime-22.1-py3.9')\n",
    "print(software_spec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36a1b7cb5d3f48049fd42edcb471d157"
   },
   "source": [
    "### Create the batch python function meta properties\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd7e0a1e303c41b9b90815e8c2b33894"
   },
   "outputs": [],
   "source": [
    "function_meta_props = {\n",
    "     wml_client.repository.FunctionMetaNames.NAME: PYTHON_FUNCTION_NAME,\n",
    "     wml_client.repository.FunctionMetaNames.SOFTWARE_SPEC_ID: software_spec_id\n",
    "     }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the Python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_artifact = wml_client.repository.store_function(meta_props=function_meta_props, function=custom_metrics_provider)\n",
    "function_uid = wml_client.repository.get_function_id(function_artifact)\n",
    "print(\"Function UID = \" + function_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ea3a96ddfafc44ab9812e93770df7db9"
   },
   "outputs": [],
   "source": [
    "function_details = wml_client.repository.get_details(function_uid)\n",
    "from pprint import pprint\n",
    "pprint(function_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b89b9d948f242ffa77bde26a8e9cb81"
   },
   "source": [
    "### Deploy the Python function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1c33df40ea94f4ca7f8de257818b417"
   },
   "outputs": [],
   "source": [
    "hardware_spec_id = wml_client.hardware_specifications.get_id_by_name('M')\n",
    "hardware_spec_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6774445edd764e708ba6b4612edaed71"
   },
   "source": [
    "### Create deployment metadata for the batch python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "888a3c84fc06461f8ebc2120dfd58b22"
   },
   "outputs": [],
   "source": [
    "deploy_meta = {\n",
    " wml_client.deployments.ConfigurationMetaNames.NAME: DEPLOYMENT_NAME,\n",
    " wml_client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    " wml_client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: { \"name\": \"S\", \"num_nodes\": 1}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3273246ba52a49a1a7e7e98964d2cb63"
   },
   "source": [
    "### Create the batch python function deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7b5a9733edfb484e9a8533d22581bd8d"
   },
   "outputs": [],
   "source": [
    "deployment_details = wml_client.deployments.create(function_uid, meta_props=deploy_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c783aa24397e4562a2969b42cc862752"
   },
   "outputs": [],
   "source": [
    "deployment_uid = wml_client.deployments.get_uid(deployment_details)\n",
    "deployment_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f5b74cd-1cab-4249-943b-4081ad6eaa56"
   },
   "source": [
    "### Get the batch deployment job URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb56417d0e6e444484c25da9e6048aa5"
   },
   "outputs": [],
   "source": [
    "created_at = deployment_details['metadata']['created_at']\n",
    "find_string_pos = created_at.find(\"T\")\n",
    "if find_string_pos != -1:\n",
    "    current_date = created_at[0:find_string_pos]\n",
    "scoring_url = WML_CREDENTIALS['url'] + '/ml/v4/deployment_jobs?version='+current_date\n",
    "print(scoring_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73c85183a81f4997837587b2c64753c6"
   },
   "source": [
    "## 4. Configure OpenScale. <a name=\"config\"></a>\n",
    "\n",
    "Import the required libraries and set up the Watson OpenScale Python client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "addc28e79d494e68a5cb6a942d4f8bac"
   },
   "outputs": [],
   "source": [
    "from ibm_watson_openscale import APIClient\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import MonitorMeasurementRequest\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import MonitorMetricRequest\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import MetricThreshold\n",
    "from ibm_watson_openscale.supporting_classes.enums import MetricThresholdTypes\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import MonitorTagRequest\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import Target\n",
    "from ibm_watson_openscale.supporting_classes.enums import TargetTypes\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import IntegratedSystems\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bb826627adf4a2ba2e2bc20d5ab25a2"
   },
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator,BearerTokenAuthenticator\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY)\n",
    "wos_client = APIClient(service_url=WOS_CREDENTIALS['url'],authenticator=authenticator)\n",
    "wos_client.version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09b669c1459a4f75ad0d040d433795e4"
   },
   "source": [
    "## 5. Create the integrated system for the custom metrics provider. <a name=\"custom\"></a>\n",
    "\n",
    "\n",
    "Update the custom metrics deployment URL, which is created during the Python function creation in the integrated system. Watson OpenScale invokes the deployment URL at runtime to compute the custom metrics. \n",
    "\n",
    "You must define the authentication type based on the communication with custom metrics deployment. Watson OpenScale supports 2 types of authentication: basic and bearer. If custom metrics deployment accepts the `basic` authentication type, then provide `auth_type=basic` otherwise use `auth_type=bearer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6447a55-c85e-40c0-b8a4-74fe50f1fef0"
   },
   "outputs": [],
   "source": [
    "auth_type = \"bearer\" #Supported values are basic and bearer\n",
    "\n",
    "if auth_type == \"basic\":\n",
    "    CUSTOM_METRICS_PROVIDER_CREDENTIALS = {\n",
    "        \"auth_type\":\"basic\",\n",
    "        \"username\":  \"*****\",# update the username here \n",
    "        \"password\": \"*****\"# Update the password here\n",
    "   }\n",
    "    \n",
    "if auth_type == \"bearer\":\n",
    "    CUSTOM_METRICS_PROVIDER_CREDENTIALS = {\n",
    "        \"auth_type\":\"bearer\",\n",
    "        \"token_info\": {\n",
    "           \"url\":  IAM_URL,\n",
    "           \"headers\": { \"Content-type\": \"application/x-www-form-urlencoded\" }, # update the headers here \n",
    "           \"payload\": \"grant_type=urn:ibm:params:oauth:grant-type:apikey&response_type=cloud_iam&apikey=\"+CLOUD_API_KEY, # update the payload here \n",
    "           \"method\": \"POST\" \n",
    "        }        \n",
    "    }\n",
    "    \n",
    "  #if custom metrics deployment is on other cpd cluster or some other cloud then please uncomment and update \n",
    "  #the below \"TOKEN_INFO\" properties to generate the token to communicate to the custom metrics deployment url\n",
    "  #Here are the sample values given in the token_info\n",
    "    #TOKEN_INFO = {\n",
    "    #    \"url\":  \"https://iam.ng.bluemix.net/oidc/token\", # update the token generation here \n",
    "    #    \"headers\": { \"Content-type\": \"application/x-www-form-urlencoded\" }, # update the headers here \n",
    "    #    \"payload\": \"grant_type=urn:ibm:params:oauth:grant-type:apikey&response_type=cloud_iam&apikey=<api_key>\", # update the payload here \n",
    "    #    \"method\": \"POST\" # # update the http method here \n",
    "    #}\n",
    "    #CUSTOM_METRICS_PROVIDER_CREDENTIALS[\"token_info\"] = TOKEN_INFO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26df5128-0663-4749-9b74-846a47b86361"
   },
   "source": [
    "### Remove existing integrated system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acc73052-9c9d-4ffe-bc52-33783cda7426"
   },
   "outputs": [],
   "source": [
    "# Delete existing custom metrics provider integrated systems if present\n",
    "integrated_systems = IntegratedSystems(wos_client).list().result.integrated_systems\n",
    "for system in integrated_systems:\n",
    "    if system.entity.type == 'custom_metrics_provider' and system.entity.name == CUSTOM_METRICS_PROVIDER_NAME:\n",
    "        print(\"Deleting integrated system {}\".format(system.entity.name))\n",
    "        IntegratedSystems(wos_client).delete(integrated_system_id=system.metadata.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1f98b6c-7c8a-4250-af1a-10f1094d5091"
   },
   "outputs": [],
   "source": [
    "custom_metrics_integrated_system = IntegratedSystems(wos_client).add(\n",
    "    name=CUSTOM_METRICS_PROVIDER_NAME,\n",
    "    description=CUSTOM_METRICS_PROVIDER_NAME,\n",
    "    type=\"custom_metrics_provider\",\n",
    "    credentials= CUSTOM_METRICS_PROVIDER_CREDENTIALS,\n",
    "    connection={\n",
    "        \"display_name\": CUSTOM_METRICS_PROVIDER_NAME,\n",
    "        \"endpoint\": scoring_url\n",
    "    }\n",
    ").result\n",
    "\n",
    "integrated_system_id = custom_metrics_integrated_system.metadata.id\n",
    "print(custom_metrics_integrated_system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c618177a-32fe-4718-a6a7-2d2d8e0e2d03"
   },
   "source": [
    "## 6. Set up the custom monitor definition and instance. <a name=\"instance\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59b9827e31ab45edbad79789213703d1"
   },
   "source": [
    "### Check for the existence of the custom monitor definition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14e3f1e2e2f24bfd86f86feee24619e0"
   },
   "outputs": [],
   "source": [
    "def get_custom_monitor_definition():\n",
    "    monitor_definitions = wos_client.monitor_definitions.list().result.monitor_definitions\n",
    "    for definition in monitor_definitions:\n",
    "        if CUSTOM_MONITOR_NAME == definition.entity.name:\n",
    "            return definition\n",
    "    return None   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30720ce70ddf485782ebf767a606366b"
   },
   "source": [
    "### Create the  custom monitor definition.\n",
    "\n",
    "Update the custom metric names, threshold types (`LOWER_LIMIT`, `UPPER_LIMIT`) and default values as required. You can define the threshold type as lower limit, upper limit, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1e01833-dcb3-433b-a19e-c46225cf3538"
   },
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Update your custom monitor metrics names in the following field. Use the same metric names for creating the \n",
    "# monitor definition and publishing the metrics to Openscale in your python function\n",
    "####################################################################\n",
    "CUSTOM_MONITOR_METRICS_NAMES = ['sensitivity','specificity', 'gender_less40_fav_prediction_ratio']\n",
    "#Update the tag values if you want to fetch the metrics by tags\n",
    "TAGS= ['region']\n",
    "TAG_DESCRIPTION =['customer geographical region'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "df7bfd7b6f274d54897133f94dc14310"
   },
   "outputs": [],
   "source": [
    "#Update the Threshold types and default values of the metrics\n",
    "def custom_metric_definitions():\n",
    "    \n",
    "    metrics = [MonitorMetricRequest(name=CUSTOM_MONITOR_METRICS_NAMES[0],\n",
    "                                    thresholds=[MetricThreshold(type=MetricThresholdTypes.LOWER_LIMIT, default=0.8)]),\n",
    "              MonitorMetricRequest(name=CUSTOM_MONITOR_METRICS_NAMES[1],\n",
    "                                 thresholds=[MetricThreshold(type=MetricThresholdTypes.LOWER_LIMIT, default=0.6),MetricThreshold(type=MetricThresholdTypes.UPPER_LIMIT, default=1)]),\n",
    "              MonitorMetricRequest(name=CUSTOM_MONITOR_METRICS_NAMES[2],\n",
    "                                 thresholds=[MetricThreshold(type=MetricThresholdTypes.LOWER_LIMIT, default=0.6),MetricThreshold(type=MetricThresholdTypes.UPPER_LIMIT, default=1)])]\n",
    "    #Comment the below tags code if there are no tags to be created\n",
    "    tags = [MonitorTagRequest(name=TAGS[0], description=TAG_DESCRIPTION[0])]\n",
    "    \n",
    "    return metrics, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79e2f275e13948e5834e77ec4dfadeb6"
   },
   "outputs": [],
   "source": [
    "def create_custom_monitor_definition():\n",
    "    # check if the custom monitor definition already exists or not\n",
    "    existing_definition = get_custom_monitor_definition()\n",
    "\n",
    "    # if it does not exists, then create a new one.\n",
    "    if existing_definition is None:\n",
    "        metrics, tags = custom_metric_definitions()\n",
    "        custom_monitor_details = wos_client.monitor_definitions.add(name=CUSTOM_MONITOR_NAME, metrics=metrics, tags=tags, background_mode=False).result\n",
    "    else:\n",
    "        # otherwise, send the existing definition\n",
    "        custom_monitor_details = existing_definition\n",
    "    return custom_monitor_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8d352bcf09e646d0a6d174e54078f2c6"
   },
   "outputs": [],
   "source": [
    "custom_monitor_details = create_custom_monitor_definition()\n",
    "custom_monitor_id = custom_monitor_details.metadata.id\n",
    "custom_monitor_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a0dbf50822c40c680cc9430eb88306c"
   },
   "source": [
    "### Check the existence of custom monitor instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7176b942f61f4d0381fb63b92101e76f"
   },
   "outputs": [],
   "source": [
    "def get_custom_monitor_instance(custom_monitor_id):\n",
    "    monitor_instances = wos_client.monitor_instances.list(data_mart_id = WOS_GUID, monitor_definition_id = custom_monitor_id, target_target_id = subscription_id).result.monitor_instances\n",
    "    if len(monitor_instances) == 1:\n",
    "        return monitor_instances[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faf41bb1-74eb-4dab-8163-2b1f47c1fc94"
   },
   "outputs": [],
   "source": [
    "# Openscale MRM service invokes custom metrics deployment url during runtime and wait for the default time of 60 second's to \n",
    "# to check the run status ie finished/Failed and fetch the latest measurement. Increase the wait time, if the runtime deployment \n",
    "# takes more than 60 seconds to compute and publish the custom metrics \n",
    "\n",
    "#Update the wait time here.\n",
    "custom_metrics_wait_time = 120 #time in seconds <update the time here>\n",
    "#specify the provider type to \"wml_batch\" for batch deployments\n",
    "custom_metrics_provider_type = \"wml_batch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "583bc2cb-eb97-43ca-b5f9-f000091a9f72"
   },
   "source": [
    "### Update the custom monitor instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4ec5a04-4a47-4238-a185-3eebf79effb8"
   },
   "outputs": [],
   "source": [
    "def update_custom_monitor_instance(custom_monitor_instance_id):\n",
    "    payload = [\n",
    "     {\n",
    "       \"op\": \"replace\",\n",
    "       \"path\": \"/parameters\",\n",
    "       \"value\": {\n",
    "           \"custom_metrics_provider_id\": integrated_system_id,\n",
    "           \"custom_metrics_provider_type\": custom_metrics_provider_type,\n",
    "           \"custom_metrics_wait_time\":   custom_metrics_wait_time,\n",
    "           \"space_id\": space_id,\n",
    "           \"deployment_id\": deployment_uid,\n",
    "           \"hardware_spec_id\": hardware_spec_id\n",
    "       }\n",
    "     }\n",
    "    ]\n",
    "    response = wos_client.monitor_instances.update(custom_monitor_instance_id, payload, update_metadata_only = True)\n",
    "    result = response.result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "678df1de54164d6284cdf9f255affd8a"
   },
   "source": [
    "### For the custom monitor definition, create a custom monitor instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97624e1c0a8e4648af05162690c96c66"
   },
   "outputs": [],
   "source": [
    "def create_custom_monitor_instance(custom_monitor_id):\n",
    "    # Check if an custom monitor instance already exists\n",
    "    existing_monitor_instance = get_custom_monitor_instance(custom_monitor_id)\n",
    "\n",
    "    # If it does not exist, then create one\n",
    "    if existing_monitor_instance is None:\n",
    "        target = Target(\n",
    "                target_type=TargetTypes.SUBSCRIPTION,\n",
    "                target_id=subscription_id\n",
    "            )\n",
    "        parameters = {\n",
    "            \"custom_metrics_provider_id\": integrated_system_id,\n",
    "            \"custom_metrics_provider_type\": custom_metrics_provider_type,\n",
    "            \"custom_metrics_wait_time\":   custom_metrics_wait_time,\n",
    "            \"space_id\": space_id,\n",
    "            \"deployment_id\": deployment_uid,\n",
    "            \"hardware_spec_id\": hardware_spec_id\n",
    "        }\n",
    "        # create the custom monitor instance id here.\n",
    "        custom_monitor_instance_details = wos_client.monitor_instances.create(\n",
    "                    data_mart_id=WOS_GUID,\n",
    "                    background_mode=False,\n",
    "                    monitor_definition_id=custom_monitor_id,\n",
    "                    target=target,\n",
    "                    parameters=parameters\n",
    "        ).result\n",
    "    else:\n",
    "        # otherwise, update the existing one with latest integrated system details.\n",
    "        instance_id = existing_monitor_instance.metadata.id\n",
    "        custom_monitor_instance_details = update_custom_monitor_instance(instance_id)\n",
    "    return custom_monitor_instance_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffb159c5c1f54ffe9f1b7a48b727810c"
   },
   "outputs": [],
   "source": [
    "monitor_instance_details = create_custom_monitor_instance(custom_monitor_id)\n",
    "custom_monitor_instance_id = monitor_instance_details.metadata.id\n",
    "print(monitor_instance_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dc64e9c-bebc-45cc-84b3-6acb0cda784d"
   },
   "source": [
    "## Recap of the steps performed in this notebook\n",
    "\n",
    "- Create a python function\n",
    "- Deploy the python function to WML\n",
    "- Create an OpenScale Integrated System pointing to the python function\n",
    "- Create a Custom Monitor Definition mentioning various custom metrics\n",
    "- Create a Custom Monitor Instance and specify the Integrated System ID in the monitor instance configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "251d7491-3f34-4698-b97c-7b183b3251a9"
   },
   "source": [
    "### Upon publishing required payload logging or feedback logging data, please visit OpenScale console and perform `Evaluate Now` from Model Risk Management dashboard / Actions menu to evaluate the configured Custom Metrics Provider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d59f9f4-3232-4bbe-a0dc-ad9811a5c6e6"
   },
   "source": [
    "# [OPTIONAL EXECUTION STEP] Invoke the custom metrics deployment Python function.\n",
    "\n",
    "Validate the custom metrics provider deployment by providing the correct set of paramaters to generate the custom metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04b1ba00040a4a5c8147b26306395f40"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "parameters = {\n",
    "    \"custom_metrics_provider_id\": integrated_system_id,\n",
    "    \"custom_metrics_wait_time\":   custom_metrics_wait_time,\n",
    "    \"custom_metrics_provider_type\": custom_metrics_provider_type,\n",
    "    \"space_id\": space_id,\n",
    "    \"deployment_id\": deployment_uid,\n",
    "    \"hardware_spec_id\": hardware_spec_id,\n",
    "    \"run_details\": {\n",
    "    \"run_id\": str(uuid.uuid4()),\n",
    "    \"run_status\": \"Running\"\n",
    "    }\n",
    "}\n",
    "\n",
    "payload= {\n",
    "    \"data_mart_id\" : WOS_GUID,\n",
    "    \"subscription_id\" : subscription_id,\n",
    "    \"custom_monitor_id\" : custom_monitor_id,\n",
    "    \"custom_monitor_instance_id\" : custom_monitor_instance_id,\n",
    "    \"custom_monitor_instance_params\": parameters\n",
    "    \n",
    "}\n",
    "\n",
    "input_data= { \"input_data\": [ {\"values\": [ payload ] } ]\n",
    "            }\n",
    "func_result = custom_metrics_provider()(input_data)\n",
    "print(func_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "210c3b5835494f67812f0704bad84705"
   },
   "source": [
    "## Congratulations\n",
    "\n",
    "You have finished configuring Custom Monitor Definition and Monitor instance for your Subscription. You can now run the custom monitor from [Watson OpenScale Dashboard](http://aiopenscale.cloud.ibm.com). Click the tile of your model and select `Evaluate Now` option from `Actions` drop down menu to run the monitor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
