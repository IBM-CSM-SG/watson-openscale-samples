{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%env PIP_DISABLE_PIP_VERSION_CHECK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "PYTHON = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$PYTHON -m pip install --no-warn-conflicts --extra-index-url https://test.pypi.org/simple/ --upgrade tabulate ibm-cloud-sdk-core ibm-watson-openscale ibm-wos-utils | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$PYTHON -m pip show ibm-wos-utils ibm-watson-openscale ibm-cloud-sdk-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"***\",\n",
    "    \"username\": \"***\",\n",
    "    \"password\": \"***\"\n",
    "}\n",
    "\n",
    "DATAMART_ID = \"***\" # default is 00000000-0000-0000-0000-000000000000\n",
    "SUBSCRIPTION_ID = \"***\"\n",
    "MONITOR_INSTANCE_ID = \"***\"\n",
    "\n",
    "HIVE_METASTORE_URI = \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "from ibm_watson_openscale import APIClient\n",
    "\n",
    "authenticator = CloudPakForDataAuthenticator(\n",
    "        url=WOS_CREDENTIALS[\"url\"],\n",
    "        username=WOS_CREDENTIALS[\"username\"],\n",
    "        password=WOS_CREDENTIALS[\"password\"],\n",
    "        disable_ssl_verification=True\n",
    "    )\n",
    "wos_client = APIClient(authenticator=authenticator, service_url=WOS_CREDENTIALS[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription = wos_client.subscriptions.get(subscription_id=SUBSCRIPTION_ID).result\n",
    "monitor_instance = wos_client.monitor_instances.get(monitor_instance_id=MONITOR_INSTANCE_ID).result\n",
    "\n",
    "model_drift_enabled = monitor_instance.entity.parameters.get(\"model_drift_enabled\", False)\n",
    "data_drift_enabled = monitor_instance.entity.parameters.get(\"data_drift_enabled\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_archive = wos_client.monitor_instances.download_drift_model(monitor_instance_id=MONITOR_INSTANCE_ID).result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import io\n",
    "import json\n",
    "import tarfile\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "from ibm_wos_utils.drift.batch.constraints.entity import DataConstraintSet\n",
    "from ibm_wos_utils.drift.batch.constraints.schema import \\\n",
    "    DriftedTransactionsSchema\n",
    "\n",
    "ddm_properties = None\n",
    "constraints_set = None\n",
    "schema = None\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    member = \"archive.tar.gz\"\n",
    "    with zipfile.ZipFile(io.BytesIO(drift_archive)) as zf:\n",
    "        zf.extract(member, tmp)\n",
    "    with tarfile.open(tmp + \"/\" + member, mode=\"r:gz\") as tar:\n",
    "        schema_json = json.load(tar.extractfile(\"drifted_transactions_schema.json\"))\n",
    "        schema = DriftedTransactionsSchema()\n",
    "        schema.from_json(schema_json)\n",
    "        \n",
    "        if model_drift_enabled:\n",
    "            ddm_properties = json.load(tar.extractfile(\"ddm_properties.json\"))\n",
    "        \n",
    "        if data_drift_enabled:\n",
    "            constraints_json = json.load(tar.extractfile(\"data_drift_constraints.json\"))\n",
    "            constraints_set = DataConstraintSet()\n",
    "            constraints_set.from_json(constraints_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_last_n_drift_measurements(n, client, subscription_id):\n",
    "    measurements = client.monitor_instances.measurements.query(target_id=subscription_id, monitor_definition_id=\"drift\", recent_count=n).result.measurements\n",
    "    results = []\n",
    "    for measurement in measurements:\n",
    "        results.append([measurement.metadata.id, measurement.entity.run_id, measurement.entity.timestamp])\n",
    "    results = pd.DataFrame(results, columns=[\"Measurement ID\", \"Monitor Run ID\", \"Timestamp\"])\n",
    "    results.sort_values(by=\"Timestamp\", ascending=False, inplace=True)\n",
    "    return results\n",
    "\n",
    "results = get_last_n_drift_measurements(15, wos_client, SUBSCRIPTION_ID)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEASUREMENT_ID = \"***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement = wos_client.monitor_instances.measurements.get(measurement_id=MEASUREMENT_ID, monitor_instance_id=MONITOR_INSTANCE_ID).result\n",
    "measurement_data = measurement.entity.sources[0].data\n",
    "MONITOR_RUN_ID = measurement.entity.run_id\n",
    "MONITOR_RUN_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IBM Watson OpenScale analyzed {} transactions between {} and {} for drift. Here's a summary.\".format(measurement_data[\"transactions_count\"], measurement_data[\"start\"], measurement_data[\"end\"]))\n",
    "\n",
    "if model_drift_enabled:\n",
    "    print(\"  - Total {} transactions out of {} transactions are causing drop in accuracy.\".format(measurement_data[\"drifted_transactions\"][\"count\"], measurement_data[\"transactions_count\"]))\n",
    "\n",
    "if data_drift_enabled:\n",
    "    print(\"  - Total {} transactions out of {} transactions are causing drop in data consistency.\".format(measurement_data[\"data_drifted_transactions\"][\"count\"], measurement_data[\"transactions_count\"]))\n",
    "    \n",
    "if model_drift_enabled and data_drift_enabled:\n",
    "    print(\"  - Total {} transactions out of {} transactions are causing both drop in accuracy and drop in data consistency.\".format(measurement_data[\"model_data_drifted_transactions\"][\"count\"], measurement_data[\"transactions_count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_drift_enabled:\n",
    "    display(pd.DataFrame(measurement_data[\"drifted_transactions\"][\"drift_model_confidence_count\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if data_drift_enabled:\n",
    "    display(pd.Series(measurement_data[\"data_drifted_transactions\"][\"features_count\"]).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_drift_enabled:\n",
    "    display(pd.Series(measurement_data[\"data_drifted_transactions\"][\"constraints_count\"]).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\\\n",
    "        .setAppName(\"Analyze Drifted Transactions\")\\\n",
    "        .set(\"spark.hadoop.hive.metastore.uris\", HIVE_METASTORE_URI)\n",
    "spark = SparkSession.builder.config(conf=conf).enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_details_from_subscription(subscription, table_type):\n",
    "    data_source = [source for source in subscription.entity.data_sources if source.type == table_type]\n",
    "    if len(data_source) == 0:\n",
    "        raise Exception(\"Details not found for data source type: {} in subscription.\".format(table_type))\n",
    "    data_source = data_source[0]\n",
    "    \n",
    "    return data_source.database_name, data_source.schema_name, data_source.table_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_database_name, _, payload_table_name = get_table_details_from_subscription(subscription, \"payload\")\n",
    "drift_database_name, _, drift_table_name = get_table_details_from_subscription(subscription, \"drift\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drifted_txns_df = spark.sql(\"select * from {}.{} where run_id = '{}'\".format(drift_database_name, drift_table_name, MONITOR_RUN_ID))\n",
    "drifted_txns_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_txns_df = spark.sql(\"select * from {}.{}\".format(payload_database_name, payload_table_name))\n",
    "payload_txns_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Total number of drifted transactions: {}\".format(drifted_txns_df.count()))\n",
    "print(\"Total number of model drift transactions: {}\".format(drifted_txns_df.where(\"is_model_drift\").count()))\n",
    "print(\"Total number of data drift transactions: {}\".format(drifted_txns_df.where(\"is_data_drift\").count()))\n",
    "print(\"Total number of model + data drift transactions: {}\".format(drifted_txns_df.where(\"is_model_drift\").where(\"is_data_drift\").count()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from IPython.display import HTML\n",
    "\n",
    "# TODO move this to joblib\n",
    "\n",
    "def show_dataframe(spark_df, num_rows = 10, priority_columns = []):\n",
    "    show_df = spark_df.limit(num_rows).toPandas()\n",
    "    original_columns = list(show_df.columns)\n",
    "    new_columns = []\n",
    "    priority_columns += [\"scoring_id\", \"scoring_timestamp\"]\n",
    "    for column in priority_columns:\n",
    "        if column in original_columns:\n",
    "            new_columns.append(column)\n",
    "            original_columns.remove(column)\n",
    "    new_columns += original_columns\n",
    "    return HTML(tabulate(show_df[new_columns], headers=new_columns, tablefmt=\"html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dm_conf_lower = 0.5\n",
    "dm_conf_upper = 0.6\n",
    "\n",
    "result = drifted_txns_df\\\n",
    "    .where(\"is_model_drift\")\\\n",
    "    .where(drifted_txns_df.drift_model_confidence.between(dm_conf_lower,dm_conf_upper))\\\n",
    "    .select([\"scoring_id\",\"drift_model_confidence\"])\n",
    "\n",
    "count = result.count()\n",
    "\n",
    "print(\"Total {} transactions are causing drop in accuracy where drift model confidence is between {} and {}\".format(count, dm_conf_lower, dm_conf_upper))\n",
    "\n",
    "if count:\n",
    "    print(\"Showing 10 such transactions in the order of drift_model_confidence\")\n",
    "\n",
    "    result = payload_txns_df\\\n",
    "        .join(result, [\"scoring_id\"], \"leftsemi\")\\\n",
    "        .join(result, [\"scoring_id\"], \"left\")\\\n",
    "        .sort([\"drift_model_confidence\"], ascending=False)\n",
    "\n",
    "    display(show_dataframe(result, priority_columns=[\"drift_model_confidence\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_wos_utils.drift.batch.util.constants import ConstraintName\n",
    "# from ibm_wos_utils\n",
    "import pyspark.sql.functions as F\n",
    "from itertools import product\n",
    "import hashlib\n",
    "\n",
    "# Scenarios:\n",
    "# SELECT * FROM drifted_annotations WHERE categorical LIKE '%1%' \n",
    "\n",
    "\n",
    "# def get_constraint_id(constraint_name, columns):\n",
    "#     return hashlib.sha224(\n",
    "#             bytes(\",\".join([constraint_name.value] + sorted(map(lambda x: x.lower(), columns))), \"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def get_constraint_id(constraint_name, columns):\n",
    "    return hashlib.sha224(\n",
    "            bytes(\",\".join([constraint_name.value] + sorted(columns)), \"utf-8\")).hexdigest()\n",
    "\n",
    "def get_constraints_for_column(column):\n",
    "    return {cid: constraint for cid, constraint in constraints_set.constraints.items()\n",
    "            if column.lower() in map(lambda x: x.lower(), constraint.columns)}\n",
    "\n",
    "\n",
    "def get_bitmap(constraints_set, schema, constraint_names=[], columns=[]):\n",
    "    if not constraint_names and not columns:\n",
    "        raise Exception(\"Need either constraint_names or columns to create a bitmap.\")\n",
    "\n",
    "    valid_constraints = constraint_names.copy()\n",
    "    if len(valid_constraints) == 0:\n",
    "        valid_constraints = list(ConstraintName)\n",
    "\n",
    "    bitmap = {key: [\"_\"] * len(value) for key,value in schema.bitmap.items()}\n",
    "    for column in columns:\n",
    "        learnt_constraints = get_constraints_for_column(column)\n",
    "        for ctr_id, ctr in learnt_constraints.items():\n",
    "            if ctr.name in valid_constraints:\n",
    "                idx = schema.bitmap[ctr.name.value].index(ctr_id)\n",
    "                bitmap[ctr.name.value][idx] = \"1\"\n",
    "                \n",
    "    return bitmap\n",
    "\n",
    "\n",
    "def get_query(constraints_set, schema, constraint_names=[], columns=[], operation = \"or\"):\n",
    "    if not constraint_names and not columns:\n",
    "        raise Exception(\"Need either constraint_names or columns to create a query.\")\n",
    "    \n",
    "    if operation not in (\"or\", \"and\"):\n",
    "        raise Exception(\"Unsupported operation '{}' passed as an argument.\".format(operation))\n",
    "    \n",
    "    subqueries = []\n",
    "    if not columns:\n",
    "        for constraint_name in constraint_names:\n",
    "            subqueries.append(F.col(constraint_name.value).like(\"%1%\"))\n",
    "\n",
    "    else:\n",
    "        bitmap = get_bitmap(constraints_set, schema, constraint_names, columns)\n",
    "        for name, values in bitmap.items():\n",
    "            if \"1\" in values:\n",
    "                subqueries.append(F.col(name).like(\"\".join(values)))\n",
    "        \n",
    "    if not subqueries:\n",
    "        return\n",
    "    \n",
    "    result = subqueries.pop()\n",
    "    \n",
    "    for subquery in subqueries:\n",
    "        result = (result | subquery) if operation == \"or\" else (result & subquery)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_query(constraints_set, schema, constraint):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filter_query = get_query(constraints_set, schema, constraints=[ConstraintName.CATEGORICAL_DISTRIBUTION_CONSTRAINT], operation=\"or\")\n",
    "print(filter_query)\n",
    "\n",
    "result = drifted_txns_df\\\n",
    "    .where(\"is_data_drift\")\\\n",
    "    .where(filter_query)\\\n",
    "    .select([\"scoring_id\"])\n",
    "print(result.explain())\n",
    "\n",
    "count = result.count()\n",
    "\n",
    "print(\"Total {} transactions are satisfying the given query.\".format(count))\n",
    "\n",
    "if count:\n",
    "    print(\"Showing 10 such transactions.\")\n",
    "\n",
    "    result = payload_txns_df\\\n",
    "        .join(result, [\"scoring_id\"], \"leftsemi\")\\\n",
    "        .join(result, [\"scoring_id\"], \"left\")\\\n",
    "\n",
    "    display(show_dataframe(result, priority_columns=[\"drift_model_confidence\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filter_query = get_query(constraints_set, schema, constraints=[ConstraintName.CATEGORICAL_DISTRIBUTION_CONSTRAINT], columns=[\"checkingstatus\"], operation=\"or\")\n",
    "\n",
    "result = drifted_txns_df\\\n",
    "    .where(\"is_data_drift\")\\\n",
    "    .where(filter_query)\\\n",
    "    .select([\"scoring_id\"])\n",
    "count = result.count()\n",
    "\n",
    "print(\"Total {} transactions are satisfying the given query.\".format(count))\n",
    "\n",
    "if count:\n",
    "    print(\"Showing 10 such transactions.\")\n",
    "\n",
    "    result = payload_txns_df\\\n",
    "        .join(result, [\"scoring_id\"], \"leftsemi\")\\\n",
    "        .join(result, [\"scoring_id\"], \"left\")\\\n",
    "\n",
    "    display(show_dataframe(result, priority_columns=[\"drift_model_confidence\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
