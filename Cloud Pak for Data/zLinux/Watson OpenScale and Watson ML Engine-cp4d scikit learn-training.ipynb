{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebd9fca6-8fba-4a2b-a429-705280fb46b6"
   },
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7908b63-8b06-4910-a629-f6dd60311b2e"
   },
   "source": [
    "# Working with Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f35b084-336a-4388-87da-1fc162378b69"
   },
   "source": [
    "This notebook should be run in a Watson Studio project, using **Default Python 3.8** runtime environment. It requires service credentials for the following Cloud services:\n",
    "  * Watson OpenScale \n",
    "  * Watson Machine Learning \n",
    "  * Cloud Object Storage\n",
    "  \n",
    "If you have a paid Cloud account, you may also provision a **Db2 Warehouse** service to take full advantage of integration with Watson Studio and continuous learning services.\n",
    "\n",
    "The notebook will train, create and deploy a German Credit Risk model, configure OpenScale to monitor that deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78ad47bf-c737-4934-8102-575cf2aa2e7a"
   },
   "source": [
    "### Contents\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Model building and deployment](#model)\n",
    "- [OpenScale configuration](#openscale)\n",
    "- [Create Trainig data json](#quality)\n",
    "- [Fairness and explanations](#fairness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32ce1b27-ff71-459a-b7c6-1758a78048b0"
   },
   "source": [
    "# Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "7027709e-335f-4a89-a8cd-27c336663089"
   },
   "source": [
    "## Package installation\n",
    "**NOTE** Using scikit-learn 0.20.2 is requirement for Drift detection model training. if you are training drift detection model using notebook, make sure you have scikit-learn version 0.20.2. Your main model can be of any scikit-learn framework version supported by Watson Machine Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99a36299bafe46a0adba0c214a6ccfca"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade ibm-watson-machine-learning | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d40edd8-9b95-497e-875f-0281852c7f95"
   },
   "source": [
    "### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fb8857264b24490a8fb90cc0af4a4ad"
   },
   "source": [
    "## Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cb38ac0-3775-4362-a1bb-6ec0440e41fa"
   },
   "source": [
    "- WOS_CREDENTIALS (CP4D)\n",
    "- WML_CREDENTIALS (CP4D)\n",
    "- DB_CREDENTIALS (DB2 on CP4D)\n",
    "- SCHEMA_NAME\n",
    "- WML_SPACE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1c70468c-3d36-4b31-aca2-0cadcc72244b"
   },
   "outputs": [],
   "source": [
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"***\",\n",
    "    \"username\": \"***\",\n",
    "    \"password\": \"***\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb84b8fa-df07-4a59-9f1f-bd7353d73a8d"
   },
   "source": [
    "### WML credentials example with API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c53410a1-feea-4014-8734-93daa8f891e2"
   },
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "                   \"url\": WOS_CREDENTIALS[\"url\"],\n",
    "                   \"username\": WOS_CREDENTIALS[\"username\"],\n",
    "                   \"password\" : WOS_CREDENTIALS[\"password\"],\n",
    "                   \"instance_id\": \"wml_local\",\n",
    "                   \"version\" : \"4.0\" #If your env is CP4D 4.0 then specify \"4.0\" instead of \"3.5\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82c82702-86ff-46b4-a5c7-30e83da0ec59",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DB_CREDENTIALS = {\n",
    "    \"hostname\":\"***\",\n",
    "    \"username\":\"***\",\n",
    "    \"password\":\"***\",\n",
    "    \"database\":\"***\",\n",
    "    \"port\":50000, #provide your actual DB2 port number (as integer value)\n",
    "    \"ssl\":\"***\",\n",
    "    \"sslmode\":\"***\",\n",
    "    \"certificate_base64\":\"***\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c01b7b0a41346d4861716cb0b47a09c"
   },
   "source": [
    "### Action: Specify created schema name below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ba7eeedb535403f8cda4f8b9b17e384"
   },
   "outputs": [],
   "source": [
    "SCHEMA_NAME = 'AIOSFASTPATHICP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e629eaf3-9997-4592-9db7-e6e82482f9dd"
   },
   "source": [
    "In next cells, you will need to paste some credentials to Cloud Object Storage. If you haven't worked with COS yet please visit getting started with COS tutorial. You can find `COS_API_KEY_ID` and `COS_RESOURCE_CRN` variables in **_Service Credentials_** in menu of your COS instance. Used COS Service Credentials must be created with _Role_ parameter set as Writer. Later training data file will be loaded to the bucket of your instance and used as training refecence in subsription.  \n",
    "`COS_ENDPOINT` variable can be found in **_Endpoint_** field of the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "815e1305-01ee-407e-b0fb-bd4bbf1c81c1"
   },
   "outputs": [],
   "source": [
    "COS_API_KEY_ID = \"***\"\n",
    "COS_RESOURCE_CRN = \"***\"\n",
    "COS_ENDPOINT = \"***\" # Current list avaiable at https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\n",
    "COS_IAM_AUTH_ENDPOINT = \"https://iam.ng.bluemix.net/oidc/token\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b44c68bc-9b48-4806-945d-32c5b3dadd37"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"***\" #example: \"credit-risk-training-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68dce8a5-b8e9-4fa6-975d-5ce5a2941745"
   },
   "source": [
    "## Run the notebook\n",
    "\n",
    "At this point, the notebook is ready to run. You can either run the cells one at a time, or click the **Kernel** option above and select **Restart and Run All** to run all the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1373067-ffde-4854-8990-0b1d888c53db"
   },
   "source": [
    "# Model building and deployment <a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcf0bd92-bb11-4b01-a15c-fdafa3aaf326"
   },
   "source": [
    "In this section you will learn how to train Scikit-learn model and next deploy it as web-service using Watson Machine Learning service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29c42f42-8648-4dd0-beb3-62913a74c7a2"
   },
   "source": [
    "## Load the training data from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4c544fa7-9f6c-4d58-8a75-7c99a8fb1b06",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm german_credit_data_biased_training.csv\n",
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/Cloud%20Pak%20for%20Data/WML/assets/data/credit_risk/german_credit_data_biased_training.csv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21a401cb-1574-4525-ab7f-27c80698891b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "training_data_file_name = \"german_credit_data_biased_training.csv\"\n",
    "data_df = pd.read_csv(training_data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aea6c652-5212-465f-9243-e17fa2327c1e"
   },
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0d7a5c8-82e7-4c07-a475-b9b6076ef740"
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d28e08af-e702-42f9-94f8-c7505b451d1c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Columns: ', list(data_df.columns))\n",
    "print('Number of columns: ', len(data_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fc8ced6-135a-4856-b752-7b787ca4e52a"
   },
   "source": [
    "As you can see, the data contains twenty one fields. `Risk` field is the one you would like to predict using feedback data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb276153-9a5b-442b-9ac1-a9f23c44e984",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Number of records: ', data_df.Risk.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7ae158e-a147-4166-b83c-a9924f0d1fcc"
   },
   "outputs": [],
   "source": [
    "target_count = data_df.groupby('Risk')['Risk'].count()\n",
    "target_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18fbde71-53a5-4a6a-a1e1-ed96576c2673"
   },
   "source": [
    "## Save training data to Cloud Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0906b881-35c8-4cb8-83e4-365c3938a818"
   },
   "outputs": [],
   "source": [
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config, ClientError\n",
    "\n",
    "cos_client = ibm_boto3.resource(\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_RESOURCE_CRN,\n",
    "    #ibm_auth_endpoint=COS_IAM_AUTH_ENDPOINT,\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81cce090-4fa8-4f8c-ab41-6a460fa418ab",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(training_data_file_name, \"rb\") as file_data:\n",
    "    cos_client.Object(BUCKET_NAME, training_data_file_name).upload_fileobj(\n",
    "        Fileobj=file_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fa30e81-5fe1-4b2e-a510-e934a6dd20a2"
   },
   "source": [
    "## Create a model\n",
    "In this section you will learn how to:\n",
    "\n",
    "- Prepare data for training a model\n",
    "- Create machine learning pipeline\n",
    "- Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b07d6388-8415-410c-8269-bdfc106d5532"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Scikit German Risk Model - for training data - zLinux\"\n",
    "DEPLOYMENT_NAME = \"Scikit German Risk Model - for training data - zLinux\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdc3deb6-1415-4831-a28f-91d1b21606f5"
   },
   "source": [
    "### You will start with importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d6704aa-e746-4bb4-b50d-5bc76abf41ce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67cbf85d-c175-4213-86a4-98a8a9598236"
   },
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60230dac-7d60-49f7-9e90-563603ce593f"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0844fc4-987f-4405-a069-21aa5f10a442"
   },
   "source": [
    "### Preparing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2864d4ce-07c3-40d7-b035-a5b83e423338"
   },
   "outputs": [],
   "source": [
    "features_idx = np.s_[0:-1]\n",
    "all_records_idx = np.s_[:]\n",
    "first_record_idx = np.s_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25b041fd-535d-439a-874d-be464eeaf9ad"
   },
   "source": [
    "In this step you will encode target column labels into numeric values. You can use `inverse_transform` to decode numeric predictions into labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "963e486f-6842-4b92-90d4-f1177060fea7"
   },
   "outputs": [],
   "source": [
    "string_fields = [type(fld) is str for fld in train_data.iloc[first_record_idx, features_idx]]\n",
    "ct = ColumnTransformer([(\"ohe\", OneHotEncoder(), list(np.array(train_data.columns)[features_idx][string_fields]))])\n",
    "clf_linear = SGDClassifier(loss='log', penalty='l2', max_iter=1000, tol=1e-5)\n",
    "\n",
    "pipeline_linear = Pipeline([('ct', ct), ('clf_linear', clf_linear)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45e72e17-7267-4fa9-acb9-c09657d7e97a"
   },
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "101fb7d1-97a7-42f7-bc6b-9430afa96cad"
   },
   "outputs": [],
   "source": [
    "risk_model = pipeline_linear.fit(train_data.drop('Risk', axis=1), train_data.Risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6724f9d3-4c7e-4f07-93cf-c5a0ace66ccb"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4a3268ea-98f6-4388-bdb8-464e2efec7bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = risk_model.predict(test_data.drop('Risk', axis=1))\n",
    "indexed_preds = [0 if prediction=='No Risk' else 1 for prediction in predictions]\n",
    "\n",
    "real_observations = test_data.Risk.replace('Risk', 1)\n",
    "real_observations = real_observations.replace('No Risk', 0).values\n",
    "\n",
    "auc = roc_auc_score(real_observations, indexed_preds)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b447d34d-0c26-4623-8309-801996639b35"
   },
   "source": [
    "## Publish the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fa34070-c8bb-4a66-b160-4022efad64d3"
   },
   "source": [
    "In this section, the notebook uses the supplied Watson Machine Learning credentials to save the model (including the pipeline) to the WML instance. Previous versions of the model are removed so that the notebook can be run again, resetting all data for another demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1676bfa1-5543-4d93-911e-25f582cf5920",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_client = APIClient(WML_CREDENTIALS)\n",
    "wml_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2ceec76-8256-4d27-9fcb-3af284bc7eae"
   },
   "source": [
    "### Listing all the available spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00bdc264-eca7-4343-8872-5cd5947a73bb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wml_client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a69e509e-1f19-4a4a-a1e8-98e8f6c30e4c"
   },
   "outputs": [],
   "source": [
    "WML_SPACE_ID='***' # use space id here\n",
    "wml_client.set.default_space(WML_SPACE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67763c9a-b074-44d5-ad3e-82494555a1e2"
   },
   "source": [
    "### Remove existing model and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2ad551e-e539-4ba6-8103-af252616ab1e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "deployments_list = wml_client.deployments.get_details()\n",
    "for deployment in deployments_list[\"resources\"]:\n",
    "    model_id = deployment[\"entity\"][\"asset\"][\"id\"]\n",
    "    deployment_id = deployment[\"metadata\"][\"id\"]\n",
    "    if deployment[\"metadata\"][\"name\"] == DEPLOYMENT_NAME:\n",
    "        print(\"Deleting deployment id\", deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "        time.sleep(5)\n",
    "        print(\"Deleting model id\", model_id)\n",
    "        wml_client.repository.delete(model_id)\n",
    "        time.sleep(5)\n",
    "\n",
    "wml_client.repository.list_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e0c191a-4e32-48ea-84c0-6c93b23b084a"
   },
   "outputs": [],
   "source": [
    "training_data_references = [\n",
    "                {\n",
    "                    \"id\": \"product line\",\n",
    "                    \"type\": \"s3\",\n",
    "                    \"connection\": {\n",
    "                        \"access_key_id\": COS_API_KEY_ID,\n",
    "                        \"endpoint_url\": COS_ENDPOINT,\n",
    "                        \"resource_instance_id\":COS_RESOURCE_CRN\n",
    "                    },\n",
    "                    \"location\": {\n",
    "                        \"bucket\": BUCKET_NAME,\n",
    "                        \"path\": training_data_file_name,\n",
    "                    }\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e91674b3-1119-4b48-bc0e-abee8ea6b4d9",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"default_py3.8\")\n",
    "print(\"Software Specification ID: {}\".format(software_spec_uid))\n",
    "\n",
    "model_props = {\n",
    "        wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(MODEL_NAME),\n",
    "        wml_client._models.ConfigurationMetaNames.TYPE: \"scikit-learn_0.23\",\n",
    "        wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n",
    "        wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"Risk\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd0397c1-1107-4e8f-9df3-a436112d9294",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Storing model ...\")\n",
    "\n",
    "published_model_details = wml_client.repository.store_model(model=risk_model, meta_props=model_props, training_data=data_df.drop([\"Risk\"], axis=1), training_target=data_df.Risk)\n",
    "model_uid = wml_client.repository.get_model_uid(published_model_details)\n",
    "print(\"Done\")\n",
    "print(\"Model ID: {}\".format(model_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "601deedd48e54b3d84fa5f6c86a55805"
   },
   "outputs": [],
   "source": [
    "model_details = wml_client.repository.get_details(model_uid)\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5faac985-f126-4ad2-9b13-d88fc59e2437"
   },
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab19ef53-c2fe-42df-82b8-e89e34feba8b"
   },
   "source": [
    "The next section of the notebook deploys the model as a RESTful web service in Watson Machine Learning. The deployed model will have a scoring URL you can use to send data to the model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8b6ded3-2e8f-4960-98b1-9553da09e087",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Deploying model...\")\n",
    "deployment_details = wml_client.deployments.create(\n",
    "    model_uid, \n",
    "    meta_props={\n",
    "        wml_client.deployments.ConfigurationMetaNames.NAME: \"{}\".format(DEPLOYMENT_NAME),\n",
    "        wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    ")\n",
    "scoring_url = wml_client.deployments.get_scoring_href(deployment_details)\n",
    "deployment_uid=wml_client.deployments.get_uid(deployment_details)\n",
    "\n",
    "print(\"Scoring URL:\" + scoring_url)\n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48d4d3c1-7429-44cc-b698-55b5a7f265f6"
   },
   "source": [
    "## Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "502eb0bc-0d41-481a-9f6e-a472351b973f"
   },
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n",
    "                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n",
    "                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "                  \"Telephone\", \"ForeignWorker\"]\n",
    "values = [\n",
    "            [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n",
    "             \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"],\n",
    "            [\"no_checking\", 24, \"prior_payments_delayed\", \"furniture\", 4567, \"500_to_1000\", \"1_to_4\", 4, \"male\", \"none\",\n",
    "             4, \"savings_insurance\", 36, \"none\", \"free\", 2, \"management_self-employed\", 1, \"none\", \"yes\"],\n",
    "        ]\n",
    "\n",
    "scoring_payload = {\"input_data\": [{\"fields\": fields, \"values\": values}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39b06e70-060e-4737-adfe-b07c7c962070"
   },
   "outputs": [],
   "source": [
    "predictions = wml_client.deployments.score(deployment_uid, scoring_payload)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ba30a5b-5081-4ed6-b34f-f87cf85eea31"
   },
   "source": [
    "# Configure OpenScale <a name=\"openscale\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e51600e-8f08-4c51-9763-84ecdb289364"
   },
   "source": [
    "The notebook will now import the necessary libraries and set up a Python OpenScale client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "671740e1-cb54-4a77-9aed-6bf10632a167",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import CloudPakForDataAuthenticator\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "\n",
    "authenticator = CloudPakForDataAuthenticator(\n",
    "        url=WOS_CREDENTIALS['url'],\n",
    "        username=WOS_CREDENTIALS['username'],\n",
    "        password=WOS_CREDENTIALS['password'],\n",
    "        disable_ssl_verification=True\n",
    "    )\n",
    "#Create client for the default instance id 00000000-0000-0000-0000-000000000000\n",
    "wos_client = APIClient(service_url=WOS_CREDENTIALS['url'], authenticator=authenticator)\n",
    "wos_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "000328b2-35ce-4c90-b1fb-ec8b5f1cb49e"
   },
   "source": [
    "## Create schema and datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "378698f6-87e5-4f8d-b340-a1f1d9f2bd09"
   },
   "source": [
    "### Set up datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60e478a0-4116-4d24-aebc-5a9cc5097bbc"
   },
   "source": [
    "Watson OpenScale uses a database to store payload logs and calculated metrics. If database credentials were supplied, the datamart will be created there unless there is an existing datamart. If an OpenScale datamart exists, the existing datamart will be used and no data will be overwritten.\n",
    "\n",
    "Prior instances of the German Credit model will be removed from OpenScale monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "011447b9-6084-4b93-94f3-dbc909cb0a9e"
   },
   "outputs": [],
   "source": [
    "wos_client.data_marts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f24cf322-2136-4c92-9266-2346c0bd285a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_marts = wos_client.data_marts.list().result.data_marts\n",
    "if len(data_marts) == 0:\n",
    "    if DB_CREDENTIALS is not None:\n",
    "        if SCHEMA_NAME is None: \n",
    "            print(\"Please specify the SCHEMA_NAME and rerun the cell\")\n",
    "\n",
    "        print('Setting up external datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\",\n",
    "                database_configuration=DatabaseConfigurationRequest(\n",
    "                  database_type=DatabaseType.POSTGRESQL,\n",
    "                    credentials=PrimaryStorageCredentialsLong(\n",
    "                        hostname=DB_CREDENTIALS['hostname'],\n",
    "                        username=DB_CREDENTIALS['username'],\n",
    "                        password=DB_CREDENTIALS['password'],\n",
    "                        db=DB_CREDENTIALS['database'],\n",
    "                        port=DB_CREDENTIALS['port'],\n",
    "                        ssl=True,\n",
    "                        sslmode=DB_CREDENTIALS['sslmode'],\n",
    "                        certificate_base64=DB_CREDENTIALS['certificate_base64']\n",
    "                    ),\n",
    "                    location=LocationSchemaName(\n",
    "                        schema_name= SCHEMA_NAME\n",
    "                    )\n",
    "                )\n",
    "             ).result\n",
    "    else:\n",
    "        print('Setting up internal datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\", \n",
    "                internal_database = True).result\n",
    "        \n",
    "    data_mart_id = added_data_mart_result.metadata.id\n",
    "    \n",
    "else:\n",
    "    data_mart_id=data_marts[0].metadata.id\n",
    "    print('Using existing datamart {}'.format(data_mart_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3b4d368-46b6-4b0f-8701-4435eef79587"
   },
   "source": [
    "### Remove existing service provider connected with used  WML instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2f2c2a5a-ded2-4433-ab93-69275086346c"
   },
   "source": [
    "Multiple service providers for the same engine instance are avaiable in Watson OpenScale. To avoid multiple service providers of used WML instance in the tutorial notebook the following code deletes existing service provder(s) and then adds new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "373ae376-0b21-4381-b595-9b29f493c172"
   },
   "outputs": [],
   "source": [
    "SERVICE_PROVIDER_NAME = \"WML - for training data\"\n",
    "SERVICE_PROVIDER_DESCRIPTION = \"Added by tutorial WOS notebook.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4efe4827-a78f-4772-8517-61f2fe4df026",
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_providers = wos_client.service_providers.list().result.service_providers\n",
    "for service_provider in service_providers:\n",
    "    service_instance_name = service_provider.entity.name\n",
    "    if service_instance_name == SERVICE_PROVIDER_NAME:\n",
    "        service_provider_id = service_provider.metadata.id\n",
    "        wos_client.service_providers.delete(service_provider_id)\n",
    "        print(\"Deleted existing service_provider for WML instance: {}\".format(service_provider_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4da60d70-dc51-4063-95db-abd7ff425d53"
   },
   "source": [
    "## Add service provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "374ab259-a510-4c43-8f1c-6a4736173b77"
   },
   "source": [
    "Watson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fad9b6ec-6dcc-44d1-9f72-80dd9e8d0e4d"
   },
   "source": [
    "**Note:** You can bind more than one engine instance if needed by calling `wos_client.service_providers.add` method. Next, you can refer to particular service provider using `service_provider_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cb49423-0fcb-4c6d-a5a3-815fd1626064",
    "tags": []
   },
   "outputs": [],
   "source": [
    "added_service_provider_result = wos_client.service_providers.add(\n",
    "        name=SERVICE_PROVIDER_NAME,\n",
    "        description=SERVICE_PROVIDER_DESCRIPTION,\n",
    "        service_type=ServiceTypes.WATSON_MACHINE_LEARNING,\n",
    "        deployment_space_id = WML_SPACE_ID,\n",
    "        operational_space_id = \"production\",\n",
    "        credentials=WMLCredentialsCP4D(),\n",
    "        background_mode=False\n",
    "    ).result\n",
    "service_provider_id = added_service_provider_result.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a509362d-de9e-402f-8cbc-2f0dfa4af709",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate training stats\n",
    "# Setup info for generating training stats for GCR Model\n",
    "from ibm_watson_openscale.utils.training_stats import TrainingStats\n",
    "service_configuration_support = {\n",
    "    \"enable_fairness\": True,\n",
    "    \"enable_explainability\": True,\n",
    "    \"enable_drift\": True\n",
    "}\n",
    "\n",
    "training_data_info = {\n",
    "    \"class_label\": \"Risk\",\n",
    "    \"feature_columns\": [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\", \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\", \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\", \"Telephone\", \"ForeignWorker\"],\n",
    "    \"categorical_columns\": [\"Sex\", \"OwnsProperty\", \"Telephone\", \"ForeignWorker\"]\n",
    "}\n",
    "\n",
    "fairness_attributes = [{\n",
    "   \"feature\": \"Sex\", \n",
    "   \"majority\": [\n",
    "       \"male\"\n",
    "   ],\n",
    "   \"minority\": [\n",
    "       \"female\"\n",
    "   ],\n",
    "   \"threshold\": 0.8\n",
    "}]\n",
    "\n",
    "model_type = \"binary\"\n",
    "parameters = {\n",
    "    \"favourable_class\" :  [ \"No Risk\" ],\n",
    "    \"unfavourable_class\": [ \"Risk\" ]\n",
    "}\n",
    "min_records = 100\n",
    "\n",
    "# Generate Training stats\n",
    "enable_explainability = service_configuration_support.get('enable_explainability')\n",
    "enable_fairness = service_configuration_support.get('enable_fairness')\n",
    "data_df = pd.read_csv('german_credit_data_biased_training.csv')\n",
    "training_data_stats = None\n",
    "if enable_explainability or enable_fairness:\n",
    "    fairness_inputs = None\n",
    "    if enable_fairness:\n",
    "        fairness_inputs = {\n",
    "                \"fairness_attributes\": fairness_attributes,\n",
    "                \"min_records\" : min_records,\n",
    "                \"favourable_class\" :  parameters[\"favourable_class\"],\n",
    "                \"unfavourable_class\": parameters[\"unfavourable_class\"]\n",
    "            }\n",
    "\n",
    "    input_parameters = {\n",
    "        \"label_column\": training_data_info[\"class_label\"],\n",
    "        \"feature_columns\": training_data_info[\"feature_columns\"],\n",
    "        \"categorical_columns\": training_data_info[\"categorical_columns\"],\n",
    "        \"fairness_inputs\": fairness_inputs,  \n",
    "        \"problem_type\" : model_type  \n",
    "    }\n",
    "\n",
    "    training_stats = TrainingStats(data_df,input_parameters, explain=enable_explainability, fairness=enable_fairness, drop_na=True)\n",
    "    training_data_stats = training_stats.get_training_statistics()\n",
    "    training_data_stats[\"notebook_version\"] = 5.0 \n",
    "\n",
    "print(training_data_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fc9fc61-4489-4dc9-86ba-2ab9b46f22b2"
   },
   "outputs": [],
   "source": [
    "#Create subscription from training stats\n",
    "prediction_column = \"prediction\"\n",
    "probability_columns = ['probability']\n",
    "predicted_target_column = \"prediction\"\n",
    "#predicted_target_column = \"***\"\n",
    "subscription_details = wos_client.subscriptions.add(data_mart_id,\n",
    "    service_provider_id,\n",
    "    asset = None,\n",
    "    deployment = None,\n",
    "    training_data_stats=training_data_stats,\n",
    "    deployment_id = deployment_uid,\n",
    "    deployment_space_id = WML_SPACE_ID,\n",
    "    prediction_field = prediction_column,\n",
    "    #predicted_target_field = predicted_target_column,\n",
    "    probability_fields = probability_columns,background_mode = False).result\n",
    "\n",
    "subscription_id = subscription_details.metadata.id\n",
    "print(subscription_details)\n",
    "print(\"Subscription id {}\".format(subscription_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5de0653-71a5-49bd-89cc-7053ad5e0f5f"
   },
   "outputs": [],
   "source": [
    "#Score payload\n",
    "from IPython.utils import io\n",
    "with io.capture_output() as captured:\n",
    "    !wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/credit_risk/german_credit_feed.json -O german_credit_feed.json\n",
    "!ls -lh german_credit_feed.json\n",
    "\n",
    "import random, time\n",
    "import uuid\n",
    "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n",
    "\n",
    "payload_data_set_id = None\n",
    "payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
    "if payload_data_set_id is None:\n",
    "    print(\"Payload data set not found. Please check subscription status.\")\n",
    "else:\n",
    "    print(\"Payload data set id: \", payload_data_set_id)\n",
    "    \n",
    "\n",
    "with open('german_credit_feed.json', 'r') as scoring_file:\n",
    "    scoring_data = json.load(scoring_file)\n",
    "\n",
    "fields = scoring_data['fields']\n",
    "values = []\n",
    "for _ in range(100):\n",
    "    values.append(random.choice(scoring_data['values']))\n",
    "payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values}]}\n",
    "\n",
    "scoring_response = wml_client.deployments.score(deployment_uid, payload_scoring)\n",
    "time.sleep(10)\n",
    "\n",
    "#wos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=[PayloadRecord(\n",
    "#                   scoring_id=str(uuid.uuid4()),\n",
    "#                   request=payload_scoring,\n",
    "#                   response=scoring_response,\n",
    "#                   response_time=460\n",
    "#               )],background_mode=False)\n",
    "#time.sleep(5)\n",
    "pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11bd2663-c476-4fe9-8173-79b5d56c5c74"
   },
   "outputs": [],
   "source": [
    "#Create monitors\n",
    "# It will create Bias and explain monitors based on what is enabled\n",
    "print(\"Creating monitor instances...\")\n",
    "response = wos_client.monitor_instances.create(monitor_definition_id = None, \n",
    "                        target = None, data_mart_id = data_mart_id, training_data_stats=training_data_stats, \n",
    "                        subscription_id=subscription_id,background_mode=False)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0438cdfa-da0f-4996-9479-9aa2ad19784a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ee3a4725-fcf0-451e-a5c5-9dfe070fd79b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
