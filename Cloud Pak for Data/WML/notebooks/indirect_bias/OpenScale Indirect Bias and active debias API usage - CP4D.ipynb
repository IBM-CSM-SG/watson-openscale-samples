{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "75feab07-55ef-4436-ab6c-48d5c2d133e4"
   },
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b18c0eec7d1c46f6b8fe4c779c478b7b"
   },
   "source": [
    "# Working with Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc3ebd630e524b3e812e2d17d603e5c9"
   },
   "source": [
    "This notebook should be run using with **Python 3.7** runtime environment. **If you are viewing this in Watson Studio and do not see Python 3.7 in the upper right corner of your screen, please update the runtime now.** It requires service credentials for the following services:\n",
    "  * Watson OpenScale\n",
    "  * Watson Machine Learning \n",
    "  * DB2\n",
    "\n",
    "  \n",
    "The notebook will train, create and deploy a model, configure OpenScale to monitor that deployment, and inject seven days' worth of historical records and measurements for viewing in the OpenScale Insights dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "262ffb75c64b4523bfda24ea95d4b8f5"
   },
   "source": [
    "# Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b7c0a42ac1e43139057e5d78abfe075"
   },
   "source": [
    "## Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "827d92b4b8e1491e81d23153816f555c"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dc441429a8ad4aada3fa29d81e98e5cf"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pyspark==2.4 --no-cache | tail -n 1\n",
    "\n",
    "!pip install --upgrade pandas==0.25.3 --no-cache | tail -n 1\n",
    "!pip install --upgrade requests==2.23 --no-cache | tail -n 1\n",
    "!pip install numpy==1.16.4 --no-cache | tail -n 1\n",
    "!pip install SciPy --no-cache | tail -n 1\n",
    "!pip install lime --no-cache | tail -n 1\n",
    "!pip install ibm-cloud-sdk-core --no-cache | tail -n 1\n",
    "\n",
    "!pip install --upgrade ibm-watson-machine-learning --user | tail -n 1\n",
    "!pip install --upgrade ibm-watson-openscale --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44f0e2adc53c4f04ba9647b031d88cb9"
   },
   "source": [
    "### Action: restart the kernel!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8cdd3fa70d94b9c8e3bea9fc4c65e9f"
   },
   "source": [
    "## Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64b031a79e2f497d8d63ca093d9bf0ad"
   },
   "source": [
    "- WOS_CREDENTIALS (CP4D)\n",
    "- WML_CREDENTIALS (CP4D)\n",
    "- DATABASE_CREDENTIALS (DB2 on CP4D or Cloud Object Storage (COS))\n",
    "- SCHEMA_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c470852b2bf14f7caeef5d025c8d64c7"
   },
   "outputs": [],
   "source": [
    "#masked\n",
    "WOS_CREDENTIALS = {\n",
    "    \"url\": \"Cluster host name\",\n",
    "    \"username\": \"XX\",\n",
    "    \"password\": \"XX\",\n",
    "    \"version\": \"3.5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd83a4b858414f22895adb44c3234185"
   },
   "outputs": [],
   "source": [
    "#masked\n",
    "WML_CREDENTIALS = {\n",
    "                   \"url\": \"Cluster host name\",\n",
    "                   \"username\": \"XX\",\n",
    "                   \"password\" : \"XX\",\n",
    "                   \"instance_id\": \"wml_local\",\n",
    "                   \"version\" : \"3.5\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8604bf1ad39c4e6981754957eec367d4"
   },
   "outputs": [],
   "source": [
    "#masked\n",
    "#IBM DB2 database connection format example\n",
    "DATABASE_CREDENTIALS = {\n",
    "    \"hostname\":\"9.999.999.99\",\n",
    "    \"username\":\"XX\",\n",
    "    \"password\":\"XX\",\n",
    "    \"database\":\"SAMPLE\",\n",
    "    \"port\":\"50000\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24b4c90ba7cb4f3e89a95faa26555865"
   },
   "source": [
    "### Action: put created schema name below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ede68cb2c2564377984fde01b0a8b2d7"
   },
   "outputs": [],
   "source": [
    "SCHEMA_NAME = 'AIOSFASTPATHICP-00000000-0000-0000-0000-000000000000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d85650ef53984d799a58b8ce79160674"
   },
   "source": [
    "## Save training data to Cloud Object Storage\n",
    "\n",
    "### Cloud object storage detailsÂ¶\n",
    "\n",
    "In next cells, you will need to paste some credentials to Cloud Object Storage. If you haven't worked with COS yet please visit getting started with COS tutorial. You can find COS_API_KEY_ID and COS_RESOURCE_CRN variables in Service Credentials in menu of your COS instance. Used COS Service Credentials must be created with Role parameter set as Writer. Later training data file will be loaded to the bucket of your instance and used as training refecence in subsription. COS_ENDPOINT variable can be found in Endpoint field of the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cb6e02e0589449b9d2a9813d44dec07"
   },
   "outputs": [],
   "source": [
    "IAM_URL=\"https://iam.ng.bluemix.net/oidc/token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbac5a57926d4f7eb3e74564cc6a95af"
   },
   "outputs": [],
   "source": [
    "# masked\n",
    "COS_API_KEY_ID = \"***\"\n",
    "COS_RESOURCE_CRN = \"***\" # eg \"crn:v1:bluemix:public:cloud-object-storage:global:a/3bf0d9003abfb5d29761c3e97696b71c:d6f04d83-6c4f-4a62-a165-696756d63903::\"\n",
    "COS_ENDPOINT = \"https://s3.us.cloud-object-storage.appdomain.cloud\" # Current list avaiable at https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\n",
    "BUCKET_NAME = \"testcasebucket\"\n",
    "FILE_NAME = \"Indirect_bias_AdultCensusdata.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "056e2d289da0487c83e16983cde997ec"
   },
   "source": [
    "# Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a74cc3aca27d406d88a25ab74a373157"
   },
   "outputs": [],
   "source": [
    "!rm Indirect_bias_AdultCensusdata.csv\n",
    "!wget https://raw.githubusercontent.com/IBM/watson-openscale-samples/main/IBM%20Cloud/WML/assets/data/adult_census/Indirect_bias_AdultCensusdata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2235027af5a4d329972a869fbcfd2f8"
   },
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6eec247a77146d88e6476fc5ad49b03"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_data = spark.read.csv(path=\"Indirect_bias_AdultCensusdata.csv\", sep=\",\", header=True, inferSchema=True) \n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a09d9e346bce47a98a7eccc833112128"
   },
   "outputs": [],
   "source": [
    "print(\"Number of records: \" + str(df_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d55078678a94079b67b183e549fc534"
   },
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88357d1f249f427491163b19f6acc9ab"
   },
   "outputs": [],
   "source": [
    "# spark_df = sqlCtx.createDataFrame(df_data)\n",
    "spark_df = df_data\n",
    "# Remove protected attributes from training data\n",
    "protected_attributes = [\"race\", \"age\", \"sex\"]\n",
    "for attr in protected_attributes:\n",
    "    spark_df = spark_df.drop(attr)\n",
    "columns = spark_df.columns\n",
    "model_name = \"Adult Census Income Classifier Model\"\n",
    "deployment_name = \"Adult Census Income Classifier Deployment\"\n",
    "\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82155d92dee14d8596d23529d454c3e9"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml import Pipeline, Model\n",
    "\n",
    "cat_features = ['workclass', 'education', 'Marital', 'occupation', 'relationship', 'citizen_status'] \n",
    "num_features = [\"fnlwgt\", \"education-num\", \"capitalgain\", \"loss\", \"hoursper\"]\n",
    "stages=[]\n",
    "\n",
    "for feature in cat_features:\n",
    "    string_indexer = StringIndexer(inputCol = feature, outputCol = feature + '_IX').setHandleInvalid(\"keep\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[string_indexer.getOutputCol()], outputCols=[feature + \"classVec\"])\n",
    "    stages += [string_indexer, encoder]\n",
    "\n",
    "si_Label = StringIndexer(inputCol=\"label\", outputCol=\"encoded_label\").fit(spark_df)\n",
    "label_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=si_Label.labels)\n",
    "stages.append(si_Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cadc3aae47ca464abf9c956375b1ec72"
   },
   "outputs": [],
   "source": [
    "assembler_inputs = [c + \"classVec\" for c in cat_features] + num_features\n",
    "va_features = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "stages.append(va_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3d7ff9894674a94bd713d2e9af4cd55"
   },
   "outputs": [],
   "source": [
    "(train_data, test_data) = spark_df.randomSplit([0.8, 0.2], 24)\n",
    "print(\"Number of records for training: \" + str(train_data.count()))\n",
    "print(\"Number of records for evaluation: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "720b9ee7712b450c8b3ecdcd4ab58893"
   },
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04cf8f5bdf08438f8992890b1bc70442"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier, DecisionTreeClassifier, RandomForestClassifier\n",
    "classifier = RandomForestClassifier(labelCol=\"encoded_label\", featuresCol=\"features\")\n",
    "stages.append(classifier)\n",
    "stages.append(label_converter)\n",
    "pipeline = Pipeline(stages=stages)\n",
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30adcf7239c54415a6e74250a6f80903"
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)\n",
    "predictions.printSchema()\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efa502d57f284612b95903f27157992f"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluatorDT = BinaryClassificationEvaluator(labelCol=\"encoded_label\", rawPredictionCol=\"rawPrediction\")\n",
    "accuracy = evaluatorDT.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy = %g\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbb45c2f139940b28e3f9dfff4e99576"
   },
   "source": [
    "# Save and deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8c46867b3f484ba1a396f364742552de"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "wml_client = APIClient(WML_CREDENTIALS)\n",
    "wml_client.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d6754453fdb4e50836da3e9ed32df17"
   },
   "outputs": [],
   "source": [
    "wml_client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1cd9533f53a414f86f748e34275cfce"
   },
   "source": [
    "## Find the space that you would like to associate the model that is created and deployed as part of the notebook, and specify it in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3393075295af4022a7f060b5a85a5b6e"
   },
   "outputs": [],
   "source": [
    "WML_SPACE_ID='***' # use space id here\n",
    "wml_client.set.default_space(WML_SPACE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7f4015490dfc48c7a7b74c7ed9627284"
   },
   "outputs": [],
   "source": [
    "deployments_list = wml_client.deployments.get_details()\n",
    "for deployment in deployments_list[\"resources\"]:\n",
    "    model_id = deployment[\"entity\"][\"asset\"][\"id\"]\n",
    "    deployment_id = deployment[\"metadata\"][\"id\"]\n",
    "    if deployment[\"metadata\"][\"name\"] == deployment_name:\n",
    "        print(\"Deleting deployment id\", deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "        print(\"Deleting model id\", model_id)\n",
    "        wml_client.repository.delete(model_id)\n",
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9df60c1cc314ccb887411f0d3253a92"
   },
   "outputs": [],
   "source": [
    "training_data_references = [\n",
    "                {\n",
    "                    \"id\": \"product line\",\n",
    "                    \"type\": \"s3\",\n",
    "                    \"connection\": {\n",
    "                        \"access_key_id\": COS_API_KEY_ID,\n",
    "                        \"endpoint_url\": COS_ENDPOINT,\n",
    "                        \"resource_instance_id\":COS_RESOURCE_CRN\n",
    "                    },\n",
    "                    \"location\": {\n",
    "                        \"bucket\": BUCKET_NAME,\n",
    "                        \"path\": FILE_NAME,\n",
    "                    }\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf0293f9272c4623a4c39f752b6554cf"
   },
   "outputs": [],
   "source": [
    "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"spark-mllib_2.4\")\n",
    "print(\"Software Specification ID: {}\".format(software_spec_uid))\n",
    "model_props = {\n",
    "        wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(model_name),\n",
    "        wml_client._models.ConfigurationMetaNames.SPACE_UID: WML_SPACE_ID,\n",
    "        wml_client._models.ConfigurationMetaNames.TYPE: \"mllib_2.4\",\n",
    "        wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n",
    "        wml_client._models.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: training_data_references,\n",
    "        wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"label\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7d3327cef8c43c18ff8191f930f887d"
   },
   "outputs": [],
   "source": [
    "print(\"Storing model ...\")\n",
    "published_model_details = wml_client.repository.store_model(\n",
    "    model=model, \n",
    "    meta_props=model_props, \n",
    "    training_data=train_data, \n",
    "    pipeline=pipeline)\n",
    "\n",
    "model_uid = wml_client.repository.get_model_uid(published_model_details)\n",
    "print(\"Done\")\n",
    "print(\"Model ID: {}\".format(model_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06c2bb55cbf04f59b092c8d773e7952b"
   },
   "outputs": [],
   "source": [
    "published_model_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5483e2532fe43c1b931b1e18aa246d0"
   },
   "source": [
    "## Create a model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdc6ce1dcab84ca2803daa6444eaea6f"
   },
   "outputs": [],
   "source": [
    "deployment_details = wml_client.deployments.create(\n",
    "    model_uid, \n",
    "    meta_props={\n",
    "        wml_client.deployments.ConfigurationMetaNames.NAME: \"{}\".format(deployment_name),\n",
    "        wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    ")\n",
    "scoring_url = wml_client.deployments.get_scoring_href(deployment_details)\n",
    "deployment_uid=wml_client.deployments.get_uid(deployment_details)\n",
    "\n",
    "print(\"Scoring URL:\" + scoring_url)\n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fa3b287605044538f3c1b3ee632eb9b"
   },
   "source": [
    "# Construct the scoring payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eb1e48ae98514c14a6dc225eba1acc9f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Indirect_bias_AdultCensusdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8aaab665f9947b594380d4892c237a7"
   },
   "source": [
    "## Remove the sensitive attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcd4da086e604f92b7bedd6f1283ba4e"
   },
   "outputs": [],
   "source": [
    "cols_to_remove = ['label']\n",
    "cols_to_remove.extend(protected_attributes)\n",
    "cols_to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "546d7ce9df5c404f84c2a556c3679e4e"
   },
   "source": [
    "## Create the meta data frame capturing the sensitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37aa35f9cdfb466085acbb7eac3e56ec"
   },
   "outputs": [],
   "source": [
    "meta_df = df[protected_attributes].copy()\n",
    "meta_fields = meta_df.columns.tolist()\n",
    "meta_values = meta_df[meta_fields].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee69bf1da4a04865a6db14f13c46908d"
   },
   "source": [
    "## Construct the scoring payload comprising the meta fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f50af2cb0f04203998c93f6caade4fb"
   },
   "outputs": [],
   "source": [
    "def get_scoring_payload(no_of_records_to_score = 1):\n",
    "    meta_payload = {\n",
    "        \"fields\": meta_fields,\n",
    "        \"values\": meta_values[:no_of_records_to_score]\n",
    "    }\n",
    "\n",
    "    for col in cols_to_remove:\n",
    "        if col in df.columns:\n",
    "            del df[col] \n",
    "\n",
    "    fields = df.columns.tolist()\n",
    "    values = df[fields].values.tolist()\n",
    "\n",
    "    payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values[:no_of_records_to_score],\"meta\": meta_payload}]}  \n",
    "    return payload_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90f239341ee04e13acb5455607cd4f25"
   },
   "source": [
    "## Method to perform scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad3991e04720434c9bcd42c7acf44b59"
   },
   "outputs": [],
   "source": [
    "def sample_scoring(no_of_records_to_score = 1):\n",
    "    records_list=[]\n",
    "    payload_scoring = get_scoring_payload(no_of_records_to_score)\n",
    "    scoring_response = wml_client.deployments.score(deployment_uid, payload_scoring)\n",
    "    print('Single record scoring result:', '\\n fields:', scoring_response['predictions'][0]['fields'], '\\n values: ', scoring_response['predictions'][0]['values'][0])\n",
    "    print(json.dumps(scoring_response, indent=None))\n",
    "    return payload_scoring, scoring_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fccba0eaa7794d6c9bb5990c435aa563"
   },
   "outputs": [],
   "source": [
    "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n",
    "def payload_logging(no_of_records_to_score = 1):\n",
    "    records_list=[]\n",
    "    payload_scoring = get_scoring_payload(no_of_records_to_score)\n",
    "    \n",
    "    \n",
    "    scoring_response = wml_client.deployments.score(deployment_uid, payload_scoring)\n",
    "    time.sleep(5)\n",
    "    pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "    print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
    "    if pl_records_count == 0:\n",
    "        print(\"Payload logging did not happen, performing explicit payload logging.\")\n",
    "    \n",
    "        #manual PL logging if automated logging does not work\n",
    "        score_input=payload_scoring['input_data'][0]\n",
    "        score_response=scoring_response['predictions'][0]\n",
    "        pl_record = PayloadRecord(request=score_input, response=score_response, response_time=int(460))\n",
    "        records_list.append(pl_record)\n",
    "        wos_client.data_sets.store_records(data_set_id = payload_data_set_id, request_body=records_list)\n",
    "        \n",
    "        \n",
    "        time.sleep(5)\n",
    "        pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "        print(\"Number of records in the payload logging table: {}\".format(pl_records_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd59a8e3d0bb431eb3be9252b1f3772c"
   },
   "source": [
    "## Score the model and print the scoring response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b1853a125a340e99c622b9f71167c9c"
   },
   "outputs": [],
   "source": [
    "sample_scoring(no_of_records_to_score = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7056440604434d4f8b9429befee9bdce"
   },
   "source": [
    "# Configure OpenScale \n",
    "\n",
    "The notebook will now import the necessary libraries and set up a Python OpenScale client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e577b95129004af19aeccbb4ae4a7862"
   },
   "outputs": [],
   "source": [
    "from ibm_watson_openscale import APIClient\n",
    "from ibm_watson_openscale.utils import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3043544c667e49d38cd70855d8ccb5ad"
   },
   "source": [
    "## Get a instance of the OpenScale SDK client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3d5b4df0a9f4d598a6cbd595700ae53"
   },
   "outputs": [],
   "source": [
    "authenticator = CloudPakForDataAuthenticator(\n",
    "        url=WOS_CREDENTIALS['url'],\n",
    "        username=WOS_CREDENTIALS['username'],\n",
    "        password=WOS_CREDENTIALS['password'],\n",
    "        disable_ssl_verification=True\n",
    "    )\n",
    "\n",
    "wos_client = APIClient(service_url=WOS_CREDENTIALS['url'],authenticator=authenticator)\n",
    "wos_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbebb627856a43cbb607cf844568a9f3"
   },
   "source": [
    "## Create datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dbc59b8112144b8a06e6c41a8301f0a"
   },
   "source": [
    "### Set up datamart\n",
    "\n",
    "Watson OpenScale uses a database to store payload logs and calculated metrics. If database credentials were not supplied above, the notebook will use the free, internal lite database. If database credentials were supplied, the datamart will be created there unless there is an existing datamart and the KEEP_MY_INTERNAL_POSTGRES variable is set to True. If an OpenScale datamart exists in Db2 or PostgreSQL, the existing datamart will be used and no data will be overwritten.\n",
    "\n",
    "Prior instances of the model will be removed from OpenScale monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ca368ed3793443da944e24b8b5e0d281"
   },
   "outputs": [],
   "source": [
    "wos_client.data_marts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2966db92a2994a958136635144f05572"
   },
   "outputs": [],
   "source": [
    "data_marts = wos_client.data_marts.list().result.data_marts\n",
    "if len(data_marts) == 0:\n",
    "    if DB_CREDENTIALS is not None:\n",
    "        if SCHEMA_NAME is None: \n",
    "            print(\"Please specify the SCHEMA_NAME and rerun the cell\")\n",
    "\n",
    "        print('Setting up external datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\",\n",
    "                database_configuration=DatabaseConfigurationRequest(\n",
    "                  database_type=DatabaseType.DB2,\n",
    "                    credentials=PrimaryStorageCredentialsLong(\n",
    "                        hostname=DATABASE_CREDENTIALS['hostname'],\n",
    "                        username=DATABASE_CREDENTIALS['username'],\n",
    "                        password=DATABASE_CREDENTIALS['password'],\n",
    "                        db=DATABASE_CREDENTIALS['database'],\n",
    "                        port=DATABASE_CREDENTIALS['port'],\n",
    "                        ssl=DATABASE_CREDENTIALS['ssl'],\n",
    "                        sslmode=DATABASE_CREDENTIALS['sslmode'],\n",
    "                        certificate_base64=DATABASE_CREDENTIALS['certificate_base64']\n",
    "                    ),\n",
    "                    location=LocationSchemaName(\n",
    "                        schema_name= SCHEMA_NAME\n",
    "                    )\n",
    "                )\n",
    "             ).result\n",
    "    else:\n",
    "        print('Setting up internal datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\", \n",
    "                internal_database = True).result\n",
    "        \n",
    "    data_mart_id = added_data_mart_result.metadata.id\n",
    "    \n",
    "else:\n",
    "    data_mart_id=data_marts[0].metadata.id\n",
    "    print('Using existing datamart {}'.format(data_mart_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5862cdb82a534375b7e290cee338774e"
   },
   "outputs": [],
   "source": [
    "data_mart_details = wos_client.data_marts.list().result.data_marts[0]\n",
    "data_mart_details.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b61551bb00fa430b8595748c93a2dfb9"
   },
   "outputs": [],
   "source": [
    "wos_client.service_providers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1ecf806072240cd89af4324cb844744"
   },
   "source": [
    "## Remove existing service provider connected with used WML instance.\n",
    "\n",
    "Multiple service providers for the same engine instance are avaiable in Watson OpenScale. To avoid multiple service providers of used WML instance in the tutorial notebook the following code deletes existing service provder(s) and then adds new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34534f784ac845438b54c6947d227ccb"
   },
   "outputs": [],
   "source": [
    "SERVICE_PROVIDER_NAME = \"Watson Machine Learning - Indirect Bias Demo\"\n",
    "SERVICE_PROVIDER_DESCRIPTION = \"Added by tutorial WOS notebook to showcase Indirect Bias functionality.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebd41ed59d0a44b3837152bdd67e10fc"
   },
   "outputs": [],
   "source": [
    "service_providers = wos_client.service_providers.list().result.service_providers\n",
    "for service_provider in service_providers:\n",
    "    service_instance_name = service_provider.entity.name\n",
    "    if service_instance_name == SERVICE_PROVIDER_NAME:\n",
    "        service_provider_id = service_provider.metadata.id\n",
    "        wos_client.service_providers.delete(service_provider_id)\n",
    "        print(\"Deleted existing service_provider for WML instance: {}\".format(service_provider_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48cf5770290744c28274669a5af0103b"
   },
   "source": [
    "## Add service provider\n",
    "\n",
    "Watson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model.\n",
    "Note: You can bind more than one engine instance if needed by calling wos_client.service_providers.add method. Next, you can refer to particular service provider using service_provider_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d260d321cad475682aea0857c9b1054"
   },
   "outputs": [],
   "source": [
    "added_service_provider_result = wos_client.service_providers.add(\n",
    "        name=SERVICE_PROVIDER_NAME,\n",
    "        description=SERVICE_PROVIDER_DESCRIPTION,\n",
    "        service_type=ServiceTypes.WATSON_MACHINE_LEARNING,\n",
    "        deployment_space_id = WML_SPACE_ID,\n",
    "        operational_space_id = \"production\",\n",
    "        credentials=WMLCredentialsCP4D(\n",
    "            url=WML_CREDENTIALS[\"url\"],\n",
    "            username=WML_CREDENTIALS[\"username\"],\n",
    "            password=WML_CREDENTIALS[\"password\"],\n",
    "            instance_id=None\n",
    "        ),\n",
    "        background_mode=False\n",
    "    ).result\n",
    "service_provider_id = added_service_provider_result.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eae202864f724fb9880ed31fadf75ac0"
   },
   "outputs": [],
   "source": [
    "print(wos_client.service_providers.get(service_provider_id).result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ced8049e546405e81129ada3cbf73d1"
   },
   "outputs": [],
   "source": [
    "asset_deployment_details = wos_client.service_providers.list_assets(data_mart_id=data_mart_id, service_provider_id=service_provider_id, deployment_id=deployment_uid, deployment_space_id = WML_SPACE_ID).result['resources'][0]\n",
    "asset_deployment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ed2cbb8cfbd40518178d204be799ecb"
   },
   "outputs": [],
   "source": [
    "model_asset_details_from_deployment=wos_client.service_providers.get_deployment_asset(data_mart_id=data_mart_id,service_provider_id=service_provider_id,deployment_id=deployment_uid,deployment_space_id=WML_SPACE_ID)\n",
    "#model_asset_details_from_deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09f4993d2caa48269b9832c7e9b145d6"
   },
   "source": [
    "## Subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e59906593c44bda97f79a9c35e728f6"
   },
   "source": [
    "Remove existing credit risk subscriptions\n",
    "\n",
    "This code removes previous subscriptions to the model to refresh the monitors with the new model and new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b97d781684b401095188860bd0a3c96"
   },
   "outputs": [],
   "source": [
    "wos_client.subscriptions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0d085c8a875458b834992abd3577219"
   },
   "source": [
    "## Remove the existing subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5ef621a07cb4e468fca6cc62d22595e"
   },
   "outputs": [],
   "source": [
    "subscriptions = wos_client.subscriptions.list().result.subscriptions\n",
    "for subscription in subscriptions:\n",
    "    sub_model_id = subscription.entity.asset.asset_id\n",
    "    if sub_model_id == model_uid:\n",
    "        wos_client.subscriptions.delete(subscription.metadata.id)\n",
    "        print('Deleted existing subscription for model', sub_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d117477d751b4d6380d2feceac14450e"
   },
   "source": [
    "This code creates the model subscription in OpenScale using the Python client API. Note that we need to provide the model unique identifier, and some information about the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3d6cdba01c140a090a4e3e27a12bdcf"
   },
   "outputs": [],
   "source": [
    "feature_columns = cat_features + num_features\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7e200c3388d42c087f937ca745938c9"
   },
   "outputs": [],
   "source": [
    "subscription_details = wos_client.subscriptions.add(\n",
    "        data_mart_id=data_mart_id,\n",
    "        service_provider_id=service_provider_id,\n",
    "        asset=Asset(\n",
    "            asset_id=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"asset_id\"],\n",
    "            name=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"name\"],\n",
    "            url=model_asset_details_from_deployment[\"entity\"][\"asset\"][\"url\"],\n",
    "            asset_type=AssetTypes.MODEL,\n",
    "            input_data_type=InputDataType.STRUCTURED,\n",
    "            problem_type=ProblemType.BINARY_CLASSIFICATION\n",
    "        ),\n",
    "        deployment=AssetDeploymentRequest(\n",
    "            deployment_id=asset_deployment_details['metadata']['guid'],\n",
    "            name=asset_deployment_details['entity']['name'],\n",
    "            deployment_type= DeploymentTypes.ONLINE,\n",
    "            url=asset_deployment_details['entity']['scoring_endpoint']['url']\n",
    "        ),\n",
    "        asset_properties=AssetPropertiesRequest(\n",
    "            label_column=\"label\",\n",
    "            probability_fields=[\"probability\"],\n",
    "            prediction_field=\"predictedLabel\",\n",
    "            feature_fields = feature_columns,\n",
    "            categorical_fields = cat_features,\n",
    "            training_data_reference=TrainingDataReference(type=\"cos\",\n",
    "                                                          location=COSTrainingDataReferenceLocation(bucket = BUCKET_NAME,\n",
    "                                                                                                    file_name = FILE_NAME),\n",
    "                                                          connection=COSTrainingDataReferenceConnection.from_dict({\n",
    "                                                                        \"resource_instance_id\": COS_RESOURCE_CRN,\n",
    "                                                                        \"url\": COS_ENDPOINT,\n",
    "                                                                        \"api_key\": COS_API_KEY_ID,\n",
    "                                                                        \"iam_url\": IAM_URL})),\n",
    "            training_data_schema=SparkStruct.from_dict(model_asset_details_from_deployment[\"entity\"][\"asset_properties\"][\"training_data_schema\"])\n",
    "        )\n",
    "    ).result\n",
    "subscription_id = subscription_details.metadata.id\n",
    "print('subscription_id: ' + subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dee41fc8ae2407483f7d08f7ecd9663"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(5)\n",
    "payload_data_set_id = None\n",
    "payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
    "if payload_data_set_id is None:\n",
    "    print(\"Payload data set not found. Please check subscription status.\")\n",
    "else:\n",
    "    print(\"Payload data set id:\", payload_data_set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e2d47b3928c4f6c87fe3379168f2301"
   },
   "outputs": [],
   "source": [
    "wos_client.data_sets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ba479997dca4e2899796ba7c050fed5"
   },
   "outputs": [],
   "source": [
    "wos_client.subscriptions.get(subscription_id).result.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d75c57ab8914d70acdc3ed523675b1b"
   },
   "source": [
    "# Score the model so we can configure monitors\n",
    "\n",
    "Now that the WML service has been bound and the subscription has been created, we need to send a request to the model before we configure OpenScale. This allows OpenScale to create a payload log in the datamart with the correct schema, so it can capture data coming into and out of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14ef8cf50f5748589f34ab3c15fe5d2f"
   },
   "outputs": [],
   "source": [
    "payload_logging(no_of_records_to_score = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "933b5220cd9d4c5681f54308ce266ade"
   },
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
    "if pl_records_count == 0:\n",
    "    raise Exception(\"Payload logging did not happen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09c318b2e5c54b839eb6f3ac8b247ca4"
   },
   "source": [
    "## Fairness configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d73b84061cc494a8ea5a19e897b981f"
   },
   "source": [
    "The code below configures fairness monitoring for our model. It turns on monitoring for two features, sex and age. In each case, we must specify:\n",
    "    \n",
    "Which model feature to monitor One or more majority groups, which are values of that feature that we expect to receive a higher percentage of favorable outcomes One or more minority groups, which are values of that feature that we expect to receive a higher percentage of unfavorable outcomes The threshold at which we would like OpenScale to display an alert if the fairness measurement falls below (in this case, 80%) Additionally, we must specify which outcomes from the model are favourable outcomes, and which are unfavourable. We must also provide the number of records OpenScale will use to calculate the fairness score. In this case, OpenScale's fairness monitor will run hourly, but will not calculate a new fairness rating until at least 100 records have been added. Finally, to calculate fairness, OpenScale must perform some calculations on the training data, so we provide the dataframe containing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f59d4d82ca7d4aa7978e7a777416c281"
   },
   "source": [
    "### Create Fairness Monitor Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1864c05c176f4a718e36059628d7f0ed"
   },
   "outputs": [],
   "source": [
    "target = Target(\n",
    "    target_type=TargetTypes.SUBSCRIPTION,\n",
    "    target_id=subscription_id\n",
    ")\n",
    "parameters = {\n",
    "    \"features\": [\n",
    "        {\n",
    "            \"feature\": \"sex\",\n",
    "            \"majority\": [\"Male\"],\n",
    "            \"minority\": [\"Female\"]\n",
    "        },\n",
    "        {\n",
    "            \"feature\": \"age\",\n",
    "            \"majority\": [[41,75]],\n",
    "            \"minority\": [[18,33]]\n",
    "        }\n",
    "    ],\n",
    "    \"favourable_class\": [\">50K\"],\n",
    "    \"unfavourable_class\": [\"<=50K\"],\n",
    "    \"min_records\": 1000\n",
    "}\n",
    "thresholds = [\n",
    "    {\n",
    "        \"metric_id\": \"fairness_value\",\n",
    "        \"specific_values\": [\n",
    "            {\n",
    "                \"applies_to\": [\n",
    "                    {\n",
    "                        \"type\": \"tag\",\n",
    "                        \"value\": \"sex\",\n",
    "                        \"key\": \"feature\"\n",
    "                    }\n",
    "                ],\n",
    "                \"value\": 80\n",
    "            },\n",
    "            {\n",
    "                \"applies_to\": [\n",
    "                    {\n",
    "                        \"type\": \"tag\",\n",
    "                        \"value\": \"age\",\n",
    "                        \"key\": \"feature\"\n",
    "                    }\n",
    "                ],\n",
    "                \"value\": 80\n",
    "            }\n",
    "        ],\n",
    "        \"type\": \"lower_limit\",\n",
    "        \"value\": 80\n",
    "    }\n",
    "]\n",
    "fairness_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.FAIRNESS.ID,\n",
    "    target=target,\n",
    "    parameters=parameters,\n",
    "    thresholds=thresholds\n",
    ").result\n",
    "fairness_monitor_instance_id =fairness_monitor_details.metadata.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae999234ea39453e82c74169ac7d74a8"
   },
   "source": [
    "### Get Fairness Monitor Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "812cdeea78af4ca8ba38ea5f07efd990"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03e3bf32570d4bb5816b860d58db555d"
   },
   "source": [
    "### Get run details\n",
    "In case of production subscription, initial monitoring run is triggered internally. Checking its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6af6098a23384c93b88f113f6b5024b7"
   },
   "outputs": [],
   "source": [
    "runs = wos_client.monitor_instances.list_runs(fairness_monitor_instance_id, limit=1).result.to_dict()\n",
    "fairness_monitoring_run_id = runs[\"runs\"][0][\"metadata\"][\"id\"]\n",
    "run_status = None\n",
    "while(run_status not in [\"finished\", \"error\"]):\n",
    "    run_details = wos_client.monitor_instances.get_run_details(fairness_monitor_instance_id, fairness_monitoring_run_id).result.to_dict()\n",
    "    run_status = run_details[\"entity\"][\"status\"][\"state\"]\n",
    "    print('run_status: ', run_status)\n",
    "    if run_status in [\"finished\", \"error\"]:\n",
    "        break\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13e80670e3474f5581ef4de516e19d70"
   },
   "source": [
    "### Fairness run output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b9b909ce8104fc4ad51ed3b7f388c5e"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.get_run_details(fairness_monitor_instance_id, fairness_monitoring_run_id).result.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd87098c263343c88302caf6c6a7fe67"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=fairness_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9a98378e36cc46388d1917d0b2440d98"
   },
   "outputs": [],
   "source": [
    "FAIRNESS_DASHBOARD_URL = WOS_CREDENTIALS[\"url\"] + \"/aiopenscale/insights/{0}/fairness/age?features=fairnessv2,indirect_bias,v2transaction\".format(deployment_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f957d3d9312a42bb8a446bf771490299"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "md(\"#### Link to IBM Watson OpenScale Fairness Dashboard: {}\".format(FAIRNESS_DASHBOARD_URL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03db2a8db59c417b89348fa82c665260"
   },
   "source": [
    "### Run on-demand Fairness\n",
    "If you would like to peform an on-demand fairness check, then we need to score a fresh set of data with meta-fields, so that they would be used for indirect bias checking. So the below two cells will score and make sure these records are reached to payload logging table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81d3d0ba7c344c0182a80525ba73bd15"
   },
   "outputs": [],
   "source": [
    "payload_logging(no_of_records_to_score = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a75a71a4d0ee44a7833a1fa0d39edbbe"
   },
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
    "print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
    "if pl_records_count == 0:\n",
    "    raise Exception(\"Payload logging did not happen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f02860d8d5564f25824b13d0c058cead"
   },
   "source": [
    "### Trigger fairness monitoring run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ff4b16a95858418aa085052cfabc350a"
   },
   "outputs": [],
   "source": [
    "run_details = wos_client.monitor_instances.run(monitor_instance_id=fairness_monitor_instance_id, background_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d272b783751e44fe83a5a179bfa4d8ad"
   },
   "source": [
    "### Check for its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8677dd14e5e42eb84da876e86eb15ee"
   },
   "outputs": [],
   "source": [
    "wos_client.monitor_instances.show_metrics(monitor_instance_id=fairness_monitor_instance_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34bb889585c04e9ca245ff091d58d921"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown as md\n",
    "md(\"#### To view the latest evaluation of the fairness check, please visit IBM Watson OpenScale Fairness Dashboard: {}\".format(FAIRNESS_DASHBOARD_URL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "958a4549555641c58bd9fbd0058d24cd"
   },
   "source": [
    "# Active debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4f0591e8da8b48ea9845950fd6423685"
   },
   "outputs": [],
   "source": [
    "no_of_records_to_score = 200\n",
    "payload_scoring, scoring_response = sample_scoring(no_of_records_to_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7166ec0e5378460782597ef4debbd0d6"
   },
   "source": [
    "### List the original model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18debd5a405e42af9f72b28dd8af58ba"
   },
   "outputs": [],
   "source": [
    "# for i in range(no_of_records_to_score):\n",
    "#     print(scoring_response['predictions'][0]['values'][i][-1:][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f60bc6f2f8c444988bc6e7b498a4331"
   },
   "source": [
    "## Get the token for calling OpenScale API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6e98dc87c5a4f47817899ed8af6325d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import base64\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import time\n",
    "\n",
    "token_url = WOS_CREDENTIALS['url'] + '/v1/preauth/validateAuth'\n",
    "headers = {}\n",
    "headers[\"Accept\"] = \"application/json\"\n",
    "auth = HTTPBasicAuth(WOS_CREDENTIALS['username'], WOS_CREDENTIALS['password'])\n",
    "response = requests.get(token_url, headers=headers, auth=auth, verify=False)\n",
    "json_data = response.json()\n",
    "access_token = json_data['accessToken']\n",
    "access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfecded322744744881cc4e2e944212e"
   },
   "outputs": [],
   "source": [
    "DEBIASING_PREDICTIONS_URL = WOS_CREDENTIALS['url'] + \"/openscale/{0}/v2/subscriptions/{1}/predictions\".format(data_mart_id,subscription_id)\n",
    "print(DEBIASING_PREDICTIONS_URL)\n",
    "\n",
    "headers = {}\n",
    "headers[\"Content-Type\"] = \"application/json\"\n",
    "headers[\"Accept\"] = \"application/json\"\n",
    "headers[\"Authorization\"] = \"Bearer {}\".format(access_token)\n",
    "\n",
    "debiased_scoring_payload = payload_scoring['input_data'][0]\n",
    "print('\\n>>>>>>>>>>>>>>>\\n')\n",
    "print(debiased_scoring_payload)\n",
    "print('\\n>>>>>>>>>>>>>>>\\n')\n",
    "\n",
    "response = requests.post(DEBIASING_PREDICTIONS_URL, data=json.dumps(debiased_scoring_payload), headers=headers, verify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a401c2184e6048db899ddcf9bfb450f1"
   },
   "source": [
    "## Listing those predictions whose original model prediction is different from the debiased prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3f46a6761dc4f5a87d45ab10fd17dc9"
   },
   "outputs": [],
   "source": [
    "predictedLabel_index = response.json()['fields'].index('predictedLabel')\n",
    "debiased_prediction_index = response.json()['fields'].index('debiased_prediction')\n",
    "\n",
    "for j in range(no_of_records_to_score):\n",
    "    scored_record = response.json()['values'][j]\n",
    "    predictedLabel = scored_record[predictedLabel_index]\n",
    "    debiased_prediction = scored_record[debiased_prediction_index]\n",
    "    if predictedLabel != debiased_prediction:\n",
    "        print('==========')\n",
    "        print(scored_record)\n",
    "        print('predictedLabel:' + str(predictedLabel) + ', debiased_prediction:' + str(debiased_prediction))\n",
    "        print('==========')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c16ee2e26b694f2e965bd37f38c5377e"
   },
   "source": [
    "## Additional data to help debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fd4853741be46d6b1330fb259ed0fc6"
   },
   "outputs": [],
   "source": [
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))\n",
    "print(\"OpenScale Datamart id: {}\".format(data_mart_id))\n",
    "print(\"OpenScale Subscription id: {}\".format(subscription_id))\n",
    "print(\"OpenScale Fairness Monitor Instance id: {}\".format(fairness_monitor_instance_id))\n",
    "print(\"OpenScale Fairness Monitoring Run id: {}\".format(fairness_monitoring_run_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "914d7fc6498141b9b1562bc1a43cf0ac"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "As part of this notebook we did the following tasks\n",
    "\n",
    "- Created and trained an Income classification model. We made sure to remove the sensitive attributes - age, sex and race while training the model.\n",
    "- Identified a Space to be associated with the model and its deployment.\n",
    "- Deployed the model to the space and scored it with additional meta fields.\n",
    "- Configured OpenScale and subscribed the deployment.\n",
    "- Configured fairness on the meta fields (sensitive attributes) age and sex.\n",
    "- Ran fairness monitor\n",
    "- Noticed that Indirect Bias exists against age attribute, as it can be visualised in the OpenScale dashboard.\n",
    "- Did an on-demand evaluation of the fairness monitor as well.\n",
    "- Call the active debias API, otherwise called as OpenScale predictions API, to notice that from the set of scored records indeed there exists some records for which debiased prediction is different from the original prediction.  \n",
    "- The above step proves that OpenScale is successfully able to debiased the model prediction even on the meta/sensitive attributes.\n",
    "\n",
    "That's all for now. Thank You!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}